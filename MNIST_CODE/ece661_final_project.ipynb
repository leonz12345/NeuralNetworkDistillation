{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ece661_final_project.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMTAhmxdP146puJqgCdphsh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"58c8c50b1daa493291e264763b37a8cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e07e705be5f243ab918b2de2a4129096","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bebc3b1e032841c28610e487d8f2215e","IPY_MODEL_fb90c47d78c14707ad9367516979a13d","IPY_MODEL_17c1f4d89d3342dca4c1a42f46d8179f"]}},"e07e705be5f243ab918b2de2a4129096":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bebc3b1e032841c28610e487d8f2215e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_23c82f5f3fef4211aabc50e1df48c2cc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f7a32e862c3b43c685c024897f7f889b"}},"fb90c47d78c14707ad9367516979a13d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_33b9fb59a2eb473abafdbc959ff8f73d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":9912422,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9912422,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1f18bf684e7b4d319572f1e41b8905b7"}},"17c1f4d89d3342dca4c1a42f46d8179f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a6c210a96c564f33aa007f40c95a3aa3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9913344/? [00:00&lt;00:00, 17026036.82it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_31292d316cdf48559642197506e0a8de"}},"23c82f5f3fef4211aabc50e1df48c2cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f7a32e862c3b43c685c024897f7f889b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"33b9fb59a2eb473abafdbc959ff8f73d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1f18bf684e7b4d319572f1e41b8905b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a6c210a96c564f33aa007f40c95a3aa3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"31292d316cdf48559642197506e0a8de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b36f38158a6b4539ba0656f9d14a5b91":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d29746f8a48c48e98a5952e453808c33","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7b541af50a1f492381df9b279ea7aa99","IPY_MODEL_9c3c51c0c57d486e92ee620f7ff662e2","IPY_MODEL_a097d77c5b1247279a84eac9d2471cc5"]}},"d29746f8a48c48e98a5952e453808c33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7b541af50a1f492381df9b279ea7aa99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8b08f85e570c4281b4554589e01a96c2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_86ab23c3e92b46c29ff200116250a97a"}},"9c3c51c0c57d486e92ee620f7ff662e2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5a2fa31d0d4643ad81a15ef37b48c984","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":28881,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28881,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_51b4bcae21d14d81be0c831fb0ec1b6a"}},"a097d77c5b1247279a84eac9d2471cc5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f8f2deae5b404fb69dd1c049bcebf4a3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29696/? [00:00&lt;00:00, 894624.18it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1f1ebfd43a2e4957b77f709e459c4702"}},"8b08f85e570c4281b4554589e01a96c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"86ab23c3e92b46c29ff200116250a97a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5a2fa31d0d4643ad81a15ef37b48c984":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"51b4bcae21d14d81be0c831fb0ec1b6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f8f2deae5b404fb69dd1c049bcebf4a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1f1ebfd43a2e4957b77f709e459c4702":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"807e87a27dfd48e7b90590018d80fb15":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0ad2a6d5d1e748d5afb7284e9f143602","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_cbeb7291ab054e81853790ee1f5335fe","IPY_MODEL_ed3382dd96c74ff9b1262a0d8878400c","IPY_MODEL_92b605464b264ea8b04313d637f81ace"]}},"0ad2a6d5d1e748d5afb7284e9f143602":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cbeb7291ab054e81853790ee1f5335fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4d664c857735440183f75f40ed885500","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_827ab53d0d7e43b8b3b716681183c540"}},"ed3382dd96c74ff9b1262a0d8878400c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fb3eb2335f0e409eaed110d033e219b4","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1648877,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1648877,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_97ec062fe93440558c87ed4786eb6e31"}},"92b605464b264ea8b04313d637f81ace":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_19bff8cc917447b994e2cf2d69d36d9b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1649664/? [00:00&lt;00:00, 5864817.51it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_701a3ad50a7d47fb8980cfcbe3b86c3e"}},"4d664c857735440183f75f40ed885500":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"827ab53d0d7e43b8b3b716681183c540":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fb3eb2335f0e409eaed110d033e219b4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"97ec062fe93440558c87ed4786eb6e31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"19bff8cc917447b994e2cf2d69d36d9b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"701a3ad50a7d47fb8980cfcbe3b86c3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a862a7f6fec7459f89075b48a09569c3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2cea1507944d4b82952a12df2d571187","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f1c1c56928bf4fe280a8346c66f817e2","IPY_MODEL_624514484ee24d8d9b0a1746eba09cf0","IPY_MODEL_7b7f54fd935b447f8f2bc62c9a09b4a3"]}},"2cea1507944d4b82952a12df2d571187":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f1c1c56928bf4fe280a8346c66f817e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5992a8177f4543c586203522ba0e2720","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ce7323cdd1db427ab51e85b8dacb160b"}},"624514484ee24d8d9b0a1746eba09cf0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6f6ecb39691548f18755fb8ef4c7df9d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":4542,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4542,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c96d855810f649dc89e16ed4dae97018"}},"7b7f54fd935b447f8f2bc62c9a09b4a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4afd68f0e77e46adb48982cc6b8a576b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5120/? [00:00&lt;00:00, 200336.18it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d03adf5c9a8944759b7e8291ed3aebe8"}},"5992a8177f4543c586203522ba0e2720":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ce7323cdd1db427ab51e85b8dacb160b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6f6ecb39691548f18755fb8ef4c7df9d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c96d855810f649dc89e16ed4dae97018":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4afd68f0e77e46adb48982cc6b8a576b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d03adf5c9a8944759b7e8291ed3aebe8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F2mjZk18qq69","executionInfo":{"status":"ok","timestamp":1638842003014,"user_tz":300,"elapsed":19738,"user":{"displayName":"林子昊","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05325542234136368744"}},"outputId":"cde29974-2457-4118-ea3e-830b7b710da8"},"source":["from google.colab import drive \n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"TI_WCjcmqtJu","executionInfo":{"status":"ok","timestamp":1638842008841,"user_tz":300,"elapsed":181,"user":{"displayName":"林子昊","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05325542234136368744"}}},"source":["import sys\n","sys.path.append('/content/drive/MyDrive/duke/ECE 661/final project/code')"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"YAKRTBu0q2-O","executionInfo":{"status":"ok","timestamp":1638842016536,"user_tz":300,"elapsed":6562,"user":{"displayName":"林子昊","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05325542234136368744"}}},"source":["import os\n","import time\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from Models import StudentSimpleNN, TeacherSimpleNN"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tlmx6JDDwUlr"},"source":["## Test network"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PkbNlnxRwW6M","executionInfo":{"status":"ok","timestamp":1638842021660,"user_tz":300,"elapsed":168,"user":{"displayName":"林子昊","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05325542234136368744"}},"outputId":"699228df-44b3-4ed8-c69f-8f9fae5ccf31"},"source":["input_test = torch.randn([3, 28, 28])\n","StudentNetwork = StudentSimpleNN()\n","out = StudentNetwork(input_test)\n","print(out.size())\n","\n","TeacherNetwork = TeacherSimpleNN()\n","out = TeacherNetwork(input_test)\n","print(out.size())"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 10])\n","torch.Size([3, 10])\n"]}]},{"cell_type":"markdown","metadata":{"id":"UEy01RSLwGUf"},"source":["## Data Preprocess"]},{"cell_type":"code","metadata":{"id":"ONgzMPztwINr","executionInfo":{"status":"ok","timestamp":1638842024974,"user_tz":300,"elapsed":364,"user":{"displayName":"林子昊","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05325542234136368744"}}},"source":["import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"6QYmJE0OwOcP","colab":{"base_uri":"https://localhost:8080/","height":417,"referenced_widgets":["58c8c50b1daa493291e264763b37a8cb","e07e705be5f243ab918b2de2a4129096","bebc3b1e032841c28610e487d8f2215e","fb90c47d78c14707ad9367516979a13d","17c1f4d89d3342dca4c1a42f46d8179f","23c82f5f3fef4211aabc50e1df48c2cc","f7a32e862c3b43c685c024897f7f889b","33b9fb59a2eb473abafdbc959ff8f73d","1f18bf684e7b4d319572f1e41b8905b7","a6c210a96c564f33aa007f40c95a3aa3","31292d316cdf48559642197506e0a8de","b36f38158a6b4539ba0656f9d14a5b91","d29746f8a48c48e98a5952e453808c33","7b541af50a1f492381df9b279ea7aa99","9c3c51c0c57d486e92ee620f7ff662e2","a097d77c5b1247279a84eac9d2471cc5","8b08f85e570c4281b4554589e01a96c2","86ab23c3e92b46c29ff200116250a97a","5a2fa31d0d4643ad81a15ef37b48c984","51b4bcae21d14d81be0c831fb0ec1b6a","f8f2deae5b404fb69dd1c049bcebf4a3","1f1ebfd43a2e4957b77f709e459c4702","807e87a27dfd48e7b90590018d80fb15","0ad2a6d5d1e748d5afb7284e9f143602","cbeb7291ab054e81853790ee1f5335fe","ed3382dd96c74ff9b1262a0d8878400c","92b605464b264ea8b04313d637f81ace","4d664c857735440183f75f40ed885500","827ab53d0d7e43b8b3b716681183c540","fb3eb2335f0e409eaed110d033e219b4","97ec062fe93440558c87ed4786eb6e31","19bff8cc917447b994e2cf2d69d36d9b","701a3ad50a7d47fb8980cfcbe3b86c3e","a862a7f6fec7459f89075b48a09569c3","2cea1507944d4b82952a12df2d571187","f1c1c56928bf4fe280a8346c66f817e2","624514484ee24d8d9b0a1746eba09cf0","7b7f54fd935b447f8f2bc62c9a09b4a3","5992a8177f4543c586203522ba0e2720","ce7323cdd1db427ab51e85b8dacb160b","6f6ecb39691548f18755fb8ef4c7df9d","c96d855810f649dc89e16ed4dae97018","4afd68f0e77e46adb48982cc6b8a576b","d03adf5c9a8944759b7e8291ed3aebe8"]},"executionInfo":{"status":"ok","timestamp":1638842293213,"user_tz":300,"elapsed":1671,"user":{"displayName":"林子昊","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05325542234136368744"}},"outputId":"fae827a9-5191-4617-f8b4-0c37b70e2336"},"source":["MNISI_shape = (28, 28)\n","pad_size = 2\n","TRAIN_BATCH_SIZE = 128\n","\n","\n","transform_train = transforms.Compose([transforms.RandomCrop(MNISI_shape, pad_size),\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize([0.5], [0.5])])\n","\n","transform_test = transforms.Compose([transforms.ToTensor(),\n","                                    transforms.Normalize([0.5], [0.5])])\n","\n","train_MNIST = torchvision.datasets.MNIST(root='./', train=True, download=True, transform = transform_train)\n","\n","test_MNIST = torchvision.datasets.MNIST(root='./', train=False, download=True, transform=transform_test)\n","\n","num_train = int(1.0 * len(train_MNIST) * 95 / 100)\n","num_val = len(train_MNIST) - num_train\n","train_MNIST, val_MNIST = torch.utils.data.random_split(train_MNIST, [num_train, num_val])\n","\n","train_loader = DataLoader(\n","    train_MNIST, \n","    batch_size=TRAIN_BATCH_SIZE,\n","    shuffle=True,\n","    num_workers=2\n",")\n","\n","val_loader = DataLoader(\n","    val_MNIST, \n","    batch_size=TRAIN_BATCH_SIZE,\n","    shuffle=True,\n","    num_workers=2\n",")\n","\n","test_loader = DataLoader(\n","    test_MNIST, \n","    batch_size=TRAIN_BATCH_SIZE,\n","    shuffle=True,\n","    num_workers=2\n",")"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"58c8c50b1daa493291e264763b37a8cb","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/9912422 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b36f38158a6b4539ba0656f9d14a5b91","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/28881 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"807e87a27dfd48e7b90590018d80fb15","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1648877 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a862a7f6fec7459f89075b48a09569c3","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/4542 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q34fGl1dykjq","executionInfo":{"status":"ok","timestamp":1638842305175,"user_tz":300,"elapsed":9067,"user":{"displayName":"林子昊","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05325542234136368744"}},"outputId":"b69fc2ef-6516-47f2-978f-29f4f0ed7be7"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"The model is deployed to\", device)\n","\n","StudentNet = StudentSimpleNN().to(device)\n","TeacherNet = TeacherSimpleNN().to(device)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["The model is deployed to cuda:0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O5qB05XqpHcK","executionInfo":{"status":"ok","timestamp":1638842307893,"user_tz":300,"elapsed":1211,"user":{"displayName":"林子昊","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05325542234136368744"}},"outputId":"ee4cf5f9-0d15-47a5-d6bf-6744bc30d81c"},"source":["trained_teacher_model = TeacherSimpleNN()\n","checkpoint = torch.load(\"/content/drive/MyDrive/duke/ECE 661/final project/code/checkpoints/TeacherNet.pth\")\n","trained_teacher_model.load_state_dict(checkpoint['state_dict'])\n","trained_teacher_model.to(device)\n","trained_teacher_model.eval()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TeacherSimpleNN(\n","  (linear1): Linear(in_features=784, out_features=1200, bias=True)\n","  (linear2): Linear(in_features=1200, out_features=1200, bias=True)\n","  (linear3): Linear(in_features=1200, out_features=10, bias=True)\n","  (dropout): Dropout(p=0.3, inplace=False)\n",")"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"NUUfspFLxCkN"},"source":["## FLOPS"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ORu4kxJrkPW","executionInfo":{"status":"ok","timestamp":1638843479330,"user_tz":300,"elapsed":168,"user":{"displayName":"林子昊","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05325542234136368744"}},"outputId":"30f0f5b1-119b-4618-ea4a-076785fbd875"},"source":["StudentSimpleNN()"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["StudentSimpleNN(\n","  (linear1): Linear(in_features=784, out_features=400, bias=True)\n","  (linear2): Linear(in_features=400, out_features=10, bias=True)\n","  (linear3): Linear(in_features=400, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B7yIIZypxEoR","executionInfo":{"status":"ok","timestamp":1638844899456,"user_tz":300,"elapsed":198,"user":{"displayName":"林子昊","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05325542234136368744"}},"outputId":"17bcae30-996d-4168-8540-dbd648f0a815"},"source":["2 * 784 * 400 + 2 * 400 * 10"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["635200"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cKkZn_kyr0TL","executionInfo":{"status":"ok","timestamp":1638843513859,"user_tz":300,"elapsed":167,"user":{"displayName":"林子昊","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05325542234136368744"}},"outputId":"b512ef44-fb6a-4183-ae49-4a287cdda1c5"},"source":["TeacherSimpleNN()"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TeacherSimpleNN(\n","  (linear1): Linear(in_features=784, out_features=1200, bias=True)\n","  (linear2): Linear(in_features=1200, out_features=1200, bias=True)\n","  (linear3): Linear(in_features=1200, out_features=10, bias=True)\n","  (dropout): Dropout(p=0.3, inplace=False)\n",")"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"USpuHQKxx37o","executionInfo":{"status":"ok","timestamp":1638845113577,"user_tz":300,"elapsed":159,"user":{"displayName":"林子昊","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05325542234136368744"}},"outputId":"1456a986-0094-4720-d7a2-8a302a706440"},"source":["2 * 784 * 1200 + 2 * 1200 * 1200 + 2 * 1200 * 10"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4785600"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":504},"id":"klOvRKKRnhDA","executionInfo":{"status":"error","timestamp":1638843419230,"user_tz":300,"elapsed":159,"user":{"displayName":"林子昊","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05325542234136368744"}},"outputId":"b42bd220-759b-48c0-94e1-3ef8ba315d38"},"source":["for name, module in TeacherNet.named_modules():\n","  input = module.linear1.weight\n","  #output = module.output\n","  # num_param = len(module.weight.reshape(-1))\n","  print(\"name: {}\".format(input))"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["name: Parameter containing:\n","tensor([[ 0.0246,  0.0195, -0.0226,  ..., -0.0204,  0.0244,  0.0213],\n","        [ 0.0026,  0.0080,  0.0189,  ...,  0.0107, -0.0018,  0.0059],\n","        [ 0.0241,  0.0020, -0.0177,  ..., -0.0051,  0.0057, -0.0353],\n","        ...,\n","        [-0.0104, -0.0326, -0.0263,  ..., -0.0168, -0.0346,  0.0138],\n","        [ 0.0124,  0.0151, -0.0339,  ...,  0.0132, -0.0258,  0.0307],\n","        [-0.0224, -0.0032,  0.0108,  ...,  0.0158, -0.0346,  0.0207]],\n","       device='cuda:0', requires_grad=True)\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-b32d15242881>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTeacherNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;31m#output = module.output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m# num_param = len(module.weight.reshape(-1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"name: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1178\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Linear' object has no attribute 'linear1'"]}]},{"cell_type":"markdown","metadata":{"id":"VM6UJfpipHyF"},"source":["## The function of train models"]},{"cell_type":"code","metadata":{"id":"bUMpS1f9pT06"},"source":["LEARNING_RATE = 0.01\n","LEARNING_RATE_DECAY = 0.95\n","\n","WEIGHT_DECAY = 1e-4\n","\n","MOMENTUM = 0.9\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","EPOCHS = 60\n","\n","DECAY_EPOCHS = 10\n","DECAY = 1.0\n","\n","CHECKPOINT_PATH = \"/content/drive/MyDrive/duke/ECE 661/final project/code/checkpoints\"\n","\n","# for student model\n","T = 1\n","alpha = 0.7 # 0.7"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xUEC0DJU0S_3"},"source":["def train_model(model, mode, train_loader, save_name):\n","\n","  print(\"Now T is {}\".format(T))\n","\n","  optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n","\n","  best_val_acc = 0\n","  current_learning_rate = LEARNING_RATE\n","\n","  softmax = torch.nn.Softmax(dim=1)\n","\n","  print(\"==> Start training!\")\n","  print(\"=\"*50)\n","\n","  for i in range(0, EPOCHS):\n","    if i % DECAY_EPOCHS == 0 and i !=0:\n","      current_learning_rate = current_learning_rate * LEARNING_RATE_DECAY\n","      for param_group in optimizer.param_groups:\n","        param_group['lr'] = current_learning_rate\n","      print(\"Current learning rate has decayed to {}\".format(current_learning_rate))\n","\n","    model.train()\n","\n","    print(\"Epoch {}\".format(i))\n","\n","    total_examples = 0\n","    correct_examples = 0\n","\n","    train_loss = 0\n","\n","    for batch_idx, (inputs, targets) in enumerate(train_loader):\n","      inputs, targets = inputs.to(device), targets.to(device)\n","\n","      pred = model(inputs)\n","      if mode == \"teacher\" or mode == \"studentOri\":\n","        train_loss = criterion(pred, targets)\n","      else:\n","        if alpha > 0:\n","          with torch.no_grad():\n","            teacher_pred = trained_teacher_model(inputs)\n","        else:\n","          teacher_pred = 0\n","        train_loss = studentLoss(teacher_pred, pred, targets, T, alpha)\n","\n","      optimizer.zero_grad()\n","      train_loss.backward()\n","      optimizer.step()\n","\n","      total_examples += inputs.shape[0]\n","\n","      out = softmax(pred)\n","      out = torch.max(out, 1)\n","\n","      correct_examples += torch.sum(targets==out[1]).cpu().data.numpy().tolist()\n","\n","    avg_loss = train_loss / len(train_loader)\n","    avg_acc = correct_examples / total_examples\n","    print(\"Training loss: {}, training accuracy: {}\".format(avg_loss, avg_acc))\n","\n","    model.eval()\n","\n","    total_examples = 0\n","    correct_examples = 0\n","\n","    with torch.no_grad():\n","      for batch_idx, (inputs, targets) in enumerate(val_loader):\n","\n","        inputs, targets = inputs.to(device), targets.to(device)\n","\n","        pred = model(inputs)\n","        val_loss = criterion(pred, targets)\n","\n","        total_examples += inputs.shape[0]\n","\n","        out = softmax(pred)\n","        out = torch.max(out, 1)\n","\n","        correct_examples += torch.sum(targets==out[1]).cpu().data.numpy().tolist()\n","\n","    avg_loss = val_loss / len(val_loader)\n","    avg_acc = correct_examples / total_examples\n","    print(\"Val loss: {}, val accuracy: {}\".format(avg_loss, avg_acc))\n","\n","    if avg_acc > best_val_acc:\n","      best_val_acc = avg_acc\n","      print(\"Saving ...\")\n","      state = {'state_dict': model.state_dict(),\n","              'epoch': i,\n","              'lr': current_learning_rate}\n","      \n","      # if mode == \"teacher\":\n","      #   model_name = \"TeacherNet.pth\"\n","      # elif mode == \"studentOri\":\n","      #   model_name = \"StudentNetOri.pth\"\n","      # else:\n","      #   model_name = \"T_\" + str(T) + \"_KDStudentNet.pth\"\n","      \n","      torch.save(state, os.path.join(CHECKPOINT_PATH, save_name))\n","\n","    print('')\n","\n","  print(\"=\"*50)\n","  print(\"==> Finished Training! The best accuracy is {}\".format(best_val_acc))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2jTdtXqZPF4Z"},"source":["def test_model(model_name, mode):\n","  if mode == \"teacher\":\n","    model = TeacherSimpleNN()\n","  else:\n","    model = StudentSimpleNN()\n","\n","  checkpoint = torch.load(os.path.join(CHECKPOINT_PATH, model_name))\n","  model.load_state_dict(checkpoint['state_dict'])\n","  model.to(device)\n","  model.eval()\n","\n","  total_examples = 0\n","  correct_examples = 0\n","  softmax = torch.nn.Softmax(dim=1)\n","\n","  with torch.no_grad():\n","    for batch_idx, (inputs, targets) in enumerate(test_loader):\n","\n","      inputs, targets = inputs.to(device), targets.to(device)\n","\n","      pred = model(inputs)\n","\n","      total_examples += inputs.shape[0]\n","\n","      out = softmax(pred)\n","      out = torch.max(out, 1)\n","\n","      correct_examples += torch.sum(targets==out[1]).cpu().data.numpy().tolist()\n","\n","  avg_acc = correct_examples / total_examples\n","  print(\"Total examples is {}, correct examples is {}; Test accuracy: {}\".format(total_examples, correct_examples, avg_acc))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"35QGzWZl9FNl"},"source":["## Teacher Model"]},{"cell_type":"code","metadata":{"id":"qlz_pOLLDzN6"},"source":["# TeacherNet = TeacherSimpleNN().to(device)\n","# train_model(TeacherNet, \"teacher\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LYm8KbMkQEFR","executionInfo":{"status":"ok","timestamp":1638198715953,"user_tz":300,"elapsed":2247,"user":{"displayName":"林子昊","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05325542234136368744"}},"outputId":"99bbdf7e-f48f-4a5d-d689-93bd9a2c8045"},"source":["test_model(\"TeacherNet.pth\", \"teacher\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total examples is 10000, correct examples is 9887; Test accuracy: 0.9887\n"]}]},{"cell_type":"markdown","metadata":{"id":"bawKy_DOkGO2"},"source":["## Student Model"]},{"cell_type":"code","metadata":{"id":"gTgDqpcJkHdQ"},"source":["def studentLoss(teacher_pred, student_pred, targets, T, alpha):\n","  \"\"\"\n","  Loss function for student network: Loss = alpha * (distillation loss with soft-target) + (1 - alpha) * (cross-entropy loss with true label)\n","\tReturn: loss\n","  \"\"\"\n","  if alpha > 0:\n","    loss = F.kl_div(F.softmax(student_pred / T, dim=1), F.softmax(teacher_pred / T, dim=1), reduction='batchmean') * (T**2) * alpha + F.cross_entropy(student_pred, targets) * (1 - alpha)\n","  else:\n","    loss = F.cross_entropy(student_pred, targets)\n","  \n","  return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KPPKADJmuZ0X","executionInfo":{"status":"ok","timestamp":1638372645101,"user_tz":300,"elapsed":650922,"user":{"displayName":"林子昊","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05325542234136368744"}},"outputId":"9100f64a-0a65-4a2e-850d-e49c206e86a3"},"source":["StudentNet = StudentSimpleNN().to(device)\n","train_model(StudentNet, \"studentOri\", train_loader, \"studentOri_alpha01.pth\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Now T is 1\n","==> Start training!\n","==================================================\n","Epoch 0\n","Training loss: 0.0008786359103396535, training accuracy: 0.7356491228070176\n","Val loss: 0.014092715457081795, val accuracy: 0.871\n","Saving ...\n","\n","Epoch 1\n","Training loss: 0.0007547381683252752, training accuracy: 0.8956491228070176\n","Val loss: 0.011453873477876186, val accuracy: 0.9276666666666666\n","Saving ...\n","\n","Epoch 2\n","Training loss: 0.0006024328758940101, training accuracy: 0.9301929824561403\n","Val loss: 0.008119028061628342, val accuracy: 0.93\n","Saving ...\n","\n","Epoch 3\n","Training loss: 0.00015600444748997688, training accuracy: 0.9423684210526316\n","Val loss: 0.006668878719210625, val accuracy: 0.9416666666666667\n","Saving ...\n","\n","Epoch 4\n","Training loss: 0.00025375670520588756, training accuracy: 0.9473684210526315\n","Val loss: 0.006049653049558401, val accuracy: 0.9486666666666667\n","Saving ...\n","\n","Epoch 5\n","Training loss: 0.00018222567450720817, training accuracy: 0.9527543859649122\n","Val loss: 0.0032350486144423485, val accuracy: 0.9556666666666667\n","Saving ...\n","\n","Epoch 6\n","Training loss: 0.0003338175010867417, training accuracy: 0.9566842105263158\n","Val loss: 0.007751289755105972, val accuracy: 0.958\n","Saving ...\n","\n","Epoch 7\n","Training loss: 0.00030274022719822824, training accuracy: 0.9588421052631579\n","Val loss: 0.0009440939757041633, val accuracy: 0.961\n","Saving ...\n","\n","Epoch 8\n","Training loss: 0.00014922060654498637, training accuracy: 0.9619473684210527\n","Val loss: 0.009698336943984032, val accuracy: 0.958\n","\n","Epoch 9\n","Training loss: 0.00019193159823771566, training accuracy: 0.961561403508772\n","Val loss: 0.003457094309851527, val accuracy: 0.9656666666666667\n","Saving ...\n","\n","Current learning rate has decayed to 0.0095\n","Epoch 10\n","Training loss: 0.00021725016995333135, training accuracy: 0.9648947368421052\n","Val loss: 0.007003037258982658, val accuracy: 0.9556666666666667\n","\n","Epoch 11\n","Training loss: 7.623626879649237e-05, training accuracy: 0.9655789473684211\n","Val loss: 0.0038239462301135063, val accuracy: 0.97\n","Saving ...\n","\n","Epoch 12\n","Training loss: 4.6468747314065695e-05, training accuracy: 0.9681052631578947\n","Val loss: 0.0011042817495763302, val accuracy: 0.9633333333333334\n","\n","Epoch 13\n","Training loss: 0.0001267565239686519, training accuracy: 0.9694385964912281\n","Val loss: 0.0063602132722735405, val accuracy: 0.9653333333333334\n","\n","Epoch 14\n","Training loss: 0.00014976579404901713, training accuracy: 0.9687368421052631\n","Val loss: 0.0036606998182833195, val accuracy: 0.9706666666666667\n","Saving ...\n","\n","Epoch 15\n","Training loss: 0.0002678612945601344, training accuracy: 0.9707894736842105\n","Val loss: 0.00583251379430294, val accuracy: 0.9693333333333334\n","\n","Epoch 16\n","Training loss: 3.1162948289420456e-05, training accuracy: 0.9709649122807018\n","Val loss: 0.008308567106723785, val accuracy: 0.974\n","Saving ...\n","\n","Epoch 17\n","Training loss: 0.0001291827211389318, training accuracy: 0.9710350877192983\n","Val loss: 0.006072673946619034, val accuracy: 0.9716666666666667\n","\n","Epoch 18\n","Training loss: 2.2719201297149993e-05, training accuracy: 0.972859649122807\n","Val loss: 0.007424185983836651, val accuracy: 0.9693333333333334\n","\n","Epoch 19\n","Training loss: 7.174207712523639e-05, training accuracy: 0.9726140350877193\n","Val loss: 0.0013825460337102413, val accuracy: 0.975\n","Saving ...\n","\n","Current learning rate has decayed to 0.009025\n","Epoch 20\n","Training loss: 6.672218296444044e-05, training accuracy: 0.9735789473684211\n","Val loss: 0.002343469299376011, val accuracy: 0.974\n","\n","Epoch 21\n","Training loss: 8.783824159763753e-05, training accuracy: 0.975\n","Val loss: 0.0010465648956596851, val accuracy: 0.9763333333333334\n","Saving ...\n","\n","Epoch 22\n","Training loss: 0.00021341981482692063, training accuracy: 0.9744561403508772\n","Val loss: 0.002131130313500762, val accuracy: 0.9773333333333334\n","Saving ...\n","\n","Epoch 23\n","Training loss: 8.182085730368271e-05, training accuracy: 0.976\n","Val loss: 0.011400445364415646, val accuracy: 0.9736666666666667\n","\n","Epoch 24\n","Training loss: 0.00017455754277762026, training accuracy: 0.9748771929824561\n","Val loss: 0.0030639274045825005, val accuracy: 0.975\n","\n","Epoch 25\n","Training loss: 0.00023473250621464103, training accuracy: 0.9753859649122807\n","Val loss: 0.007342561148107052, val accuracy: 0.973\n","\n","Epoch 26\n","Training loss: 4.31765838584397e-05, training accuracy: 0.977561403508772\n","Val loss: 0.004624527413398027, val accuracy: 0.974\n","\n","Epoch 27\n","Training loss: 5.3774809202877805e-05, training accuracy: 0.9768421052631578\n","Val loss: 0.0005191243253648281, val accuracy: 0.9793333333333333\n","Saving ...\n","\n","Epoch 28\n","Training loss: 0.0002825096307788044, training accuracy: 0.9778070175438597\n","Val loss: 0.0026109153404831886, val accuracy: 0.978\n","\n","Epoch 29\n","Training loss: 0.00023266737116500735, training accuracy: 0.9774035087719298\n","Val loss: 0.005126989912241697, val accuracy: 0.9753333333333334\n","\n","Current learning rate has decayed to 0.00857375\n","Epoch 30\n","Training loss: 0.00011966493184445426, training accuracy: 0.978140350877193\n","Val loss: 0.008212759159505367, val accuracy: 0.9733333333333334\n","\n","Epoch 31\n","Training loss: 0.00015252221783157438, training accuracy: 0.9788947368421053\n","Val loss: 0.008931910619139671, val accuracy: 0.975\n","\n","Epoch 32\n","Training loss: 4.390465255710296e-05, training accuracy: 0.9785263157894737\n","Val loss: 0.00886007770895958, val accuracy: 0.9786666666666667\n","\n","Epoch 33\n","Training loss: 3.623095108196139e-05, training accuracy: 0.979\n","Val loss: 0.0006604857626371086, val accuracy: 0.978\n","\n","Epoch 34\n","Training loss: 0.0001884465746115893, training accuracy: 0.9792456140350877\n","Val loss: 0.0007200022228062153, val accuracy: 0.975\n","\n","Epoch 35\n","Training loss: 0.00026779636391438544, training accuracy: 0.9794736842105263\n","Val loss: 0.00207298481836915, val accuracy: 0.98\n","Saving ...\n","\n","Epoch 36\n","Training loss: 2.8906226361868903e-05, training accuracy: 0.9798421052631578\n","Val loss: 0.00022362376330420375, val accuracy: 0.9806666666666667\n","Saving ...\n","\n","Epoch 37\n","Training loss: 5.3435174777405336e-05, training accuracy: 0.9794385964912281\n","Val loss: 0.003212118288502097, val accuracy: 0.9816666666666667\n","Saving ...\n","\n","Epoch 38\n","Training loss: 0.00014088502211961895, training accuracy: 0.9805789473684211\n","Val loss: 0.004455073270946741, val accuracy: 0.9776666666666667\n","\n","Epoch 39\n","Training loss: 0.00043963294592686, training accuracy: 0.9803508771929824\n","Val loss: 0.0043301354162395, val accuracy: 0.976\n","\n","Current learning rate has decayed to 0.0081450625\n","Epoch 40\n","Training loss: 5.318140392773785e-05, training accuracy: 0.9811052631578947\n","Val loss: 0.000672024441882968, val accuracy: 0.9753333333333334\n","\n","Epoch 41\n","Training loss: 0.00024004725855775177, training accuracy: 0.9812105263157894\n","Val loss: 0.0016832835972309113, val accuracy: 0.9793333333333333\n","\n","Epoch 42\n","Training loss: 8.567902841605246e-05, training accuracy: 0.9811228070175438\n","Val loss: 0.002192896092310548, val accuracy: 0.976\n","\n","Epoch 43\n","Training loss: 0.00010278775880578905, training accuracy: 0.981280701754386\n","Val loss: 0.006592059042304754, val accuracy: 0.9806666666666667\n","\n","Epoch 44\n","Training loss: 0.00022090208949521184, training accuracy: 0.9814736842105263\n","Val loss: 0.0022597946226596832, val accuracy: 0.9786666666666667\n","\n","Epoch 45\n","Training loss: 9.859184501692653e-05, training accuracy: 0.9822631578947368\n","Val loss: 0.0022935993038117886, val accuracy: 0.978\n","\n","Epoch 46\n","Training loss: 5.728864198317751e-05, training accuracy: 0.9821929824561404\n","Val loss: 0.0006880904547870159, val accuracy: 0.981\n","\n","Epoch 47\n","Training loss: 2.4649507395224646e-05, training accuracy: 0.9820350877192983\n","Val loss: 0.0025164384860545397, val accuracy: 0.981\n","\n","Epoch 48\n","Training loss: 9.594020957592875e-05, training accuracy: 0.9818771929824561\n","Val loss: 0.0012801471166312695, val accuracy: 0.977\n","\n","Epoch 49\n","Training loss: 7.905469101388007e-05, training accuracy: 0.982421052631579\n","Val loss: 0.008915165439248085, val accuracy: 0.981\n","\n","Current learning rate has decayed to 0.007737809374999999\n","Epoch 50\n","Training loss: 0.00011742487549781799, training accuracy: 0.9826140350877193\n","Val loss: 0.0026555899530649185, val accuracy: 0.9816666666666667\n","\n","Epoch 51\n","Training loss: 0.00018272433953825384, training accuracy: 0.9825263157894737\n","Val loss: 0.001277641043998301, val accuracy: 0.982\n","Saving ...\n","\n","Epoch 52\n","Training loss: 1.776376120687928e-05, training accuracy: 0.982280701754386\n","Val loss: 0.0014626348856836557, val accuracy: 0.9806666666666667\n","\n","Epoch 53\n","Training loss: 2.846105780918151e-05, training accuracy: 0.9834035087719298\n","Val loss: 0.003796603297814727, val accuracy: 0.9786666666666667\n","\n","Epoch 54\n","Training loss: 0.0005490851472131908, training accuracy: 0.9841052631578947\n","Val loss: 0.004692353308200836, val accuracy: 0.98\n","\n","Epoch 55\n","Training loss: 0.00046210066648200154, training accuracy: 0.9839473684210527\n","Val loss: 0.0016901659546419978, val accuracy: 0.978\n","\n","Epoch 56\n","Training loss: 5.388117642723955e-05, training accuracy: 0.9842982456140351\n","Val loss: 0.0020062741823494434, val accuracy: 0.9763333333333334\n","\n","Epoch 57\n","Training loss: 3.1306939490605146e-05, training accuracy: 0.9833859649122807\n","Val loss: 0.0016138434875756502, val accuracy: 0.982\n","\n","Epoch 58\n","Training loss: 0.00015532590623479337, training accuracy: 0.983719298245614\n","Val loss: 0.0011425225529819727, val accuracy: 0.9833333333333333\n","Saving ...\n","\n","Epoch 59\n","Training loss: 0.00022614399495068938, training accuracy: 0.9841052631578947\n","Val loss: 0.00048398261424154043, val accuracy: 0.9816666666666667\n","\n","==================================================\n","==> Finished Training! The best accuracy is 0.9833333333333333\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7POIS3_RQMpE","executionInfo":{"status":"ok","timestamp":1638375237750,"user_tz":300,"elapsed":2629,"user":{"displayName":"林子昊","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05325542234136368744"}},"outputId":"778863ca-a92b-4e6d-c07f-d57f3c7f347b"},"source":["test_model(\"StudentNetOri.pth\", \"student\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total examples is 10000, correct examples is 9857; Test accuracy: 0.9857\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n0TpijKBvHZS","executionInfo":{"status":"ok","timestamp":1638375947707,"user_tz":300,"elapsed":672630,"user":{"displayName":"林子昊","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05325542234136368744"}},"outputId":"41f11691-083a-4a30-d18d-ead598f03641"},"source":["StudentNet = StudentSimpleNN().to(device)\n","train_model(StudentNet, \"KDStudent\", train_loader, \"studentKD_alpha01.pth\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Now T is 1\n","==> Start training!\n","==================================================\n","Epoch 0\n","Training loss: 0.0007320089498534799, training accuracy: 0.7282456140350877\n","Val loss: 0.016094662249088287, val accuracy: 0.856\n","Saving ...\n","\n","Epoch 1\n","Training loss: 0.0004601279797498137, training accuracy: 0.8919122807017544\n","Val loss: 0.00945367943495512, val accuracy: 0.923\n","Saving ...\n","\n","Epoch 2\n","Training loss: 0.00014840307994745672, training accuracy: 0.9284035087719298\n","Val loss: 0.010069044306874275, val accuracy: 0.9413333333333334\n","Saving ...\n","\n","Epoch 3\n","Training loss: 0.0005979017587378621, training accuracy: 0.9401929824561404\n","Val loss: 0.009637534618377686, val accuracy: 0.9463333333333334\n","Saving ...\n","\n","Epoch 4\n","Training loss: 0.00011982600699411705, training accuracy: 0.9489122807017544\n","Val loss: 0.01147396769374609, val accuracy: 0.955\n","Saving ...\n","\n","Epoch 5\n","Training loss: 0.0001865160302259028, training accuracy: 0.9527543859649122\n","Val loss: 0.012406110763549805, val accuracy: 0.9563333333333334\n","Saving ...\n","\n","Epoch 6\n","Training loss: -5.174531906959601e-05, training accuracy: 0.9573508771929825\n","Val loss: 0.004283107817173004, val accuracy: 0.956\n","\n","Epoch 7\n","Training loss: -8.703169442014769e-05, training accuracy: 0.9595263157894737\n","Val loss: 0.0016497757751494646, val accuracy: 0.9656666666666667\n","Saving ...\n","\n","Epoch 8\n","Training loss: -4.917099431622773e-06, training accuracy: 0.9618771929824561\n","Val loss: 0.004161587450653315, val accuracy: 0.964\n","\n","Epoch 9\n","Training loss: 0.0002139612042810768, training accuracy: 0.9639649122807018\n","Val loss: 0.005839088466018438, val accuracy: 0.964\n","\n","Current learning rate has decayed to 0.0095\n","Epoch 10\n","Training loss: -9.942227916326374e-05, training accuracy: 0.9655964912280702\n","Val loss: 0.0022513559088110924, val accuracy: 0.968\n","Saving ...\n","\n","Epoch 11\n","Training loss: 4.901229203824187e-06, training accuracy: 0.9679649122807018\n","Val loss: 0.0016597271896898746, val accuracy: 0.9653333333333334\n","\n","Epoch 12\n","Training loss: -5.246667205938138e-05, training accuracy: 0.9672456140350877\n","Val loss: 0.002517451997846365, val accuracy: 0.9703333333333334\n","Saving ...\n","\n","Epoch 13\n","Training loss: -0.00010995468619512394, training accuracy: 0.9691754385964912\n","Val loss: 0.001990850083529949, val accuracy: 0.9713333333333334\n","Saving ...\n","\n","Epoch 14\n","Training loss: -4.722714584204368e-05, training accuracy: 0.969859649122807\n","Val loss: 0.006310399156063795, val accuracy: 0.9666666666666667\n","\n","Epoch 15\n","Training loss: -3.1462666811421514e-05, training accuracy: 0.9706842105263158\n","Val loss: 0.003626057645305991, val accuracy: 0.9716666666666667\n","Saving ...\n","\n","Epoch 16\n","Training loss: -0.0001903929514810443, training accuracy: 0.9712280701754386\n","Val loss: 0.00206303084269166, val accuracy: 0.9733333333333334\n","Saving ...\n","\n","Epoch 17\n","Training loss: -4.3668842408806086e-05, training accuracy: 0.9714912280701754\n","Val loss: 0.000585112429689616, val accuracy: 0.9716666666666667\n","\n","Epoch 18\n","Training loss: -0.00010183005360886455, training accuracy: 0.9728421052631578\n","Val loss: 0.0023848526179790497, val accuracy: 0.973\n","\n","Epoch 19\n","Training loss: 0.00018918525893241167, training accuracy: 0.9737368421052631\n","Val loss: 0.001428096555173397, val accuracy: 0.977\n","Saving ...\n","\n","Current learning rate has decayed to 0.009025\n","Epoch 20\n","Training loss: 0.00012171832349849865, training accuracy: 0.9746842105263158\n","Val loss: 0.001734214718453586, val accuracy: 0.9743333333333334\n","\n","Epoch 21\n","Training loss: -5.4332758736563846e-05, training accuracy: 0.974859649122807\n","Val loss: 0.0014252813998609781, val accuracy: 0.9743333333333334\n","\n","Epoch 22\n","Training loss: -0.00017839757492765784, training accuracy: 0.975421052631579\n","Val loss: 0.004624759778380394, val accuracy: 0.9786666666666667\n","Saving ...\n","\n","Epoch 23\n","Training loss: -9.943902841769159e-05, training accuracy: 0.9757719298245614\n","Val loss: 0.0072165485471487045, val accuracy: 0.9733333333333334\n","\n","Epoch 24\n","Training loss: 0.00024612125707790256, training accuracy: 0.9765789473684211\n","Val loss: 0.004096359945833683, val accuracy: 0.9776666666666667\n","\n","Epoch 25\n","Training loss: -0.00014006061246618629, training accuracy: 0.9767368421052631\n","Val loss: 0.0015111842658370733, val accuracy: 0.975\n","\n","Epoch 26\n","Training loss: -4.434159927768633e-05, training accuracy: 0.9766491228070175\n","Val loss: 0.003138633444905281, val accuracy: 0.9773333333333334\n","\n","Epoch 27\n","Training loss: -8.556149987271056e-05, training accuracy: 0.9766315789473684\n","Val loss: 0.003665017429739237, val accuracy: 0.978\n","\n","Epoch 28\n","Training loss: -0.00017083107377402484, training accuracy: 0.9784385964912281\n","Val loss: 0.006843585055321455, val accuracy: 0.9776666666666667\n","\n","Epoch 29\n","Training loss: -6.87502179061994e-05, training accuracy: 0.9771228070175438\n","Val loss: 0.004431187640875578, val accuracy: 0.98\n","Saving ...\n","\n","Current learning rate has decayed to 0.00857375\n","Epoch 30\n","Training loss: -4.913591328659095e-05, training accuracy: 0.9783684210526316\n","Val loss: 0.002213436644524336, val accuracy: 0.9786666666666667\n","\n","Epoch 31\n","Training loss: -3.488098082016222e-05, training accuracy: 0.9784561403508772\n","Val loss: 0.004601282998919487, val accuracy: 0.978\n","\n","Epoch 32\n","Training loss: -0.00015459935821127146, training accuracy: 0.9789649122807017\n","Val loss: 0.0013664982980117202, val accuracy: 0.9756666666666667\n","\n","Epoch 33\n","Training loss: -0.00021711918816436082, training accuracy: 0.9804736842105263\n","Val loss: 0.002415220020338893, val accuracy: 0.9786666666666667\n","\n","Epoch 34\n","Training loss: 0.00033802364487200975, training accuracy: 0.9802631578947368\n","Val loss: 0.0011016749776899815, val accuracy: 0.98\n","\n","Epoch 35\n","Training loss: -6.485191261162981e-05, training accuracy: 0.9790877192982456\n","Val loss: 0.006136344280093908, val accuracy: 0.9786666666666667\n","\n","Epoch 36\n","Training loss: 2.8316584575804882e-05, training accuracy: 0.979719298245614\n","Val loss: 0.008599613793194294, val accuracy: 0.9816666666666667\n","Saving ...\n","\n","Epoch 37\n","Training loss: 0.0001323812612099573, training accuracy: 0.9803859649122807\n","Val loss: 0.006320414133369923, val accuracy: 0.976\n","\n","Epoch 38\n","Training loss: -0.00010343224130338058, training accuracy: 0.9802982456140351\n","Val loss: 0.006739486940205097, val accuracy: 0.9723333333333334\n","\n","Epoch 39\n","Training loss: -7.45040233596228e-05, training accuracy: 0.9814912280701754\n","Val loss: 0.0015118870651349425, val accuracy: 0.9803333333333333\n","\n","Current learning rate has decayed to 0.0081450625\n","Epoch 40\n","Training loss: -5.4838648793520406e-05, training accuracy: 0.9811754385964913\n","Val loss: 0.0012667588889598846, val accuracy: 0.9776666666666667\n","\n","Epoch 41\n","Training loss: -0.0002103264123434201, training accuracy: 0.9810877192982456\n","Val loss: 0.001112394267693162, val accuracy: 0.9786666666666667\n","\n","Epoch 42\n","Training loss: -0.00020352669525891542, training accuracy: 0.9823157894736843\n","Val loss: 0.003951579798012972, val accuracy: 0.9796666666666667\n","\n","Epoch 43\n","Training loss: -0.00017815192404668778, training accuracy: 0.9821228070175438\n","Val loss: 0.00041880455682985485, val accuracy: 0.981\n","\n","Epoch 44\n","Training loss: -0.00015931998495943844, training accuracy: 0.9816491228070175\n","Val loss: 0.005730552598834038, val accuracy: 0.9776666666666667\n","\n","Epoch 45\n","Training loss: -0.00019550534489098936, training accuracy: 0.982140350877193\n","Val loss: 0.0014477737713605165, val accuracy: 0.9813333333333333\n","\n","Epoch 46\n","Training loss: -0.00019606668502092361, training accuracy: 0.9818070175438597\n","Val loss: 0.0028083319775760174, val accuracy: 0.9793333333333333\n","\n","Epoch 47\n","Training loss: -0.00021115434356033802, training accuracy: 0.9822982456140351\n","Val loss: 0.0017895549535751343, val accuracy: 0.979\n","\n","Epoch 48\n","Training loss: -7.416422158712521e-05, training accuracy: 0.9821929824561404\n","Val loss: 0.0020328820683062077, val accuracy: 0.984\n","Saving ...\n","\n","Epoch 49\n","Training loss: -4.8797748604556546e-05, training accuracy: 0.9822105263157894\n","Val loss: 0.005731615703552961, val accuracy: 0.9793333333333333\n","\n","Current learning rate has decayed to 0.007737809374999999\n","Epoch 50\n","Training loss: -0.00019374367548152804, training accuracy: 0.9837368421052631\n","Val loss: 0.0009819853585213423, val accuracy: 0.9806666666666667\n","\n","Epoch 51\n","Training loss: -0.00020321234478615224, training accuracy: 0.9831754385964913\n","Val loss: 0.0012852723011747003, val accuracy: 0.9796666666666667\n","\n","Epoch 52\n","Training loss: -0.00017600746650714427, training accuracy: 0.983578947368421\n","Val loss: 0.0013676350936293602, val accuracy: 0.981\n","\n","Epoch 53\n","Training loss: 0.00011845802509924397, training accuracy: 0.9828421052631579\n","Val loss: 0.000906703935470432, val accuracy: 0.9803333333333333\n","\n","Epoch 54\n","Training loss: -0.00014157622354105115, training accuracy: 0.9839824561403508\n","Val loss: 0.0025279023684561253, val accuracy: 0.9776666666666667\n","\n","Epoch 55\n","Training loss: 0.00019958053599111736, training accuracy: 0.9836666666666667\n","Val loss: 0.0030502513982355595, val accuracy: 0.9803333333333333\n","\n","Epoch 56\n","Training loss: -0.00020207524357829243, training accuracy: 0.9833333333333333\n","Val loss: 0.002162921242415905, val accuracy: 0.981\n","\n","Epoch 57\n","Training loss: -0.00015779839304741472, training accuracy: 0.9840877192982456\n","Val loss: 0.000975433737039566, val accuracy: 0.9796666666666667\n","\n","Epoch 58\n","Training loss: -8.825233089737594e-05, training accuracy: 0.9834385964912281\n","Val loss: 0.0004780596063937992, val accuracy: 0.98\n","\n","Epoch 59\n","Training loss: -0.00020278942247387022, training accuracy: 0.9847543859649123\n","Val loss: 0.007876097224652767, val accuracy: 0.9793333333333333\n","\n","==================================================\n","==> Finished Training! The best accuracy is 0.984\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ooixuf0XQTGn","executionInfo":{"status":"ok","timestamp":1638198767624,"user_tz":300,"elapsed":1958,"user":{"displayName":"林子昊","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05325542234136368744"}},"outputId":"522b2ddd-98a6-4246-c524-1ada7031c11d"},"source":["test_model(\"KDStudentNet.pth\", \"KDStudent\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total examples is 10000, correct examples is 9863; Test accuracy: 0.9863\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QFrOCHhkVKnC","executionInfo":{"status":"ok","timestamp":1638385333588,"user_tz":300,"elapsed":6028761,"user":{"displayName":"林子昊","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05325542234136368744"}},"outputId":"9a69fdc4-0497-4dc1-e474-c847e9afc8b6"},"source":["T_list = [20, 30, 40, 50, 60, 70, 80, 90, 100]  # 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9， 2, 3, 4, 5, 6, 7, 8, 9, 10\n","for T in T_list:\n","  StudentNet = StudentSimpleNN().to(device)\n","  model_name = \"T_\" + str(T) + \"_KDStudentNet.pth\"\n","  train_model(StudentNet, \"KDStudent\", train_loader, save_name = model_name)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Now T is 20\n","==> Start training!\n","==================================================\n","Epoch 0\n","Training loss: -0.21100632846355438, training accuracy: 0.722561403508772\n","Val loss: 0.024117683991789818, val accuracy: 0.8286666666666667\n","Saving ...\n","\n","Epoch 1\n","Training loss: -0.2115207463502884, training accuracy: 0.8778771929824561\n","Val loss: 0.018347488716244698, val accuracy: 0.9066666666666666\n","Saving ...\n","\n","Epoch 2\n","Training loss: -0.21266768872737885, training accuracy: 0.905719298245614\n","Val loss: 0.015518459491431713, val accuracy: 0.8956666666666667\n","\n","Epoch 3\n","Training loss: -0.21087253093719482, training accuracy: 0.9129122807017543\n","Val loss: 0.06547026336193085, val accuracy: 0.9213333333333333\n","Saving ...\n","\n","Epoch 4\n","Training loss: -0.21364814043045044, training accuracy: 0.9204561403508772\n","Val loss: 0.007759190164506435, val accuracy: 0.93\n","Saving ...\n","\n","Epoch 5\n","Training loss: -0.21441122889518738, training accuracy: 0.9274561403508772\n","Val loss: 0.012312270700931549, val accuracy: 0.9426666666666667\n","Saving ...\n","\n","Epoch 6\n","Training loss: -0.21579352021217346, training accuracy: 0.9344035087719298\n","Val loss: 0.06603416800498962, val accuracy: 0.944\n","Saving ...\n","\n","Epoch 7\n","Training loss: -0.21610873937606812, training accuracy: 0.9408245614035088\n","Val loss: 0.012149274349212646, val accuracy: 0.9503333333333334\n","Saving ...\n","\n","Epoch 8\n","Training loss: -0.21655972301959991, training accuracy: 0.9437368421052632\n","Val loss: 0.05652741715312004, val accuracy: 0.9453333333333334\n","\n","Epoch 9\n","Training loss: -0.21740023791790009, training accuracy: 0.9481754385964912\n","Val loss: 0.09052323549985886, val accuracy: 0.937\n","\n","Current learning rate has decayed to 0.0095\n","Epoch 10\n","Training loss: -0.21716788411140442, training accuracy: 0.9493859649122807\n","Val loss: 0.029489194974303246, val accuracy: 0.9496666666666667\n","\n","Epoch 11\n","Training loss: -0.2144627422094345, training accuracy: 0.9522982456140351\n","Val loss: 0.002960069803521037, val accuracy: 0.948\n","\n","Epoch 12\n","Training loss: -0.21391822397708893, training accuracy: 0.9545614035087719\n","Val loss: 0.05528172105550766, val accuracy: 0.9606666666666667\n","Saving ...\n","\n","Epoch 13\n","Training loss: -0.2172529101371765, training accuracy: 0.9571052631578948\n","Val loss: 0.007597602438181639, val accuracy: 0.9613333333333334\n","Saving ...\n","\n","Epoch 14\n","Training loss: -0.21733547747135162, training accuracy: 0.9570526315789474\n","Val loss: 0.00010396553989266977, val accuracy: 0.9603333333333334\n","\n","Epoch 15\n","Training loss: -0.21752849221229553, training accuracy: 0.9588421052631579\n","Val loss: 0.013197220861911774, val accuracy: 0.964\n","Saving ...\n","\n","Epoch 16\n","Training loss: -0.218080073595047, training accuracy: 0.9602280701754385\n","Val loss: 0.021155355498194695, val accuracy: 0.9583333333333334\n","\n","Epoch 17\n","Training loss: -0.2099871188402176, training accuracy: 0.9603157894736842\n","Val loss: 3.1542663236905355e-06, val accuracy: 0.958\n","\n","Epoch 18\n","Training loss: -0.21801137924194336, training accuracy: 0.9625087719298245\n","Val loss: 0.004565907642245293, val accuracy: 0.9626666666666667\n","\n","Epoch 19\n","Training loss: -0.21680140495300293, training accuracy: 0.9641052631578947\n","Val loss: 0.0465644896030426, val accuracy: 0.957\n","\n","Current learning rate has decayed to 0.009025\n","Epoch 20\n","Training loss: -0.21647658944129944, training accuracy: 0.9645789473684211\n","Val loss: 0.028767447918653488, val accuracy: 0.97\n","Saving ...\n","\n","Epoch 21\n","Training loss: -0.21706871688365936, training accuracy: 0.966280701754386\n","Val loss: 0.00783671997487545, val accuracy: 0.971\n","Saving ...\n","\n","Epoch 22\n","Training loss: -0.21769773960113525, training accuracy: 0.9665263157894737\n","Val loss: 0.1264459490776062, val accuracy: 0.9716666666666667\n","Saving ...\n","\n","Epoch 23\n","Training loss: -0.21792328357696533, training accuracy: 0.9669649122807018\n","Val loss: 0.006185030099004507, val accuracy: 0.97\n","\n","Epoch 24\n","Training loss: -0.21574218571186066, training accuracy: 0.9670526315789474\n","Val loss: 0.08185853064060211, val accuracy: 0.972\n","Saving ...\n","\n","Epoch 25\n","Training loss: -0.21807409822940826, training accuracy: 0.9678771929824561\n","Val loss: 0.12759748101234436, val accuracy: 0.9693333333333334\n","\n","Epoch 26\n","Training loss: -0.21753345429897308, training accuracy: 0.969561403508772\n","Val loss: 0.008925252594053745, val accuracy: 0.9693333333333334\n","\n","Epoch 27\n","Training loss: -0.21796752512454987, training accuracy: 0.97\n","Val loss: 4.147175786783919e-06, val accuracy: 0.968\n","\n","Epoch 28\n","Training loss: -0.21516945958137512, training accuracy: 0.9697719298245614\n","Val loss: 3.968813871324528e-06, val accuracy: 0.9683333333333334\n","\n","Epoch 29\n","Training loss: -0.21522721648216248, training accuracy: 0.9707894736842105\n","Val loss: 0.008112538605928421, val accuracy: 0.974\n","Saving ...\n","\n","Current learning rate has decayed to 0.00857375\n","Epoch 30\n","Training loss: -0.21820683777332306, training accuracy: 0.9722105263157895\n","Val loss: 0.07609617710113525, val accuracy: 0.9693333333333334\n","\n","Epoch 31\n","Training loss: -0.2160937339067459, training accuracy: 0.9722631578947368\n","Val loss: 0.06738786399364471, val accuracy: 0.9633333333333334\n","\n","Epoch 32\n","Training loss: -0.21668054163455963, training accuracy: 0.971561403508772\n","Val loss: 0.009065032936632633, val accuracy: 0.9713333333333334\n","\n","Epoch 33\n","Training loss: -0.2162780463695526, training accuracy: 0.9709122807017544\n","Val loss: 2.7979096557828598e-05, val accuracy: 0.9743333333333334\n","Saving ...\n","\n","Epoch 34\n","Training loss: -0.21758678555488586, training accuracy: 0.9726842105263158\n","Val loss: 0.00405013095587492, val accuracy: 0.9713333333333334\n","\n","Epoch 35\n","Training loss: -0.2173108458518982, training accuracy: 0.9735087719298245\n","Val loss: 0.0213733222335577, val accuracy: 0.974\n","\n","Epoch 36\n","Training loss: -0.21340122818946838, training accuracy: 0.9726140350877193\n","Val loss: 7.570557500002906e-05, val accuracy: 0.968\n","\n","Epoch 37\n","Training loss: -0.21821169555187225, training accuracy: 0.9738947368421053\n","Val loss: 0.09838881343603134, val accuracy: 0.9716666666666667\n","\n","Epoch 38\n","Training loss: -0.21829716861248016, training accuracy: 0.9742631578947368\n","Val loss: 2.474616245251582e-08, val accuracy: 0.9726666666666667\n","\n","Epoch 39\n","Training loss: -0.21820692718029022, training accuracy: 0.974859649122807\n","Val loss: 0.0632387101650238, val accuracy: 0.972\n","\n","Current learning rate has decayed to 0.0081450625\n","Epoch 40\n","Training loss: -0.21801412105560303, training accuracy: 0.9749824561403508\n","Val loss: 7.884973030058973e-08, val accuracy: 0.972\n","\n","Epoch 41\n","Training loss: -0.21762706339359283, training accuracy: 0.975701754385965\n","Val loss: 9.126459588060243e-08, val accuracy: 0.9723333333333334\n","\n","Epoch 42\n","Training loss: -0.21762482821941376, training accuracy: 0.9750175438596491\n","Val loss: 0.04265410825610161, val accuracy: 0.9693333333333334\n","\n","Epoch 43\n","Training loss: -0.2185726761817932, training accuracy: 0.9757719298245614\n","Val loss: 0.012194493785500526, val accuracy: 0.9726666666666667\n","\n","Epoch 44\n","Training loss: -0.21804337203502655, training accuracy: 0.9754385964912281\n","Val loss: 5.5199110647663474e-05, val accuracy: 0.9736666666666667\n","\n","Epoch 45\n","Training loss: -0.21627593040466309, training accuracy: 0.9757543859649123\n","Val loss: 0.009307848289608955, val accuracy: 0.9806666666666667\n","Saving ...\n","\n","Epoch 46\n","Training loss: -0.2180870771408081, training accuracy: 0.976280701754386\n","Val loss: 0.1108851358294487, val accuracy: 0.978\n","\n","Epoch 47\n","Training loss: -0.21452753245830536, training accuracy: 0.9754736842105263\n","Val loss: 2.9180871052858492e-08, val accuracy: 0.9756666666666667\n","\n","Epoch 48\n","Training loss: -0.21766358613967896, training accuracy: 0.9752280701754386\n","Val loss: 0.004463091026991606, val accuracy: 0.979\n","\n","Epoch 49\n","Training loss: -0.2176865190267563, training accuracy: 0.9776491228070175\n","Val loss: 0.020162533968687057, val accuracy: 0.9736666666666667\n","\n","Current learning rate has decayed to 0.007737809374999999\n","Epoch 50\n","Training loss: -0.2165328562259674, training accuracy: 0.9779649122807017\n","Val loss: 0.006157690193504095, val accuracy: 0.9733333333333334\n","\n","Epoch 51\n","Training loss: -0.2181742787361145, training accuracy: 0.9776315789473684\n","Val loss: 0.01667162775993347, val accuracy: 0.9773333333333334\n","\n","Epoch 52\n","Training loss: -0.21723707020282745, training accuracy: 0.9775438596491228\n","Val loss: 0.01451845746487379, val accuracy: 0.9766666666666667\n","\n","Epoch 53\n","Training loss: -0.21818985044956207, training accuracy: 0.9777719298245614\n","Val loss: 0.003849304746836424, val accuracy: 0.9783333333333334\n","\n","Epoch 54\n","Training loss: -0.2182978242635727, training accuracy: 0.9769824561403508\n","Val loss: 0.032408855855464935, val accuracy: 0.9726666666666667\n","\n","Epoch 55\n","Training loss: -0.21823036670684814, training accuracy: 0.9789824561403508\n","Val loss: 0.02804177813231945, val accuracy: 0.977\n","\n","Epoch 56\n","Training loss: -0.2182846963405609, training accuracy: 0.9785438596491228\n","Val loss: 0.04319050535559654, val accuracy: 0.9756666666666667\n","\n","Epoch 57\n","Training loss: -0.21768181025981903, training accuracy: 0.978859649122807\n","Val loss: 0.06331593543291092, val accuracy: 0.9776666666666667\n","\n","Epoch 58\n","Training loss: -0.21758350729942322, training accuracy: 0.9779298245614035\n","Val loss: 5.515883003681665e-06, val accuracy: 0.9776666666666667\n","\n","Epoch 59\n","Training loss: -0.21811796724796295, training accuracy: 0.9784912280701754\n","Val loss: 0.05781921371817589, val accuracy: 0.977\n","\n","==================================================\n","==> Finished Training! The best accuracy is 0.9806666666666667\n","Now T is 30\n","==> Start training!\n","==================================================\n","Epoch 0\n","Training loss: -0.4803308844566345, training accuracy: 0.7243333333333334\n","Val loss: 0.01971263810992241, val accuracy: 0.8456666666666667\n","Saving ...\n","\n","Epoch 1\n","Training loss: -0.4808565378189087, training accuracy: 0.8802631578947369\n","Val loss: 0.03461094945669174, val accuracy: 0.8996666666666666\n","Saving ...\n","\n","Epoch 2\n","Training loss: -0.481594979763031, training accuracy: 0.9094210526315789\n","Val loss: 0.011652878485620022, val accuracy: 0.9213333333333333\n","Saving ...\n","\n","Epoch 3\n","Training loss: -0.48174336552619934, training accuracy: 0.9163333333333333\n","Val loss: 0.010913862846791744, val accuracy: 0.9063333333333333\n","\n","Epoch 4\n","Training loss: -0.4843854606151581, training accuracy: 0.9194035087719298\n","Val loss: 0.01854458637535572, val accuracy: 0.9246666666666666\n","Saving ...\n","\n","Epoch 5\n","Training loss: -0.4851973354816437, training accuracy: 0.9219298245614035\n","Val loss: 0.10649129748344421, val accuracy: 0.934\n","Saving ...\n","\n","Epoch 6\n","Training loss: -0.4847835600376129, training accuracy: 0.9284210526315789\n","Val loss: 0.018739577382802963, val accuracy: 0.9256666666666666\n","\n","Epoch 7\n","Training loss: -0.4844822883605957, training accuracy: 0.9338070175438596\n","Val loss: 0.04113004356622696, val accuracy: 0.9393333333333334\n","Saving ...\n","\n","Epoch 8\n","Training loss: -0.48514941334724426, training accuracy: 0.9408596491228071\n","Val loss: 0.10811679065227509, val accuracy: 0.9493333333333334\n","Saving ...\n","\n","Epoch 9\n","Training loss: -0.4860824644565582, training accuracy: 0.9437192982456141\n","Val loss: 0.133403480052948, val accuracy: 0.9463333333333334\n","\n","Current learning rate has decayed to 0.0095\n","Epoch 10\n","Training loss: -0.4831496477127075, training accuracy: 0.9471929824561404\n","Val loss: 0.05927605181932449, val accuracy: 0.9463333333333334\n","\n","Epoch 11\n","Training loss: -0.48637834191322327, training accuracy: 0.9496140350877192\n","Val loss: 0.07101455330848694, val accuracy: 0.954\n","Saving ...\n","\n","Epoch 12\n","Training loss: -0.4877544045448303, training accuracy: 0.9531754385964912\n","Val loss: 0.0030628968961536884, val accuracy: 0.9593333333333334\n","Saving ...\n","\n","Epoch 13\n","Training loss: -0.48993995785713196, training accuracy: 0.955859649122807\n","Val loss: 0.010994328185915947, val accuracy: 0.9626666666666667\n","Saving ...\n","\n","Epoch 14\n","Training loss: -0.4855559468269348, training accuracy: 0.9564561403508772\n","Val loss: 0.1483069807291031, val accuracy: 0.952\n","\n","Epoch 15\n","Training loss: -0.4878329336643219, training accuracy: 0.958421052631579\n","Val loss: 0.025998923927545547, val accuracy: 0.9583333333333334\n","\n","Epoch 16\n","Training loss: -0.48833850026130676, training accuracy: 0.9583333333333334\n","Val loss: 0.04216831177473068, val accuracy: 0.966\n","Saving ...\n","\n","Epoch 17\n","Training loss: -0.4814056158065796, training accuracy: 0.9603508771929825\n","Val loss: 0.036595456302165985, val accuracy: 0.9623333333333334\n","\n","Epoch 18\n","Training loss: -0.4876633882522583, training accuracy: 0.9622105263157895\n","Val loss: 0.03267053887248039, val accuracy: 0.9583333333333334\n","\n","Epoch 19\n","Training loss: -0.4878980219364166, training accuracy: 0.9603333333333334\n","Val loss: 0.016553057357668877, val accuracy: 0.9653333333333334\n","\n","Current learning rate has decayed to 0.009025\n","Epoch 20\n","Training loss: -0.48843806982040405, training accuracy: 0.9647543859649123\n","Val loss: 0.005955565255135298, val accuracy: 0.9633333333333334\n","\n","Epoch 21\n","Training loss: -0.4870127737522125, training accuracy: 0.9623508771929824\n","Val loss: 0.03932485729455948, val accuracy: 0.962\n","\n","Epoch 22\n","Training loss: -0.4836438000202179, training accuracy: 0.9647543859649123\n","Val loss: 9.756708774233402e-10, val accuracy: 0.9656666666666667\n","\n","Epoch 23\n","Training loss: -0.490055650472641, training accuracy: 0.965561403508772\n","Val loss: 0.0002242195187136531, val accuracy: 0.968\n","Saving ...\n","\n","Epoch 24\n","Training loss: -0.48744645714759827, training accuracy: 0.966842105263158\n","Val loss: 0.011749602854251862, val accuracy: 0.969\n","Saving ...\n","\n","Epoch 25\n","Training loss: -0.48580294847488403, training accuracy: 0.9666842105263158\n","Val loss: 0.02871331200003624, val accuracy: 0.9666666666666667\n","\n","Epoch 26\n","Training loss: -0.48628297448158264, training accuracy: 0.9676842105263158\n","Val loss: 0.03596854582428932, val accuracy: 0.9616666666666667\n","\n","Epoch 27\n","Training loss: -0.48828834295272827, training accuracy: 0.9676842105263158\n","Val loss: 0.05056754872202873, val accuracy: 0.9666666666666667\n","\n","Epoch 28\n","Training loss: -0.4873292148113251, training accuracy: 0.9685789473684211\n","Val loss: 0.006320897024124861, val accuracy: 0.967\n","\n","Epoch 29\n","Training loss: -0.4900926351547241, training accuracy: 0.9687894736842105\n","Val loss: 0.06418134272098541, val accuracy: 0.9713333333333334\n","Saving ...\n","\n","Current learning rate has decayed to 0.00857375\n","Epoch 30\n","Training loss: -0.4869163930416107, training accuracy: 0.9699473684210527\n","Val loss: 0.03848157823085785, val accuracy: 0.9713333333333334\n","\n","Epoch 31\n","Training loss: -0.4850633144378662, training accuracy: 0.9700350877192983\n","Val loss: 0.007099553477019072, val accuracy: 0.9696666666666667\n","\n","Epoch 32\n","Training loss: -0.49073341488838196, training accuracy: 0.9705789473684211\n","Val loss: 0.0278725977987051, val accuracy: 0.9763333333333334\n","Saving ...\n","\n","Epoch 33\n","Training loss: -0.48959487676620483, training accuracy: 0.971701754385965\n","Val loss: 5.593508467427455e-05, val accuracy: 0.9713333333333334\n","\n","Epoch 34\n","Training loss: -0.48226380348205566, training accuracy: 0.9720877192982457\n","Val loss: 0.0016819760203361511, val accuracy: 0.967\n","\n","Epoch 35\n","Training loss: -0.4900303781032562, training accuracy: 0.9713333333333334\n","Val loss: 0.04840504750609398, val accuracy: 0.972\n","\n","Epoch 36\n","Training loss: -0.4878707230091095, training accuracy: 0.9728245614035088\n","Val loss: 0.07217100262641907, val accuracy: 0.9726666666666667\n","\n","Epoch 37\n","Training loss: -0.4905543625354767, training accuracy: 0.9736140350877193\n","Val loss: 0.11462973058223724, val accuracy: 0.9726666666666667\n","\n","Epoch 38\n","Training loss: -0.4862440526485443, training accuracy: 0.9728070175438597\n","Val loss: 0.029273850843310356, val accuracy: 0.9736666666666667\n","\n","Epoch 39\n","Training loss: -0.4848564863204956, training accuracy: 0.9725789473684211\n","Val loss: 0.01113553624600172, val accuracy: 0.9753333333333334\n","\n","Current learning rate has decayed to 0.0081450625\n","Epoch 40\n","Training loss: -0.4886760413646698, training accuracy: 0.9750526315789474\n","Val loss: 0.01648743450641632, val accuracy: 0.975\n","\n","Epoch 41\n","Training loss: -0.4867337942123413, training accuracy: 0.9740350877192983\n","Val loss: 0.08520247042179108, val accuracy: 0.9683333333333334\n","\n","Epoch 42\n","Training loss: -0.48994508385658264, training accuracy: 0.9745263157894737\n","Val loss: 1.6061733276728773e-06, val accuracy: 0.9766666666666667\n","Saving ...\n","\n","Epoch 43\n","Training loss: -0.4879356026649475, training accuracy: 0.9749824561403508\n","Val loss: 0.0, val accuracy: 0.9733333333333334\n","\n","Epoch 44\n","Training loss: -0.4903542697429657, training accuracy: 0.9749824561403508\n","Val loss: 0.039329688996076584, val accuracy: 0.9763333333333334\n","\n","Epoch 45\n","Training loss: -0.49023544788360596, training accuracy: 0.9755263157894737\n","Val loss: 0.009900734759867191, val accuracy: 0.9756666666666667\n","\n","Epoch 46\n","Training loss: -0.48966705799102783, training accuracy: 0.9753333333333334\n","Val loss: 7.627642162333359e-08, val accuracy: 0.9753333333333334\n","\n","Epoch 47\n","Training loss: -0.4888780117034912, training accuracy: 0.9757719298245614\n","Val loss: 0.0, val accuracy: 0.9793333333333333\n","Saving ...\n","\n","Epoch 48\n","Training loss: -0.49027618765830994, training accuracy: 0.9770175438596491\n","Val loss: 8.230948878917843e-05, val accuracy: 0.976\n","\n","Epoch 49\n","Training loss: -0.4903974235057831, training accuracy: 0.976859649122807\n","Val loss: 5.394508093559125e-07, val accuracy: 0.9716666666666667\n","\n","Current learning rate has decayed to 0.007737809374999999\n","Epoch 50\n","Training loss: -0.4855731129646301, training accuracy: 0.9764561403508772\n","Val loss: 0.030734945088624954, val accuracy: 0.973\n","\n","Epoch 51\n","Training loss: -0.4900365471839905, training accuracy: 0.9768245614035088\n","Val loss: 6.412552977508312e-08, val accuracy: 0.976\n","\n","Epoch 52\n","Training loss: -0.4868009090423584, training accuracy: 0.9770526315789474\n","Val loss: 0.07674853503704071, val accuracy: 0.9756666666666667\n","\n","Epoch 53\n","Training loss: -0.48769354820251465, training accuracy: 0.977421052631579\n","Val loss: 0.0, val accuracy: 0.978\n","\n","Epoch 54\n","Training loss: -0.4847579002380371, training accuracy: 0.9771052631578947\n","Val loss: 0.036095455288887024, val accuracy: 0.977\n","\n","Epoch 55\n","Training loss: -0.49094274640083313, training accuracy: 0.9782280701754386\n","Val loss: 0.01174379512667656, val accuracy: 0.9776666666666667\n","\n","Epoch 56\n","Training loss: -0.48496460914611816, training accuracy: 0.9778421052631578\n","Val loss: 0.058365993201732635, val accuracy: 0.9696666666666667\n","\n","Epoch 57\n","Training loss: -0.4882373809814453, training accuracy: 0.9778070175438597\n","Val loss: 0.005316497758030891, val accuracy: 0.9746666666666667\n","\n","Epoch 58\n","Training loss: -0.4903780519962311, training accuracy: 0.9780350877192983\n","Val loss: 0.028414450585842133, val accuracy: 0.9733333333333334\n","\n","Epoch 59\n","Training loss: -0.48955026268959045, training accuracy: 0.9784035087719298\n","Val loss: 0.001346640638075769, val accuracy: 0.975\n","\n","==================================================\n","==> Finished Training! The best accuracy is 0.9793333333333333\n","Now T is 40\n","==> Start training!\n","==================================================\n","Epoch 0\n","Training loss: -0.8574724793434143, training accuracy: 0.7253508771929824\n","Val loss: 0.008834004402160645, val accuracy: 0.851\n","Saving ...\n","\n","Epoch 1\n","Training loss: -0.858024001121521, training accuracy: 0.8780877192982456\n","Val loss: 0.017427299171686172, val accuracy: 0.9\n","Saving ...\n","\n","Epoch 2\n","Training loss: -0.8581139445304871, training accuracy: 0.9085087719298246\n","Val loss: 0.018501313403248787, val accuracy: 0.918\n","Saving ...\n","\n","Epoch 3\n","Training loss: -0.8592319488525391, training accuracy: 0.916859649122807\n","Val loss: 0.013964207842946053, val accuracy: 0.9026666666666666\n","\n","Epoch 4\n","Training loss: -0.8602458834648132, training accuracy: 0.9181052631578948\n","Val loss: 0.07904346287250519, val accuracy: 0.921\n","Saving ...\n","\n","Epoch 5\n","Training loss: -0.861020028591156, training accuracy: 0.9200701754385965\n","Val loss: 0.025594253093004227, val accuracy: 0.9273333333333333\n","Saving ...\n","\n","Epoch 6\n","Training loss: -0.8584805727005005, training accuracy: 0.9267368421052632\n","Val loss: 0.038938768208026886, val accuracy: 0.9273333333333333\n","\n","Epoch 7\n","Training loss: -0.8617501854896545, training accuracy: 0.9302807017543859\n","Val loss: 0.058831773698329926, val accuracy: 0.944\n","Saving ...\n","\n","Epoch 8\n","Training loss: -0.8669299483299255, training accuracy: 0.9370175438596491\n","Val loss: 0.03827924281358719, val accuracy: 0.9403333333333334\n","\n","Epoch 9\n","Training loss: -0.8663144111633301, training accuracy: 0.9404736842105264\n","Val loss: 0.10472919791936874, val accuracy: 0.9403333333333334\n","\n","Current learning rate has decayed to 0.0095\n","Epoch 10\n","Training loss: -0.8652854561805725, training accuracy: 0.9452105263157895\n","Val loss: 0.13051575422286987, val accuracy: 0.9506666666666667\n","Saving ...\n","\n","Epoch 11\n","Training loss: -0.8594937324523926, training accuracy: 0.9483333333333334\n","Val loss: 0.04963571950793266, val accuracy: 0.9453333333333334\n","\n","Epoch 12\n","Training loss: -0.8693783283233643, training accuracy: 0.9491929824561404\n","Val loss: 0.10299761593341827, val accuracy: 0.9563333333333334\n","Saving ...\n","\n","Epoch 13\n","Training loss: -0.859085738658905, training accuracy: 0.9513508771929825\n","Val loss: 0.04121307656168938, val accuracy: 0.9633333333333334\n","Saving ...\n","\n","Epoch 14\n","Training loss: -0.8677360415458679, training accuracy: 0.9545087719298245\n","Val loss: 1.3482211898008245e-06, val accuracy: 0.9606666666666667\n","\n","Epoch 15\n","Training loss: -0.8657230138778687, training accuracy: 0.9557894736842105\n","Val loss: 0.18046599626541138, val accuracy: 0.9566666666666667\n","\n","Epoch 16\n","Training loss: -0.8691058158874512, training accuracy: 0.9573859649122807\n","Val loss: 0.05621569603681564, val accuracy: 0.963\n","\n","Epoch 17\n","Training loss: -0.8676296472549438, training accuracy: 0.9589298245614035\n","Val loss: 0.011962054297327995, val accuracy: 0.9536666666666667\n","\n","Epoch 18\n","Training loss: -0.8674572110176086, training accuracy: 0.96\n","Val loss: 2.1287342999443126e-09, val accuracy: 0.9616666666666667\n","\n","Epoch 19\n","Training loss: -0.8677716851234436, training accuracy: 0.9619473684210527\n","Val loss: 0.01082785427570343, val accuracy: 0.9673333333333334\n","Saving ...\n","\n","Current learning rate has decayed to 0.009025\n","Epoch 20\n","Training loss: -0.8678677082061768, training accuracy: 0.9625263157894737\n","Val loss: 0.1268971711397171, val accuracy: 0.9556666666666667\n","\n","Epoch 21\n","Training loss: -0.8689394593238831, training accuracy: 0.9634561403508772\n","Val loss: 0.04125554859638214, val accuracy: 0.971\n","Saving ...\n","\n","Epoch 22\n","Training loss: -0.8695292472839355, training accuracy: 0.9637543859649123\n","Val loss: 0.00544153805822134, val accuracy: 0.9626666666666667\n","\n","Epoch 23\n","Training loss: -0.8690659403800964, training accuracy: 0.965140350877193\n","Val loss: 0.00028925700462423265, val accuracy: 0.9663333333333334\n","\n","Epoch 24\n","Training loss: -0.8664748668670654, training accuracy: 0.9655789473684211\n","Val loss: 0.1611700803041458, val accuracy: 0.969\n","\n","Epoch 25\n","Training loss: -0.8676671981811523, training accuracy: 0.966842105263158\n","Val loss: 3.237391865695827e-08, val accuracy: 0.9626666666666667\n","\n","Epoch 26\n","Training loss: -0.8691529631614685, training accuracy: 0.9667368421052631\n","Val loss: 0.01350092887878418, val accuracy: 0.9616666666666667\n","\n","Epoch 27\n","Training loss: -0.8658879399299622, training accuracy: 0.9676140350877193\n","Val loss: 0.04132360219955444, val accuracy: 0.9683333333333334\n","\n","Epoch 28\n","Training loss: -0.8685079216957092, training accuracy: 0.9678771929824561\n","Val loss: 0.002198029775172472, val accuracy: 0.968\n","\n","Epoch 29\n","Training loss: -0.8695648312568665, training accuracy: 0.9679473684210527\n","Val loss: 0.0010582210961729288, val accuracy: 0.969\n","\n","Current learning rate has decayed to 0.00857375\n","Epoch 30\n","Training loss: -0.8681179285049438, training accuracy: 0.9693508771929824\n","Val loss: 0.07987025380134583, val accuracy: 0.97\n","\n","Epoch 31\n","Training loss: -0.8672863245010376, training accuracy: 0.9696666666666667\n","Val loss: 0.00941307470202446, val accuracy: 0.9733333333333334\n","Saving ...\n","\n","Epoch 32\n","Training loss: -0.869805634021759, training accuracy: 0.9706315789473684\n","Val loss: 0.2379572093486786, val accuracy: 0.9723333333333334\n","\n","Epoch 33\n","Training loss: -0.8648316860198975, training accuracy: 0.9711052631578947\n","Val loss: 0.01794780232012272, val accuracy: 0.9723333333333334\n","\n","Epoch 34\n","Training loss: -0.8695192933082581, training accuracy: 0.9701228070175438\n","Val loss: 0.00040893207187764347, val accuracy: 0.9723333333333334\n","\n","Epoch 35\n","Training loss: -0.8695676922798157, training accuracy: 0.9706491228070175\n","Val loss: 0.017836207523941994, val accuracy: 0.9703333333333334\n","\n","Epoch 36\n","Training loss: -0.8694421648979187, training accuracy: 0.9709824561403508\n","Val loss: 0.021906768903136253, val accuracy: 0.9733333333333334\n","\n","Epoch 37\n","Training loss: -0.8664950132369995, training accuracy: 0.9728421052631578\n","Val loss: 0.013056786730885506, val accuracy: 0.976\n","Saving ...\n","\n","Epoch 38\n","Training loss: -0.8704550266265869, training accuracy: 0.9731052631578947\n","Val loss: 0.18094611167907715, val accuracy: 0.977\n","Saving ...\n","\n","Epoch 39\n","Training loss: -0.8693382143974304, training accuracy: 0.9728421052631578\n","Val loss: 0.006572991143912077, val accuracy: 0.9726666666666667\n","\n","Current learning rate has decayed to 0.0081450625\n","Epoch 40\n","Training loss: -0.8695101141929626, training accuracy: 0.9732280701754386\n","Val loss: 0.17585377395153046, val accuracy: 0.972\n","\n","Epoch 41\n","Training loss: -0.8588084578514099, training accuracy: 0.9734912280701754\n","Val loss: 0.021085217595100403, val accuracy: 0.971\n","\n","Epoch 42\n","Training loss: -0.8583595752716064, training accuracy: 0.9729122807017544\n","Val loss: 0.0, val accuracy: 0.976\n","\n","Epoch 43\n","Training loss: -0.8664886951446533, training accuracy: 0.974719298245614\n","Val loss: 0.05626211315393448, val accuracy: 0.9693333333333334\n","\n","Epoch 44\n","Training loss: -0.8686196804046631, training accuracy: 0.9745789473684211\n","Val loss: 0.07135887444019318, val accuracy: 0.9756666666666667\n","\n","Epoch 45\n","Training loss: -0.8700523376464844, training accuracy: 0.9754385964912281\n","Val loss: 0.06795097142457962, val accuracy: 0.9733333333333334\n","\n","Epoch 46\n","Training loss: -0.8701640367507935, training accuracy: 0.9741228070175438\n","Val loss: 0.0, val accuracy: 0.9763333333333334\n","\n","Epoch 47\n","Training loss: -0.8700283765792847, training accuracy: 0.974859649122807\n","Val loss: 0.06729193031787872, val accuracy: 0.9753333333333334\n","\n","Epoch 48\n","Training loss: -0.8703881502151489, training accuracy: 0.9757368421052631\n","Val loss: 2.72660918199108e-06, val accuracy: 0.9783333333333334\n","Saving ...\n","\n","Epoch 49\n","Training loss: -0.870570957660675, training accuracy: 0.9760526315789474\n","Val loss: 0.024136371910572052, val accuracy: 0.976\n","\n","Current learning rate has decayed to 0.007737809374999999\n","Epoch 50\n","Training loss: -0.8702208995819092, training accuracy: 0.9755789473684211\n","Val loss: 1.1728964182111667e-06, val accuracy: 0.972\n","\n","Epoch 51\n","Training loss: -0.8697137236595154, training accuracy: 0.9763333333333334\n","Val loss: 0.031601645052433014, val accuracy: 0.979\n","Saving ...\n","\n","Epoch 52\n","Training loss: -0.8698851466178894, training accuracy: 0.9762456140350877\n","Val loss: 8.86973827718407e-11, val accuracy: 0.972\n","\n","Epoch 53\n","Training loss: -0.8665945529937744, training accuracy: 0.9773859649122807\n","Val loss: 0.033255260437726974, val accuracy: 0.9736666666666667\n","\n","Epoch 54\n","Training loss: -0.8615146279335022, training accuracy: 0.9775438596491228\n","Val loss: 0.10377386212348938, val accuracy: 0.9753333333333334\n","\n","Epoch 55\n","Training loss: -0.870743453502655, training accuracy: 0.9769649122807017\n","Val loss: 0.12235691398382187, val accuracy: 0.9726666666666667\n","\n","Epoch 56\n","Training loss: -0.8675438165664673, training accuracy: 0.9776315789473684\n","Val loss: 0.016516447067260742, val accuracy: 0.9793333333333333\n","Saving ...\n","\n","Epoch 57\n","Training loss: -0.8705241680145264, training accuracy: 0.9766842105263158\n","Val loss: 0.08431964367628098, val accuracy: 0.9763333333333334\n","\n","Epoch 58\n","Training loss: -0.8681639432907104, training accuracy: 0.9766140350877193\n","Val loss: 0.004688604269176722, val accuracy: 0.975\n","\n","Epoch 59\n","Training loss: -0.861943244934082, training accuracy: 0.9785438596491228\n","Val loss: 0.040790632367134094, val accuracy: 0.9763333333333334\n","\n","==================================================\n","==> Finished Training! The best accuracy is 0.9793333333333333\n","Now T is 50\n","==> Start training!\n","==================================================\n","Epoch 0\n","Training loss: -1.3417681455612183, training accuracy: 0.7221578947368421\n","Val loss: 0.012231300584971905, val accuracy: 0.8326666666666667\n","Saving ...\n","\n","Epoch 1\n","Training loss: -1.342653512954712, training accuracy: 0.8786315789473684\n","Val loss: 0.018073193728923798, val accuracy: 0.9076666666666666\n","Saving ...\n","\n","Epoch 2\n","Training loss: -1.344151496887207, training accuracy: 0.9099824561403509\n","Val loss: 0.003024386242032051, val accuracy: 0.9256666666666666\n","Saving ...\n","\n","Epoch 3\n","Training loss: -1.3445380926132202, training accuracy: 0.9184912280701755\n","Val loss: 0.008770668879151344, val accuracy: 0.916\n","\n","Epoch 4\n","Training loss: -1.3444572687149048, training accuracy: 0.9189649122807018\n","Val loss: 0.008618999272584915, val accuracy: 0.9196666666666666\n","\n","Epoch 5\n","Training loss: -1.3462421894073486, training accuracy: 0.9191578947368421\n","Val loss: 0.0434240847826004, val accuracy: 0.9246666666666666\n","\n","Epoch 6\n","Training loss: -1.3455020189285278, training accuracy: 0.9221228070175439\n","Val loss: 0.020527906715869904, val accuracy: 0.9296666666666666\n","Saving ...\n","\n","Epoch 7\n","Training loss: -1.347245454788208, training accuracy: 0.9280175438596491\n","Val loss: 0.009864727035164833, val accuracy: 0.935\n","Saving ...\n","\n","Epoch 8\n","Training loss: -1.3491555452346802, training accuracy: 0.9308070175438596\n","Val loss: 0.03780573606491089, val accuracy: 0.9456666666666667\n","Saving ...\n","\n","Epoch 9\n","Training loss: -1.3544286489486694, training accuracy: 0.9386842105263158\n","Val loss: 0.15764747560024261, val accuracy: 0.9403333333333334\n","\n","Current learning rate has decayed to 0.0095\n","Epoch 10\n","Training loss: -1.3477433919906616, training accuracy: 0.9426842105263158\n","Val loss: 0.08986707031726837, val accuracy: 0.947\n","Saving ...\n","\n","Epoch 11\n","Training loss: -1.3469287157058716, training accuracy: 0.9451754385964912\n","Val loss: 0.06405593454837799, val accuracy: 0.942\n","\n","Epoch 12\n","Training loss: -1.3526725769042969, training accuracy: 0.9478070175438597\n","Val loss: 0.1635400354862213, val accuracy: 0.9493333333333334\n","Saving ...\n","\n","Epoch 13\n","Training loss: -1.3463668823242188, training accuracy: 0.9515789473684211\n","Val loss: 0.08734225481748581, val accuracy: 0.9496666666666667\n","Saving ...\n","\n","Epoch 14\n","Training loss: -1.355384349822998, training accuracy: 0.952859649122807\n","Val loss: 0.10307568311691284, val accuracy: 0.9566666666666667\n","Saving ...\n","\n","Epoch 15\n","Training loss: -1.351763367652893, training accuracy: 0.9548947368421052\n","Val loss: 0.1117103099822998, val accuracy: 0.959\n","Saving ...\n","\n","Epoch 16\n","Training loss: -1.3548041582107544, training accuracy: 0.9561754385964912\n","Val loss: 0.055710405111312866, val accuracy: 0.9596666666666667\n","Saving ...\n","\n","Epoch 17\n","Training loss: -1.3518650531768799, training accuracy: 0.9571754385964912\n","Val loss: 0.0, val accuracy: 0.9586666666666667\n","\n","Epoch 18\n","Training loss: -1.3567214012145996, training accuracy: 0.9611754385964912\n","Val loss: 0.08501917123794556, val accuracy: 0.9603333333333334\n","Saving ...\n","\n","Epoch 19\n","Training loss: -1.3500685691833496, training accuracy: 0.9596666666666667\n","Val loss: 0.05219786614179611, val accuracy: 0.9586666666666667\n","\n","Current learning rate has decayed to 0.009025\n","Epoch 20\n","Training loss: -1.3572577238082886, training accuracy: 0.9618771929824561\n","Val loss: 0.3425707221031189, val accuracy: 0.964\n","Saving ...\n","\n","Epoch 21\n","Training loss: -1.3493764400482178, training accuracy: 0.9636842105263158\n","Val loss: 0.062021031975746155, val accuracy: 0.964\n","\n","Epoch 22\n","Training loss: -1.3480311632156372, training accuracy: 0.963561403508772\n","Val loss: 0.03665272146463394, val accuracy: 0.965\n","Saving ...\n","\n","Epoch 23\n","Training loss: -1.355168342590332, training accuracy: 0.9647719298245614\n","Val loss: 0.0887678861618042, val accuracy: 0.9713333333333334\n","Saving ...\n","\n","Epoch 24\n","Training loss: -1.3520499467849731, training accuracy: 0.9642982456140351\n","Val loss: 0.0883544534444809, val accuracy: 0.9676666666666667\n","\n","Epoch 25\n","Training loss: -1.357237458229065, training accuracy: 0.9637368421052631\n","Val loss: 0.1535802185535431, val accuracy: 0.9706666666666667\n","\n","Epoch 26\n","Training loss: -1.357209324836731, training accuracy: 0.966561403508772\n","Val loss: 0.18049387633800507, val accuracy: 0.9566666666666667\n","\n","Epoch 27\n","Training loss: -1.351805567741394, training accuracy: 0.9675438596491228\n","Val loss: 0.011944839730858803, val accuracy: 0.9666666666666667\n","\n","Epoch 28\n","Training loss: -1.355784296989441, training accuracy: 0.9673508771929824\n","Val loss: 2.217431349649246e-09, val accuracy: 0.97\n","\n","Epoch 29\n","Training loss: -1.3575555086135864, training accuracy: 0.9676666666666667\n","Val loss: 0.0, val accuracy: 0.9663333333333334\n","\n","Current learning rate has decayed to 0.00857375\n","Epoch 30\n","Training loss: -1.3582289218902588, training accuracy: 0.9693333333333334\n","Val loss: 0.10323436558246613, val accuracy: 0.9693333333333334\n","\n","Epoch 31\n","Training loss: -1.3519254922866821, training accuracy: 0.9687719298245614\n","Val loss: 0.021651074290275574, val accuracy: 0.9696666666666667\n","\n","Epoch 32\n","Training loss: -1.3540757894515991, training accuracy: 0.9700175438596491\n","Val loss: 0.05940879136323929, val accuracy: 0.9683333333333334\n","\n","Epoch 33\n","Training loss: -1.3567674160003662, training accuracy: 0.9712456140350877\n","Val loss: 0.10653188824653625, val accuracy: 0.9703333333333334\n","\n","Epoch 34\n","Training loss: -1.3529536724090576, training accuracy: 0.9702280701754386\n","Val loss: 0.021554358303546906, val accuracy: 0.9706666666666667\n","\n","Epoch 35\n","Training loss: -1.3503901958465576, training accuracy: 0.9711929824561404\n","Val loss: 0.2003009170293808, val accuracy: 0.9673333333333334\n","\n","Epoch 36\n","Training loss: -1.3512625694274902, training accuracy: 0.9721228070175438\n","Val loss: 0.06400766968727112, val accuracy: 0.9683333333333334\n","\n","Epoch 37\n","Training loss: -1.3546255826950073, training accuracy: 0.9723684210526315\n","Val loss: 0.10377566516399384, val accuracy: 0.9643333333333334\n","\n","Epoch 38\n","Training loss: -1.3578027486801147, training accuracy: 0.9731929824561404\n","Val loss: 0.14299799501895905, val accuracy: 0.973\n","Saving ...\n","\n","Epoch 39\n","Training loss: -1.3550995588302612, training accuracy: 0.9728245614035088\n","Val loss: 0.07809213548898697, val accuracy: 0.973\n","\n","Current learning rate has decayed to 0.0081450625\n","Epoch 40\n","Training loss: -1.3574601411819458, training accuracy: 0.9727368421052631\n","Val loss: 0.02875334583222866, val accuracy: 0.9726666666666667\n","\n","Epoch 41\n","Training loss: -1.3516764640808105, training accuracy: 0.9738245614035088\n","Val loss: 0.06722036749124527, val accuracy: 0.9736666666666667\n","Saving ...\n","\n","Epoch 42\n","Training loss: -1.3577545881271362, training accuracy: 0.9740175438596491\n","Val loss: 0.25301408767700195, val accuracy: 0.9716666666666667\n","\n","Epoch 43\n","Training loss: -1.3570045232772827, training accuracy: 0.9746491228070175\n","Val loss: 0.04611353576183319, val accuracy: 0.9716666666666667\n","\n","Epoch 44\n","Training loss: -1.3583829402923584, training accuracy: 0.9736842105263158\n","Val loss: 0.0, val accuracy: 0.978\n","Saving ...\n","\n","Epoch 45\n","Training loss: -1.3583303689956665, training accuracy: 0.9755438596491228\n","Val loss: 0.013661541044712067, val accuracy: 0.9763333333333334\n","\n","Epoch 46\n","Training loss: -1.3535674810409546, training accuracy: 0.9754035087719298\n","Val loss: 0.04265040159225464, val accuracy: 0.9753333333333334\n","\n","Epoch 47\n","Training loss: -1.3535630702972412, training accuracy: 0.9755964912280701\n","Val loss: 0.0398966483771801, val accuracy: 0.9766666666666667\n","\n","Epoch 48\n","Training loss: -1.3577189445495605, training accuracy: 0.9754736842105263\n","Val loss: 0.05699053406715393, val accuracy: 0.9723333333333334\n","\n","Epoch 49\n","Training loss: -1.3493000268936157, training accuracy: 0.9749122807017544\n","Val loss: 0.027852460741996765, val accuracy: 0.9763333333333334\n","\n","Current learning rate has decayed to 0.007737809374999999\n","Epoch 50\n","Training loss: -1.3546109199523926, training accuracy: 0.9757368421052631\n","Val loss: 0.0, val accuracy: 0.975\n","\n","Epoch 51\n","Training loss: -1.3579825162887573, training accuracy: 0.9766315789473684\n","Val loss: 0.01264660432934761, val accuracy: 0.973\n","\n","Epoch 52\n","Training loss: -1.355354905128479, training accuracy: 0.9761052631578947\n","Val loss: 0.007662729360163212, val accuracy: 0.9746666666666667\n","\n","Epoch 53\n","Training loss: -1.3547431230545044, training accuracy: 0.9765789473684211\n","Val loss: 0.21862487494945526, val accuracy: 0.9753333333333334\n","\n","Epoch 54\n","Training loss: -1.3542611598968506, training accuracy: 0.9759824561403508\n","Val loss: 0.3167882263660431, val accuracy: 0.971\n","\n","Epoch 55\n","Training loss: -1.3564180135726929, training accuracy: 0.976719298245614\n","Val loss: 0.059445545077323914, val accuracy: 0.9743333333333334\n","\n","Epoch 56\n","Training loss: -1.3578280210494995, training accuracy: 0.9773157894736842\n","Val loss: 3.5478950333178716e-10, val accuracy: 0.977\n","\n","Epoch 57\n","Training loss: -1.357471227645874, training accuracy: 0.9777368421052631\n","Val loss: 0.014926288276910782, val accuracy: 0.9783333333333334\n","Saving ...\n","\n","Epoch 58\n","Training loss: -1.3568382263183594, training accuracy: 0.9773684210526316\n","Val loss: 0.03673553094267845, val accuracy: 0.9803333333333333\n","Saving ...\n","\n","Epoch 59\n","Training loss: -1.3545039892196655, training accuracy: 0.9770877192982456\n","Val loss: 0.2226489633321762, val accuracy: 0.9746666666666667\n","\n","==================================================\n","==> Finished Training! The best accuracy is 0.9803333333333333\n","Now T is 60\n","==> Start training!\n","==================================================\n","Epoch 0\n","Training loss: -1.933916687965393, training accuracy: 0.7216842105263158\n","Val loss: 0.018609602004289627, val accuracy: 0.8376666666666667\n","Saving ...\n","\n","Epoch 1\n","Training loss: -1.9357026815414429, training accuracy: 0.8801228070175439\n","Val loss: 0.004091533832252026, val accuracy: 0.895\n","Saving ...\n","\n","Epoch 2\n","Training loss: -1.934969186782837, training accuracy: 0.9107894736842105\n","Val loss: 0.008456061594188213, val accuracy: 0.9176666666666666\n","Saving ...\n","\n","Epoch 3\n","Training loss: -1.936563491821289, training accuracy: 0.9170350877192982\n","Val loss: 0.014428844675421715, val accuracy: 0.9286666666666666\n","Saving ...\n","\n","Epoch 4\n","Training loss: -1.9380934238433838, training accuracy: 0.9199298245614035\n","Val loss: 0.0032908697612583637, val accuracy: 0.9043333333333333\n","\n","Epoch 5\n","Training loss: -1.9380345344543457, training accuracy: 0.9206140350877193\n","Val loss: 0.016775570809841156, val accuracy: 0.932\n","Saving ...\n","\n","Epoch 6\n","Training loss: -1.9412446022033691, training accuracy: 0.9229122807017544\n","Val loss: 0.08684159815311432, val accuracy: 0.9156666666666666\n","\n","Epoch 7\n","Training loss: -1.935063362121582, training accuracy: 0.9244035087719298\n","Val loss: 0.008270727470517159, val accuracy: 0.934\n","Saving ...\n","\n","Epoch 8\n","Training loss: -1.9406269788742065, training accuracy: 0.9297719298245614\n","Val loss: 0.03877048194408417, val accuracy: 0.9343333333333333\n","Saving ...\n","\n","Epoch 9\n","Training loss: -1.9462366104125977, training accuracy: 0.9346666666666666\n","Val loss: 0.028563551604747772, val accuracy: 0.948\n","Saving ...\n","\n","Current learning rate has decayed to 0.0095\n","Epoch 10\n","Training loss: -1.9436126947402954, training accuracy: 0.9415964912280702\n","Val loss: 0.01953251287341118, val accuracy: 0.94\n","\n","Epoch 11\n","Training loss: -1.9399418830871582, training accuracy: 0.9447192982456141\n","Val loss: 0.08414031565189362, val accuracy: 0.928\n","\n","Epoch 12\n","Training loss: -1.9407280683517456, training accuracy: 0.9463508771929825\n","Val loss: 0.05839323252439499, val accuracy: 0.954\n","Saving ...\n","\n","Epoch 13\n","Training loss: -1.9476032257080078, training accuracy: 0.95\n","Val loss: 0.0013682912103831768, val accuracy: 0.941\n","\n","Epoch 14\n","Training loss: -1.9478825330734253, training accuracy: 0.9509298245614035\n","Val loss: 0.029278088361024857, val accuracy: 0.9486666666666667\n","\n","Epoch 15\n","Training loss: -1.9471837282180786, training accuracy: 0.9545614035087719\n","Val loss: 0.0, val accuracy: 0.9573333333333334\n","Saving ...\n","\n","Epoch 16\n","Training loss: -1.945778250694275, training accuracy: 0.9545614035087719\n","Val loss: 0.056326381862163544, val accuracy: 0.9543333333333334\n","\n","Epoch 17\n","Training loss: -1.9472532272338867, training accuracy: 0.959140350877193\n","Val loss: 0.10317926853895187, val accuracy: 0.9586666666666667\n","Saving ...\n","\n","Epoch 18\n","Training loss: -1.9478321075439453, training accuracy: 0.9587017543859649\n","Val loss: 0.05896497890353203, val accuracy: 0.9593333333333334\n","Saving ...\n","\n","Epoch 19\n","Training loss: -1.950610637664795, training accuracy: 0.9602456140350877\n","Val loss: 0.11770237982273102, val accuracy: 0.96\n","Saving ...\n","\n","Current learning rate has decayed to 0.009025\n","Epoch 20\n","Training loss: -1.9512676000595093, training accuracy: 0.9611929824561404\n","Val loss: 0.0, val accuracy: 0.9636666666666667\n","Saving ...\n","\n","Epoch 21\n","Training loss: -1.9451775550842285, training accuracy: 0.9621228070175438\n","Val loss: 0.020784901455044746, val accuracy: 0.9683333333333334\n","Saving ...\n","\n","Epoch 22\n","Training loss: -1.952478051185608, training accuracy: 0.9638947368421052\n","Val loss: 0.02714761719107628, val accuracy: 0.964\n","\n","Epoch 23\n","Training loss: -1.9466525316238403, training accuracy: 0.9639473684210527\n","Val loss: 0.04905372112989426, val accuracy: 0.9613333333333334\n","\n","Epoch 24\n","Training loss: -1.9484598636627197, training accuracy: 0.965\n","Val loss: 0.1065794974565506, val accuracy: 0.967\n","\n","Epoch 25\n","Training loss: -1.9464513063430786, training accuracy: 0.9648070175438597\n","Val loss: 0.1703394055366516, val accuracy: 0.9646666666666667\n","\n","Epoch 26\n","Training loss: -1.9405097961425781, training accuracy: 0.9662982456140351\n","Val loss: 2.2351450468249823e-08, val accuracy: 0.9663333333333334\n","\n","Epoch 27\n","Training loss: -1.9528840780258179, training accuracy: 0.9664035087719298\n","Val loss: 0.023788105696439743, val accuracy: 0.9703333333333334\n","Saving ...\n","\n","Epoch 28\n","Training loss: -1.943461298942566, training accuracy: 0.9668771929824561\n","Val loss: 0.10216980427503586, val accuracy: 0.9673333333333334\n","\n","Epoch 29\n","Training loss: -1.9445425271987915, training accuracy: 0.9687543859649123\n","Val loss: 0.015133361332118511, val accuracy: 0.9643333333333334\n","\n","Current learning rate has decayed to 0.00857375\n","Epoch 30\n","Training loss: -1.9521774053573608, training accuracy: 0.968701754385965\n","Val loss: 0.1269756555557251, val accuracy: 0.967\n","\n","Epoch 31\n","Training loss: -1.950326681137085, training accuracy: 0.9688070175438597\n","Val loss: 0.11922571063041687, val accuracy: 0.9633333333333334\n","\n","Epoch 32\n","Training loss: -1.951501727104187, training accuracy: 0.970859649122807\n","Val loss: 0.11400149762630463, val accuracy: 0.9633333333333334\n","\n","Epoch 33\n","Training loss: -1.9508198499679565, training accuracy: 0.9697543859649123\n","Val loss: 0.14163723587989807, val accuracy: 0.9663333333333334\n","\n","Epoch 34\n","Training loss: -1.9491758346557617, training accuracy: 0.9702982456140351\n","Val loss: 0.19941657781600952, val accuracy: 0.9683333333333334\n","\n","Epoch 35\n","Training loss: -1.9519352912902832, training accuracy: 0.9708245614035088\n","Val loss: 0.1451111137866974, val accuracy: 0.9706666666666667\n","Saving ...\n","\n","Epoch 36\n","Training loss: -1.9518399238586426, training accuracy: 0.9721929824561404\n","Val loss: 0.0, val accuracy: 0.9746666666666667\n","Saving ...\n","\n","Epoch 37\n","Training loss: -1.9521373510360718, training accuracy: 0.9712631578947368\n","Val loss: 0.08938981592655182, val accuracy: 0.9716666666666667\n","\n","Epoch 38\n","Training loss: -1.9500927925109863, training accuracy: 0.9731578947368421\n","Val loss: 0.12473887205123901, val accuracy: 0.966\n","\n","Epoch 39\n","Training loss: -1.9477497339248657, training accuracy: 0.9719122807017544\n","Val loss: 0.22822712361812592, val accuracy: 0.9656666666666667\n","\n","Current learning rate has decayed to 0.0081450625\n","Epoch 40\n","Training loss: -1.951340675354004, training accuracy: 0.973140350877193\n","Val loss: 0.005517079494893551, val accuracy: 0.963\n","\n","Epoch 41\n","Training loss: -1.9520646333694458, training accuracy: 0.9727543859649123\n","Val loss: 2.660921483155221e-10, val accuracy: 0.9713333333333334\n","\n","Epoch 42\n","Training loss: -1.9536384344100952, training accuracy: 0.9726315789473684\n","Val loss: 0.010610165074467659, val accuracy: 0.9703333333333334\n","\n","Epoch 43\n","Training loss: -1.9484997987747192, training accuracy: 0.9732982456140351\n","Val loss: 0.10518640279769897, val accuracy: 0.9736666666666667\n","\n","Epoch 44\n","Training loss: -1.9446500539779663, training accuracy: 0.9738771929824561\n","Val loss: 0.060299765318632126, val accuracy: 0.9703333333333334\n","\n","Epoch 45\n","Training loss: -1.9524918794631958, training accuracy: 0.9746666666666667\n","Val loss: 0.13887950778007507, val accuracy: 0.9723333333333334\n","\n","Epoch 46\n","Training loss: -1.947105050086975, training accuracy: 0.9743333333333334\n","Val loss: 0.08553524315357208, val accuracy: 0.9746666666666667\n","\n","Epoch 47\n","Training loss: -1.9488575458526611, training accuracy: 0.9753684210526316\n","Val loss: 0.06116882711648941, val accuracy: 0.9723333333333334\n","\n","Epoch 48\n","Training loss: -1.9497565031051636, training accuracy: 0.9754035087719298\n","Val loss: 0.11609822511672974, val accuracy: 0.9763333333333334\n","Saving ...\n","\n","Epoch 49\n","Training loss: -1.9526289701461792, training accuracy: 0.9748771929824561\n","Val loss: 0.021137282252311707, val accuracy: 0.9723333333333334\n","\n","Current learning rate has decayed to 0.007737809374999999\n","Epoch 50\n","Training loss: -1.952272891998291, training accuracy: 0.9767894736842105\n","Val loss: 0.008606556802988052, val accuracy: 0.9753333333333334\n","\n","Epoch 51\n","Training loss: -1.954184889793396, training accuracy: 0.9753684210526316\n","Val loss: 0.059252288192510605, val accuracy: 0.975\n","\n","Epoch 52\n","Training loss: -1.9462248086929321, training accuracy: 0.9770350877192983\n","Val loss: 0.0, val accuracy: 0.9786666666666667\n","Saving ...\n","\n","Epoch 53\n","Training loss: -1.9525659084320068, training accuracy: 0.976280701754386\n","Val loss: 0.0008200858719646931, val accuracy: 0.9743333333333334\n","\n","Epoch 54\n","Training loss: -1.951555848121643, training accuracy: 0.976421052631579\n","Val loss: 0.21764066815376282, val accuracy: 0.9773333333333334\n","\n","Epoch 55\n","Training loss: -1.9530707597732544, training accuracy: 0.9760701754385965\n","Val loss: 0.09625350683927536, val accuracy: 0.9793333333333333\n","Saving ...\n","\n","Epoch 56\n","Training loss: -1.9532451629638672, training accuracy: 0.977280701754386\n","Val loss: 0.0909523069858551, val accuracy: 0.9756666666666667\n","\n","Epoch 57\n","Training loss: -1.9541574716567993, training accuracy: 0.9770701754385965\n","Val loss: 4.445687409315724e-06, val accuracy: 0.9796666666666667\n","Saving ...\n","\n","Epoch 58\n","Training loss: -1.951168179512024, training accuracy: 0.9766315789473684\n","Val loss: 0.09745143353939056, val accuracy: 0.9736666666666667\n","\n","Epoch 59\n","Training loss: -1.953637957572937, training accuracy: 0.9780877192982456\n","Val loss: 0.001630811719223857, val accuracy: 0.9783333333333334\n","\n","==================================================\n","==> Finished Training! The best accuracy is 0.9796666666666667\n","Now T is 70\n","==> Start training!\n","==================================================\n","Epoch 0\n","Training loss: -2.634988784790039, training accuracy: 0.7278771929824561\n","Val loss: 0.03097379207611084, val accuracy: 0.844\n","Saving ...\n","\n","Epoch 1\n","Training loss: -2.6352920532226562, training accuracy: 0.8806140350877193\n","Val loss: 0.007818960584700108, val accuracy: 0.9093333333333333\n","Saving ...\n","\n","Epoch 2\n","Training loss: -2.6370022296905518, training accuracy: 0.9100877192982456\n","Val loss: 0.002822008915245533, val accuracy: 0.9193333333333333\n","Saving ...\n","\n","Epoch 3\n","Training loss: -2.6368250846862793, training accuracy: 0.9172631578947369\n","Val loss: 0.012068158946931362, val accuracy: 0.9196666666666666\n","Saving ...\n","\n","Epoch 4\n","Training loss: -2.6386992931365967, training accuracy: 0.9200701754385965\n","Val loss: 0.037247832864522934, val accuracy: 0.9253333333333333\n","Saving ...\n","\n","Epoch 5\n","Training loss: -2.6373777389526367, training accuracy: 0.9204912280701755\n","Val loss: 0.06953561305999756, val accuracy: 0.9173333333333333\n","\n","Epoch 6\n","Training loss: -2.636820077896118, training accuracy: 0.9231929824561403\n","Val loss: 0.04885275661945343, val accuracy: 0.935\n","Saving ...\n","\n","Epoch 7\n","Training loss: -2.6413674354553223, training accuracy: 0.9264035087719298\n","Val loss: 0.016434449702501297, val accuracy: 0.9366666666666666\n","Saving ...\n","\n","Epoch 8\n","Training loss: -2.646089553833008, training accuracy: 0.9286666666666666\n","Val loss: 0.008228855207562447, val accuracy: 0.9396666666666667\n","Saving ...\n","\n","Epoch 9\n","Training loss: -2.6466283798217773, training accuracy: 0.9345263157894736\n","Val loss: 0.08015960454940796, val accuracy: 0.9276666666666666\n","\n","Current learning rate has decayed to 0.0095\n","Epoch 10\n","Training loss: -2.6438777446746826, training accuracy: 0.9400350877192982\n","Val loss: 0.025075431913137436, val accuracy: 0.94\n","Saving ...\n","\n","Epoch 11\n","Training loss: -2.6460154056549072, training accuracy: 0.9436315789473684\n","Val loss: 0.020293081179261208, val accuracy: 0.9486666666666667\n","Saving ...\n","\n","Epoch 12\n","Training loss: -2.630600929260254, training accuracy: 0.9455438596491228\n","Val loss: 0.09836946427822113, val accuracy: 0.9483333333333334\n","\n","Epoch 13\n","Training loss: -2.6515729427337646, training accuracy: 0.9504912280701754\n","Val loss: 0.038373347371816635, val accuracy: 0.951\n","Saving ...\n","\n","Epoch 14\n","Training loss: -2.6391007900238037, training accuracy: 0.9526491228070175\n","Val loss: 5.722161859011976e-06, val accuracy: 0.954\n","Saving ...\n","\n","Epoch 15\n","Training loss: -2.6406166553497314, training accuracy: 0.9539824561403509\n","Val loss: 0.00047133045154623687, val accuracy: 0.957\n","Saving ...\n","\n","Epoch 16\n","Training loss: -2.6530513763427734, training accuracy: 0.9556140350877192\n","Val loss: 0.15783649682998657, val accuracy: 0.959\n","Saving ...\n","\n","Epoch 17\n","Training loss: -2.638594627380371, training accuracy: 0.9561228070175438\n","Val loss: 0.12037595361471176, val accuracy: 0.9596666666666667\n","Saving ...\n","\n","Epoch 18\n","Training loss: -2.651059150695801, training accuracy: 0.9576315789473684\n","Val loss: 0.08436132967472076, val accuracy: 0.9583333333333334\n","\n","Epoch 19\n","Training loss: -2.654529571533203, training accuracy: 0.9588421052631579\n","Val loss: 0.08932171761989594, val accuracy: 0.9623333333333334\n","Saving ...\n","\n","Current learning rate has decayed to 0.009025\n","Epoch 20\n","Training loss: -2.648658514022827, training accuracy: 0.9609473684210527\n","Val loss: 0.03906123340129852, val accuracy: 0.9663333333333334\n","Saving ...\n","\n","Epoch 21\n","Training loss: -2.655601739883423, training accuracy: 0.9621754385964912\n","Val loss: 0.15521873533725739, val accuracy: 0.962\n","\n","Epoch 22\n","Training loss: -2.6528003215789795, training accuracy: 0.962859649122807\n","Val loss: 0.022462476044893265, val accuracy: 0.9573333333333334\n","\n","Epoch 23\n","Training loss: -2.649278163909912, training accuracy: 0.9634035087719298\n","Val loss: 0.11093039810657501, val accuracy: 0.964\n","\n","Epoch 24\n","Training loss: -2.647550106048584, training accuracy: 0.9652105263157895\n","Val loss: 0.04133269935846329, val accuracy: 0.965\n","\n","Epoch 25\n","Training loss: -2.6529147624969482, training accuracy: 0.9647894736842105\n","Val loss: 0.13280285894870758, val accuracy: 0.9623333333333334\n","\n","Epoch 26\n","Training loss: -2.655930995941162, training accuracy: 0.9665789473684211\n","Val loss: 0.032213736325502396, val accuracy: 0.9706666666666667\n","Saving ...\n","\n","Epoch 27\n","Training loss: -2.647526502609253, training accuracy: 0.9672105263157895\n","Val loss: 6.862899226689478e-07, val accuracy: 0.9716666666666667\n","Saving ...\n","\n","Epoch 28\n","Training loss: -2.6497838497161865, training accuracy: 0.9663508771929824\n","Val loss: 0.20941683650016785, val accuracy: 0.973\n","Saving ...\n","\n","Epoch 29\n","Training loss: -2.6528263092041016, training accuracy: 0.9672105263157895\n","Val loss: 3.5478950333178716e-10, val accuracy: 0.972\n","\n","Current learning rate has decayed to 0.00857375\n","Epoch 30\n","Training loss: -2.6429553031921387, training accuracy: 0.9672456140350877\n","Val loss: 0.0, val accuracy: 0.964\n","\n","Epoch 31\n","Training loss: -2.6559605598449707, training accuracy: 0.9684561403508772\n","Val loss: 0.06535429507493973, val accuracy: 0.9723333333333334\n","\n","Epoch 32\n","Training loss: -2.6484534740448, training accuracy: 0.9697894736842105\n","Val loss: 0.040468428283929825, val accuracy: 0.9673333333333334\n","\n","Epoch 33\n","Training loss: -2.6493895053863525, training accuracy: 0.9700350877192983\n","Val loss: 0.2229214757680893, val accuracy: 0.9663333333333334\n","\n","Epoch 34\n","Training loss: -2.651475429534912, training accuracy: 0.9686315789473684\n","Val loss: 0.0008861339883878827, val accuracy: 0.9733333333333334\n","Saving ...\n","\n","Epoch 35\n","Training loss: -2.655461072921753, training accuracy: 0.9706491228070175\n","Val loss: 0.06618981808423996, val accuracy: 0.971\n","\n","Epoch 36\n","Training loss: -2.651792287826538, training accuracy: 0.9722105263157895\n","Val loss: 0.00168487464543432, val accuracy: 0.973\n","\n","Epoch 37\n","Training loss: -2.651116132736206, training accuracy: 0.9717894736842105\n","Val loss: 0.08553792536258698, val accuracy: 0.967\n","\n","Epoch 38\n","Training loss: -2.6559271812438965, training accuracy: 0.9713333333333334\n","Val loss: 6.767407967345207e-08, val accuracy: 0.9716666666666667\n","\n","Epoch 39\n","Training loss: -2.649928569793701, training accuracy: 0.9720350877192983\n","Val loss: 0.008260693401098251, val accuracy: 0.9746666666666667\n","Saving ...\n","\n","Current learning rate has decayed to 0.0081450625\n","Epoch 40\n","Training loss: -2.6496920585632324, training accuracy: 0.9722631578947368\n","Val loss: 0.13032764196395874, val accuracy: 0.977\n","Saving ...\n","\n","Epoch 41\n","Training loss: -2.6556272506713867, training accuracy: 0.9730701754385965\n","Val loss: 0.0, val accuracy: 0.9716666666666667\n","\n","Epoch 42\n","Training loss: -2.6551077365875244, training accuracy: 0.9732456140350877\n","Val loss: 0.00022265191364567727, val accuracy: 0.9793333333333333\n","Saving ...\n","\n","Epoch 43\n","Training loss: -2.654143810272217, training accuracy: 0.9731228070175438\n","Val loss: 0.02176060900092125, val accuracy: 0.9726666666666667\n","\n","Epoch 44\n","Training loss: -2.6492538452148438, training accuracy: 0.9739122807017544\n","Val loss: 0.0858471542596817, val accuracy: 0.9756666666666667\n","\n","Epoch 45\n","Training loss: -2.652384042739868, training accuracy: 0.9740526315789474\n","Val loss: 0.09038980305194855, val accuracy: 0.976\n","\n","Epoch 46\n","Training loss: -2.646928071975708, training accuracy: 0.9741228070175438\n","Val loss: 0.011706783436238766, val accuracy: 0.9746666666666667\n","\n","Epoch 47\n","Training loss: -2.6561439037323, training accuracy: 0.9741754385964912\n","Val loss: 0.012729205191135406, val accuracy: 0.973\n","\n","Epoch 48\n","Training loss: -2.6546452045440674, training accuracy: 0.9743508771929824\n","Val loss: 0.0, val accuracy: 0.9776666666666667\n","\n","Epoch 49\n","Training loss: -2.654383659362793, training accuracy: 0.9756491228070175\n","Val loss: 0.07966307550668716, val accuracy: 0.972\n","\n","Current learning rate has decayed to 0.007737809374999999\n","Epoch 50\n","Training loss: -2.6453123092651367, training accuracy: 0.9769824561403508\n","Val loss: 0.0012020415160804987, val accuracy: 0.9743333333333334\n","\n","Epoch 51\n","Training loss: -2.6532363891601562, training accuracy: 0.9748421052631578\n","Val loss: 0.012591294012963772, val accuracy: 0.9723333333333334\n","\n","Epoch 52\n","Training loss: -2.651432752609253, training accuracy: 0.9757719298245614\n","Val loss: 0.01259051077067852, val accuracy: 0.9696666666666667\n","\n","Epoch 53\n","Training loss: -2.6555702686309814, training accuracy: 0.976561403508772\n","Val loss: 0.2550399899482727, val accuracy: 0.966\n","\n","Epoch 54\n","Training loss: -2.651258945465088, training accuracy: 0.9761754385964913\n","Val loss: 0.0, val accuracy: 0.9766666666666667\n","\n","Epoch 55\n","Training loss: -2.6552467346191406, training accuracy: 0.9770526315789474\n","Val loss: 0.0, val accuracy: 0.9803333333333333\n","Saving ...\n","\n","Epoch 56\n","Training loss: -2.6544885635375977, training accuracy: 0.9770175438596491\n","Val loss: 0.021078310906887054, val accuracy: 0.9763333333333334\n","\n","Epoch 57\n","Training loss: -2.6572158336639404, training accuracy: 0.9768771929824561\n","Val loss: 0.21779096126556396, val accuracy: 0.9706666666666667\n","\n","Epoch 58\n","Training loss: -2.6539647579193115, training accuracy: 0.9767543859649123\n","Val loss: 0.46258223056793213, val accuracy: 0.9763333333333334\n","\n","Epoch 59\n","Training loss: -2.6431725025177, training accuracy: 0.9779298245614035\n","Val loss: 0.0720965787768364, val accuracy: 0.978\n","\n","==================================================\n","==> Finished Training! The best accuracy is 0.9803333333333333\n","Now T is 80\n","==> Start training!\n","==================================================\n","Epoch 0\n","Training loss: -3.4431216716766357, training accuracy: 0.7235789473684211\n","Val loss: 0.021043209359049797, val accuracy: 0.8336666666666667\n","Saving ...\n","\n","Epoch 1\n","Training loss: -3.4439542293548584, training accuracy: 0.882438596491228\n","Val loss: 0.018718436360359192, val accuracy: 0.9093333333333333\n","Saving ...\n","\n","Epoch 2\n","Training loss: -3.4446568489074707, training accuracy: 0.9100877192982456\n","Val loss: 0.007769656367599964, val accuracy: 0.9086666666666666\n","\n","Epoch 3\n","Training loss: -3.4426140785217285, training accuracy: 0.9167017543859649\n","Val loss: 0.004147842526435852, val accuracy: 0.9243333333333333\n","Saving ...\n","\n","Epoch 4\n","Training loss: -3.4466543197631836, training accuracy: 0.9205263157894736\n","Val loss: 0.012120465748012066, val accuracy: 0.9196666666666666\n","\n","Epoch 5\n","Training loss: -3.4477579593658447, training accuracy: 0.9209824561403509\n","Val loss: 0.018429603427648544, val accuracy: 0.93\n","Saving ...\n","\n","Epoch 6\n","Training loss: -3.4484634399414062, training accuracy: 0.9220701754385965\n","Val loss: 0.02860632911324501, val accuracy: 0.9303333333333333\n","Saving ...\n","\n","Epoch 7\n","Training loss: -3.450087547302246, training accuracy: 0.922\n","Val loss: 0.08864527940750122, val accuracy: 0.92\n","\n","Epoch 8\n","Training loss: -3.44942307472229, training accuracy: 0.9275964912280702\n","Val loss: 0.003368990495800972, val accuracy: 0.922\n","\n","Epoch 9\n","Training loss: -3.457339286804199, training accuracy: 0.9317719298245614\n","Val loss: 0.11345404386520386, val accuracy: 0.9336666666666666\n","Saving ...\n","\n","Current learning rate has decayed to 0.0095\n","Epoch 10\n","Training loss: -3.459143877029419, training accuracy: 0.9374736842105263\n","Val loss: 0.14752712845802307, val accuracy: 0.9226666666666666\n","\n","Epoch 11\n","Training loss: -3.4614739418029785, training accuracy: 0.9411929824561404\n","Val loss: 0.12759211659431458, val accuracy: 0.942\n","Saving ...\n","\n","Epoch 12\n","Training loss: -3.4589884281158447, training accuracy: 0.9450526315789474\n","Val loss: 0.026510139927268028, val accuracy: 0.941\n","\n","Epoch 13\n","Training loss: -3.463177442550659, training accuracy: 0.9486666666666667\n","Val loss: 0.0633794441819191, val accuracy: 0.9463333333333334\n","Saving ...\n","\n","Epoch 14\n","Training loss: -3.4620065689086914, training accuracy: 0.9509824561403509\n","Val loss: 0.004584208130836487, val accuracy: 0.9533333333333334\n","Saving ...\n","\n","Epoch 15\n","Training loss: -3.4575071334838867, training accuracy: 0.9530526315789474\n","Val loss: 0.19846270978450775, val accuracy: 0.9516666666666667\n","\n","Epoch 16\n","Training loss: -3.4490110874176025, training accuracy: 0.9545964912280702\n","Val loss: 8.86973827718407e-11, val accuracy: 0.9586666666666667\n","Saving ...\n","\n","Epoch 17\n","Training loss: -3.4642462730407715, training accuracy: 0.9569298245614035\n","Val loss: 0.11426542699337006, val accuracy: 0.9566666666666667\n","\n","Epoch 18\n","Training loss: -3.4577794075012207, training accuracy: 0.9574035087719298\n","Val loss: 0.22541972994804382, val accuracy: 0.9516666666666667\n","\n","Epoch 19\n","Training loss: -3.4644346237182617, training accuracy: 0.9580877192982457\n","Val loss: 0.037061989307403564, val accuracy: 0.9523333333333334\n","\n","Current learning rate has decayed to 0.009025\n","Epoch 20\n","Training loss: -3.458225965499878, training accuracy: 0.9615263157894737\n","Val loss: 0.0684473067522049, val accuracy: 0.959\n","Saving ...\n","\n","Epoch 21\n","Training loss: -3.461033821105957, training accuracy: 0.9617368421052631\n","Val loss: 0.00022709944460075349, val accuracy: 0.9643333333333334\n","Saving ...\n","\n","Epoch 22\n","Training loss: -3.464512586593628, training accuracy: 0.9620877192982457\n","Val loss: 0.04141990840435028, val accuracy: 0.9623333333333334\n","\n","Epoch 23\n","Training loss: -3.456996202468872, training accuracy: 0.9625438596491228\n","Val loss: 0.024108467623591423, val accuracy: 0.966\n","Saving ...\n","\n","Epoch 24\n","Training loss: -3.4597880840301514, training accuracy: 0.9640526315789474\n","Val loss: 0.10323744267225266, val accuracy: 0.964\n","\n","Epoch 25\n","Training loss: -3.465595245361328, training accuracy: 0.9629298245614035\n","Val loss: 0.01744541898369789, val accuracy: 0.9556666666666667\n","\n","Epoch 26\n","Training loss: -3.464165687561035, training accuracy: 0.964561403508772\n","Val loss: 0.06422358751296997, val accuracy: 0.961\n","\n","Epoch 27\n","Training loss: -3.4600565433502197, training accuracy: 0.9659122807017544\n","Val loss: 0.0014629906509071589, val accuracy: 0.9666666666666667\n","Saving ...\n","\n","Epoch 28\n","Training loss: -3.4676711559295654, training accuracy: 0.965859649122807\n","Val loss: 0.33438199758529663, val accuracy: 0.9666666666666667\n","\n","Epoch 29\n","Training loss: -3.4622082710266113, training accuracy: 0.9672631578947368\n","Val loss: 0.08459960669279099, val accuracy: 0.9666666666666667\n","\n","Current learning rate has decayed to 0.00857375\n","Epoch 30\n","Training loss: -3.464655637741089, training accuracy: 0.9685263157894737\n","Val loss: 0.03568389266729355, val accuracy: 0.967\n","Saving ...\n","\n","Epoch 31\n","Training loss: -3.4550180435180664, training accuracy: 0.9677719298245614\n","Val loss: 0.006340780761092901, val accuracy: 0.969\n","Saving ...\n","\n","Epoch 32\n","Training loss: -3.464118242263794, training accuracy: 0.9681052631578947\n","Val loss: 0.0693659782409668, val accuracy: 0.969\n","\n","Epoch 33\n","Training loss: -3.4668469429016113, training accuracy: 0.9697368421052631\n","Val loss: 0.0, val accuracy: 0.9753333333333334\n","Saving ...\n","\n","Epoch 34\n","Training loss: -3.461242914199829, training accuracy: 0.9704561403508772\n","Val loss: 0.14203041791915894, val accuracy: 0.966\n","\n","Epoch 35\n","Training loss: -3.467600107192993, training accuracy: 0.9713684210526315\n","Val loss: 0.010517149232327938, val accuracy: 0.9693333333333334\n","\n","Epoch 36\n","Training loss: -3.459660530090332, training accuracy: 0.9699824561403508\n","Val loss: 0.0444016307592392, val accuracy: 0.9656666666666667\n","\n","Epoch 37\n","Training loss: -3.4561593532562256, training accuracy: 0.9706491228070175\n","Val loss: 0.0009660417563281953, val accuracy: 0.972\n","\n","Epoch 38\n","Training loss: -3.466888666152954, training accuracy: 0.9711228070175438\n","Val loss: 0.15225262939929962, val accuracy: 0.971\n","\n","Epoch 39\n","Training loss: -3.4649369716644287, training accuracy: 0.9725438596491228\n","Val loss: 0.520561158657074, val accuracy: 0.971\n","\n","Current learning rate has decayed to 0.0081450625\n","Epoch 40\n","Training loss: -3.466055393218994, training accuracy: 0.9726842105263158\n","Val loss: 0.1287112981081009, val accuracy: 0.9756666666666667\n","Saving ...\n","\n","Epoch 41\n","Training loss: -3.46262526512146, training accuracy: 0.9724912280701754\n","Val loss: 0.1298573613166809, val accuracy: 0.9703333333333334\n","\n","Epoch 42\n","Training loss: -3.4648993015289307, training accuracy: 0.9733508771929824\n","Val loss: 0.23115873336791992, val accuracy: 0.9696666666666667\n","\n","Epoch 43\n","Training loss: -3.4597976207733154, training accuracy: 0.9736842105263158\n","Val loss: 1.951339978489841e-09, val accuracy: 0.9756666666666667\n","\n","Epoch 44\n","Training loss: -3.4667418003082275, training accuracy: 0.972859649122807\n","Val loss: 0.0, val accuracy: 0.9706666666666667\n","\n","Epoch 45\n","Training loss: -3.4594814777374268, training accuracy: 0.9742982456140351\n","Val loss: 0.007765473797917366, val accuracy: 0.9723333333333334\n","\n","Epoch 46\n","Training loss: -3.4657957553863525, training accuracy: 0.9738421052631578\n","Val loss: 0.06658119708299637, val accuracy: 0.9726666666666667\n","\n","Epoch 47\n","Training loss: -3.465703010559082, training accuracy: 0.9738245614035088\n","Val loss: 0.15251372754573822, val accuracy: 0.966\n","\n","Epoch 48\n","Training loss: -3.4649393558502197, training accuracy: 0.9747368421052631\n","Val loss: 0.049758076667785645, val accuracy: 0.9736666666666667\n","\n","Epoch 49\n","Training loss: -3.4559621810913086, training accuracy: 0.9756315789473684\n","Val loss: 0.22349035739898682, val accuracy: 0.968\n","\n","Current learning rate has decayed to 0.007737809374999999\n","Epoch 50\n","Training loss: -3.4601283073425293, training accuracy: 0.9759473684210527\n","Val loss: 0.05360376462340355, val accuracy: 0.9756666666666667\n","\n","Epoch 51\n","Training loss: -3.462769031524658, training accuracy: 0.975859649122807\n","Val loss: 0.048735734075307846, val accuracy: 0.9736666666666667\n","\n","Epoch 52\n","Training loss: -3.4647388458251953, training accuracy: 0.9761052631578947\n","Val loss: 0.04110322892665863, val accuracy: 0.9773333333333334\n","Saving ...\n","\n","Epoch 53\n","Training loss: -3.4657504558563232, training accuracy: 0.9762280701754386\n","Val loss: 0.13244600594043732, val accuracy: 0.9746666666666667\n","\n","Epoch 54\n","Training loss: -3.466853618621826, training accuracy: 0.976\n","Val loss: 0.17823468148708344, val accuracy: 0.976\n","\n","Epoch 55\n","Training loss: -3.462345600128174, training accuracy: 0.9766491228070175\n","Val loss: 0.08437348902225494, val accuracy: 0.9793333333333333\n","Saving ...\n","\n","Epoch 56\n","Training loss: -3.466884136199951, training accuracy: 0.9764561403508772\n","Val loss: 0.19317659735679626, val accuracy: 0.9756666666666667\n","\n","Epoch 57\n","Training loss: -3.466078281402588, training accuracy: 0.9766842105263158\n","Val loss: 0.28953924775123596, val accuracy: 0.9766666666666667\n","\n","Epoch 58\n","Training loss: -3.4627270698547363, training accuracy: 0.9764561403508772\n","Val loss: 0.05575636029243469, val accuracy: 0.972\n","\n","Epoch 59\n","Training loss: -3.467928171157837, training accuracy: 0.9770877192982456\n","Val loss: 0.07823766767978668, val accuracy: 0.9746666666666667\n","\n","==================================================\n","==> Finished Training! The best accuracy is 0.9793333333333333\n","Now T is 90\n","==> Start training!\n","==================================================\n","Epoch 0\n","Training loss: -4.359305381774902, training accuracy: 0.7267543859649123\n","Val loss: 0.01323691662400961, val accuracy: 0.8593333333333333\n","Saving ...\n","\n","Epoch 1\n","Training loss: -4.360090732574463, training accuracy: 0.8826666666666667\n","Val loss: 0.021040156483650208, val accuracy: 0.9116666666666666\n","Saving ...\n","\n","Epoch 2\n","Training loss: -4.3608856201171875, training accuracy: 0.9119824561403509\n","Val loss: 0.0074085937812924385, val accuracy: 0.9306666666666666\n","Saving ...\n","\n","Epoch 3\n","Training loss: -4.360877513885498, training accuracy: 0.9177543859649123\n","Val loss: 0.009612467139959335, val accuracy: 0.919\n","\n","Epoch 4\n","Training loss: -4.361527442932129, training accuracy: 0.920859649122807\n","Val loss: 0.08901913464069366, val accuracy: 0.9133333333333333\n","\n","Epoch 5\n","Training loss: -4.362577438354492, training accuracy: 0.9212807017543859\n","Val loss: 0.005856414325535297, val accuracy: 0.919\n","\n","Epoch 6\n","Training loss: -4.362595081329346, training accuracy: 0.9214912280701755\n","Val loss: 0.06276434659957886, val accuracy: 0.922\n","\n","Epoch 7\n","Training loss: -4.367448806762695, training accuracy: 0.924719298245614\n","Val loss: 0.04951396584510803, val accuracy: 0.9323333333333333\n","Saving ...\n","\n","Epoch 8\n","Training loss: -4.365747928619385, training accuracy: 0.9265263157894736\n","Val loss: 0.008464590646326542, val accuracy: 0.924\n","\n","Epoch 9\n","Training loss: -4.370009422302246, training accuracy: 0.9306491228070175\n","Val loss: 0.032092414796352386, val accuracy: 0.923\n","\n","Current learning rate has decayed to 0.0095\n","Epoch 10\n","Training loss: -4.366397380828857, training accuracy: 0.9359122807017544\n","Val loss: 0.24173977971076965, val accuracy: 0.933\n","Saving ...\n","\n","Epoch 11\n","Training loss: -4.361897945404053, training accuracy: 0.942\n","Val loss: 0.628070592880249, val accuracy: 0.947\n","Saving ...\n","\n","Epoch 12\n","Training loss: -4.378517150878906, training accuracy: 0.9432807017543859\n","Val loss: 0.013937411829829216, val accuracy: 0.948\n","Saving ...\n","\n","Epoch 13\n","Training loss: -4.377458572387695, training accuracy: 0.9456491228070175\n","Val loss: 1.2240139568575614e-08, val accuracy: 0.942\n","\n","Epoch 14\n","Training loss: -4.381360054016113, training accuracy: 0.9489824561403509\n","Val loss: 0.09630005061626434, val accuracy: 0.9526666666666667\n","Saving ...\n","\n","Epoch 15\n","Training loss: -4.381056785583496, training accuracy: 0.9522631578947368\n","Val loss: 0.07669781148433685, val accuracy: 0.9503333333333334\n","\n","Epoch 16\n","Training loss: -4.366591930389404, training accuracy: 0.9526491228070175\n","Val loss: 0.16100557148456573, val accuracy: 0.953\n","Saving ...\n","\n","Epoch 17\n","Training loss: -4.3824381828308105, training accuracy: 0.9562105263157895\n","Val loss: 0.4767051339149475, val accuracy: 0.9546666666666667\n","Saving ...\n","\n","Epoch 18\n","Training loss: -4.3815484046936035, training accuracy: 0.9573859649122807\n","Val loss: 0.15550565719604492, val accuracy: 0.961\n","Saving ...\n","\n","Epoch 19\n","Training loss: -4.380895137786865, training accuracy: 0.9574561403508772\n","Val loss: 0.23310165107250214, val accuracy: 0.9603333333333334\n","\n","Current learning rate has decayed to 0.009025\n","Epoch 20\n","Training loss: -4.382011413574219, training accuracy: 0.9594561403508772\n","Val loss: 0.016719909384846687, val accuracy: 0.9693333333333334\n","Saving ...\n","\n","Epoch 21\n","Training loss: -4.378201961517334, training accuracy: 0.9605789473684211\n","Val loss: 0.17826566100120544, val accuracy: 0.9646666666666667\n","\n","Epoch 22\n","Training loss: -4.366262435913086, training accuracy: 0.961280701754386\n","Val loss: 0.0, val accuracy: 0.965\n","\n","Epoch 23\n","Training loss: -4.379755020141602, training accuracy: 0.9620701754385965\n","Val loss: 0.04027216136455536, val accuracy: 0.969\n","\n","Epoch 24\n","Training loss: -4.384222984313965, training accuracy: 0.9642982456140351\n","Val loss: 0.007135964464396238, val accuracy: 0.967\n","\n","Epoch 25\n","Training loss: -4.384742736816406, training accuracy: 0.9647894736842105\n","Val loss: 0.0, val accuracy: 0.9583333333333334\n","\n","Epoch 26\n","Training loss: -4.370809555053711, training accuracy: 0.9654561403508772\n","Val loss: 0.07223261892795563, val accuracy: 0.9663333333333334\n","\n","Epoch 27\n","Training loss: -4.380657196044922, training accuracy: 0.9648947368421052\n","Val loss: 0.13976332545280457, val accuracy: 0.968\n","\n","Epoch 28\n","Training loss: -4.379338264465332, training accuracy: 0.9665789473684211\n","Val loss: 0.07987415045499802, val accuracy: 0.9746666666666667\n","Saving ...\n","\n","Epoch 29\n","Training loss: -4.3779778480529785, training accuracy: 0.9670175438596491\n","Val loss: 0.08428563922643661, val accuracy: 0.9643333333333334\n","\n","Current learning rate has decayed to 0.00857375\n","Epoch 30\n","Training loss: -4.370532989501953, training accuracy: 0.9682456140350877\n","Val loss: 2.3838038032408804e-07, val accuracy: 0.9716666666666667\n","\n","Epoch 31\n","Training loss: -4.377676486968994, training accuracy: 0.9676315789473684\n","Val loss: 9.756709884456427e-10, val accuracy: 0.9716666666666667\n","\n","Epoch 32\n","Training loss: -4.377459526062012, training accuracy: 0.9676666666666667\n","Val loss: 0.0881505161523819, val accuracy: 0.9643333333333334\n","\n","Epoch 33\n","Training loss: -4.383792877197266, training accuracy: 0.9689649122807018\n","Val loss: 0.04567692428827286, val accuracy: 0.967\n","\n","Epoch 34\n","Training loss: -4.382406711578369, training accuracy: 0.9698771929824561\n","Val loss: 0.017542358487844467, val accuracy: 0.9716666666666667\n","\n","Epoch 35\n","Training loss: -4.383523941040039, training accuracy: 0.9696666666666667\n","Val loss: 0.21526990830898285, val accuracy: 0.969\n","\n","Epoch 36\n","Training loss: -4.373645305633545, training accuracy: 0.9696842105263158\n","Val loss: 0.08633234351873398, val accuracy: 0.9706666666666667\n","\n","Epoch 37\n","Training loss: -4.378978252410889, training accuracy: 0.9706842105263158\n","Val loss: 0.001153499586507678, val accuracy: 0.9696666666666667\n","\n","Epoch 38\n","Training loss: -4.3852715492248535, training accuracy: 0.9713859649122807\n","Val loss: 0.4170101284980774, val accuracy: 0.969\n","\n","Epoch 39\n","Training loss: -4.385532379150391, training accuracy: 0.9712280701754386\n","Val loss: 0.022421395406126976, val accuracy: 0.9733333333333334\n","\n","Current learning rate has decayed to 0.0081450625\n","Epoch 40\n","Training loss: -4.375668525695801, training accuracy: 0.9717368421052631\n","Val loss: 0.029674623161554337, val accuracy: 0.9683333333333334\n","\n","Epoch 41\n","Training loss: -4.381915092468262, training accuracy: 0.9726140350877193\n","Val loss: 0.11007708311080933, val accuracy: 0.97\n","\n","Epoch 42\n","Training loss: -4.385745525360107, training accuracy: 0.9730350877192983\n","Val loss: 0.003710986813530326, val accuracy: 0.971\n","\n","Epoch 43\n","Training loss: -4.37656831741333, training accuracy: 0.9735789473684211\n","Val loss: 0.16423022747039795, val accuracy: 0.976\n","Saving ...\n","\n","Epoch 44\n","Training loss: -4.380753993988037, training accuracy: 0.9746666666666667\n","Val loss: 0.17045262455940247, val accuracy: 0.968\n","\n","Epoch 45\n","Training loss: -4.384912490844727, training accuracy: 0.9728245614035088\n","Val loss: 0.0, val accuracy: 0.9706666666666667\n","\n","Epoch 46\n","Training loss: -4.380343437194824, training accuracy: 0.9736666666666667\n","Val loss: 0.2657095491886139, val accuracy: 0.9703333333333334\n","\n","Epoch 47\n","Training loss: -4.3831281661987305, training accuracy: 0.9737719298245614\n","Val loss: 0.0, val accuracy: 0.9763333333333334\n","Saving ...\n","\n","Epoch 48\n","Training loss: -4.383699893951416, training accuracy: 0.9751228070175438\n","Val loss: 0.0, val accuracy: 0.9736666666666667\n","\n","Epoch 49\n","Training loss: -4.379130840301514, training accuracy: 0.9751754385964913\n","Val loss: 1.6852486073304362e-09, val accuracy: 0.974\n","\n","Current learning rate has decayed to 0.007737809374999999\n","Epoch 50\n","Training loss: -4.3808674812316895, training accuracy: 0.9751052631578947\n","Val loss: 0.0, val accuracy: 0.979\n","Saving ...\n","\n","Epoch 51\n","Training loss: -4.386083126068115, training accuracy: 0.9753333333333334\n","Val loss: 0.0, val accuracy: 0.973\n","\n","Epoch 52\n","Training loss: -4.375079154968262, training accuracy: 0.9762456140350877\n","Val loss: 0.128631129860878, val accuracy: 0.9726666666666667\n","\n","Epoch 53\n","Training loss: -4.3611321449279785, training accuracy: 0.9757719298245614\n","Val loss: 0.20546165108680725, val accuracy: 0.9726666666666667\n","\n","Epoch 54\n","Training loss: -4.382016658782959, training accuracy: 0.976280701754386\n","Val loss: 0.12904894351959229, val accuracy: 0.9743333333333334\n","\n","Epoch 55\n","Training loss: -4.382154941558838, training accuracy: 0.9765087719298245\n","Val loss: 0.23579084873199463, val accuracy: 0.9753333333333334\n","\n","Epoch 56\n","Training loss: -4.387219429016113, training accuracy: 0.9758070175438597\n","Val loss: 0.18057796359062195, val accuracy: 0.9723333333333334\n","\n","Epoch 57\n","Training loss: -4.386248588562012, training accuracy: 0.9768245614035088\n","Val loss: 1.0405341299701831e-06, val accuracy: 0.9756666666666667\n","\n","Epoch 58\n","Training loss: -4.369056701660156, training accuracy: 0.9774035087719298\n","Val loss: 6.208815683805824e-10, val accuracy: 0.9773333333333334\n","\n","Epoch 59\n","Training loss: -4.367593288421631, training accuracy: 0.9772631578947368\n","Val loss: 0.0, val accuracy: 0.971\n","\n","==================================================\n","==> Finished Training! The best accuracy is 0.979\n","Now T is 100\n","==> Start training!\n","==================================================\n","Epoch 0\n","Training loss: -5.382153034210205, training accuracy: 0.7238245614035088\n","Val loss: 0.026587042957544327, val accuracy: 0.848\n","Saving ...\n","\n","Epoch 1\n","Training loss: -5.383376598358154, training accuracy: 0.8823859649122807\n","Val loss: 0.0033520516008138657, val accuracy: 0.914\n","Saving ...\n","\n","Epoch 2\n","Training loss: -5.384519577026367, training accuracy: 0.9122631578947369\n","Val loss: 0.02615255117416382, val accuracy: 0.9133333333333333\n","\n","Epoch 3\n","Training loss: -5.3846282958984375, training accuracy: 0.9167017543859649\n","Val loss: 0.002378234174102545, val accuracy: 0.9146666666666666\n","Saving ...\n","\n","Epoch 4\n","Training loss: -5.385476112365723, training accuracy: 0.9203157894736842\n","Val loss: 0.02671835571527481, val accuracy: 0.9136666666666666\n","\n","Epoch 5\n","Training loss: -5.386849880218506, training accuracy: 0.9203157894736842\n","Val loss: 0.013164832256734371, val accuracy: 0.9233333333333333\n","Saving ...\n","\n","Epoch 6\n","Training loss: -5.38798189163208, training accuracy: 0.9233859649122808\n","Val loss: 0.08518315851688385, val accuracy: 0.9286666666666666\n","Saving ...\n","\n","Epoch 7\n","Training loss: -5.390113830566406, training accuracy: 0.9250877192982456\n","Val loss: 0.05944395065307617, val accuracy: 0.935\n","Saving ...\n","\n","Epoch 8\n","Training loss: -5.380694389343262, training accuracy: 0.9271052631578948\n","Val loss: 0.07778242230415344, val accuracy: 0.9243333333333333\n","\n","Epoch 9\n","Training loss: -5.3995442390441895, training accuracy: 0.9317543859649123\n","Val loss: 0.06253477931022644, val accuracy: 0.946\n","Saving ...\n","\n","Current learning rate has decayed to 0.0095\n","Epoch 10\n","Training loss: -5.400789737701416, training accuracy: 0.9349824561403509\n","Val loss: 0.1142520010471344, val accuracy: 0.9296666666666666\n","\n","Epoch 11\n","Training loss: -5.3985209465026855, training accuracy: 0.9391754385964912\n","Val loss: 0.10812076181173325, val accuracy: 0.948\n","Saving ...\n","\n","Epoch 12\n","Training loss: -5.399838447570801, training accuracy: 0.9420701754385965\n","Val loss: 0.15539893507957458, val accuracy: 0.9466666666666667\n","\n","Epoch 13\n","Training loss: -5.403240203857422, training accuracy: 0.9454912280701755\n","Val loss: 4.774822741637763e-07, val accuracy: 0.954\n","Saving ...\n","\n","Epoch 14\n","Training loss: -5.401804447174072, training accuracy: 0.9491754385964912\n","Val loss: 0.12914711236953735, val accuracy: 0.9553333333333334\n","Saving ...\n","\n","Epoch 15\n","Training loss: -5.4082932472229, training accuracy: 0.9508947368421052\n","Val loss: 0.016828628256917, val accuracy: 0.9613333333333334\n","Saving ...\n","\n","Epoch 16\n","Training loss: -5.404236316680908, training accuracy: 0.9521929824561404\n","Val loss: 0.031036822125315666, val accuracy: 0.9586666666666667\n","\n","Epoch 17\n","Training loss: -5.404842853546143, training accuracy: 0.9552456140350877\n","Val loss: 0.06955797225236893, val accuracy: 0.958\n","\n","Epoch 18\n","Training loss: -5.404983997344971, training accuracy: 0.9545263157894737\n","Val loss: 0.01882222667336464, val accuracy: 0.9506666666666667\n","\n","Epoch 19\n","Training loss: -5.400155067443848, training accuracy: 0.9557017543859649\n","Val loss: 1.4191567920818215e-09, val accuracy: 0.9606666666666667\n","\n","Current learning rate has decayed to 0.009025\n","Epoch 20\n","Training loss: -5.408496379852295, training accuracy: 0.9595438596491228\n","Val loss: 0.609361469745636, val accuracy: 0.9596666666666667\n","\n","Epoch 21\n","Training loss: -5.4064860343933105, training accuracy: 0.9617543859649123\n","Val loss: 0.08464927971363068, val accuracy: 0.9606666666666667\n","\n","Epoch 22\n","Training loss: -5.40585994720459, training accuracy: 0.9619122807017544\n","Val loss: 0.16079726815223694, val accuracy: 0.964\n","Saving ...\n","\n","Epoch 23\n","Training loss: -5.407533168792725, training accuracy: 0.9613684210526315\n","Val loss: 0.1259513795375824, val accuracy: 0.9596666666666667\n","\n","Epoch 24\n","Training loss: -5.40852689743042, training accuracy: 0.9636491228070175\n","Val loss: 0.3836787939071655, val accuracy: 0.9633333333333334\n","\n","Epoch 25\n","Training loss: -5.407137393951416, training accuracy: 0.9639649122807018\n","Val loss: 0.10500258207321167, val accuracy: 0.963\n","\n","Epoch 26\n","Training loss: -5.41203498840332, training accuracy: 0.964421052631579\n","Val loss: 0.028996799141168594, val accuracy: 0.9633333333333334\n","\n","Epoch 27\n","Training loss: -5.400611400604248, training accuracy: 0.9647192982456141\n","Val loss: 0.19492655992507935, val accuracy: 0.9643333333333334\n","Saving ...\n","\n","Epoch 28\n","Training loss: -5.407732009887695, training accuracy: 0.965280701754386\n","Val loss: 0.05950240418314934, val accuracy: 0.9646666666666667\n","Saving ...\n","\n","Epoch 29\n","Training loss: -5.407331943511963, training accuracy: 0.9662456140350877\n","Val loss: 0.13189536333084106, val accuracy: 0.9686666666666667\n","Saving ...\n","\n","Current learning rate has decayed to 0.00857375\n","Epoch 30\n","Training loss: -5.4100141525268555, training accuracy: 0.9676140350877193\n","Val loss: 0.058504559099674225, val accuracy: 0.971\n","Saving ...\n","\n","Epoch 31\n","Training loss: -5.407320976257324, training accuracy: 0.968140350877193\n","Val loss: 0.004808226600289345, val accuracy: 0.9746666666666667\n","Saving ...\n","\n","Epoch 32\n","Training loss: -5.409563064575195, training accuracy: 0.9687719298245614\n","Val loss: 0.2454160451889038, val accuracy: 0.9616666666666667\n","\n","Epoch 33\n","Training loss: -5.408290386199951, training accuracy: 0.9689824561403508\n","Val loss: 0.05073307454586029, val accuracy: 0.9633333333333334\n","\n","Epoch 34\n","Training loss: -5.40870475769043, training accuracy: 0.968842105263158\n","Val loss: 0.1744842380285263, val accuracy: 0.966\n","\n","Epoch 35\n","Training loss: -5.394662380218506, training accuracy: 0.9699298245614035\n","Val loss: 0.052901070564985275, val accuracy: 0.973\n","\n","Epoch 36\n","Training loss: -5.41105318069458, training accuracy: 0.9702982456140351\n","Val loss: 0.291805624961853, val accuracy: 0.9696666666666667\n","\n","Epoch 37\n","Training loss: -5.3987603187561035, training accuracy: 0.9716491228070175\n","Val loss: 5.4635584945117444e-08, val accuracy: 0.972\n","\n","Epoch 38\n","Training loss: -5.408323287963867, training accuracy: 0.9705789473684211\n","Val loss: 0.8150039911270142, val accuracy: 0.975\n","Saving ...\n","\n","Epoch 39\n","Training loss: -5.395837306976318, training accuracy: 0.9718245614035088\n","Val loss: 0.06740868091583252, val accuracy: 0.9723333333333334\n","\n","Current learning rate has decayed to 0.0081450625\n","Epoch 40\n","Training loss: -5.410834312438965, training accuracy: 0.9725789473684211\n","Val loss: 0.023605823516845703, val accuracy: 0.9713333333333334\n","\n","Epoch 41\n","Training loss: -5.407723903656006, training accuracy: 0.972859649122807\n","Val loss: 0.021826978772878647, val accuracy: 0.967\n","\n","Epoch 42\n","Training loss: -5.408137321472168, training accuracy: 0.9718947368421053\n","Val loss: 0.0, val accuracy: 0.9733333333333334\n","\n","Epoch 43\n","Training loss: -5.40737247467041, training accuracy: 0.974140350877193\n","Val loss: 0.0, val accuracy: 0.97\n","\n","Epoch 44\n","Training loss: -5.410987854003906, training accuracy: 0.973421052631579\n","Val loss: 0.039896875619888306, val accuracy: 0.9713333333333334\n","\n","Epoch 45\n","Training loss: -5.410070419311523, training accuracy: 0.9735789473684211\n","Val loss: 0.17486336827278137, val accuracy: 0.9743333333333334\n","\n","Epoch 46\n","Training loss: -5.4127349853515625, training accuracy: 0.9739473684210527\n","Val loss: 0.0, val accuracy: 0.9693333333333334\n","\n","Epoch 47\n","Training loss: -5.411160945892334, training accuracy: 0.9736842105263158\n","Val loss: 0.2888363003730774, val accuracy: 0.973\n","\n","Epoch 48\n","Training loss: -5.405109882354736, training accuracy: 0.9739473684210527\n","Val loss: 0.09902401268482208, val accuracy: 0.9713333333333334\n","\n","Epoch 49\n","Training loss: -5.400893211364746, training accuracy: 0.9744736842105263\n","Val loss: 0.19210603833198547, val accuracy: 0.975\n","\n","Current learning rate has decayed to 0.007737809374999999\n","Epoch 50\n","Training loss: -5.411438941955566, training accuracy: 0.9755087719298245\n","Val loss: 0.12630711495876312, val accuracy: 0.9703333333333334\n","\n","Epoch 51\n","Training loss: -5.39355993270874, training accuracy: 0.9749298245614035\n","Val loss: 0.09712773561477661, val accuracy: 0.977\n","Saving ...\n","\n","Epoch 52\n","Training loss: -5.412948131561279, training accuracy: 0.974859649122807\n","Val loss: 0.04439619928598404, val accuracy: 0.973\n","\n","Epoch 53\n","Training loss: -5.414441108703613, training accuracy: 0.9754561403508772\n","Val loss: 0.08838741481304169, val accuracy: 0.9753333333333334\n","\n","Epoch 54\n","Training loss: -5.407731056213379, training accuracy: 0.9760701754385965\n","Val loss: 0.0, val accuracy: 0.9766666666666667\n","\n","Epoch 55\n","Training loss: -5.411004543304443, training accuracy: 0.9754035087719298\n","Val loss: 0.0502142570912838, val accuracy: 0.9756666666666667\n","\n","Epoch 56\n","Training loss: -5.4097700119018555, training accuracy: 0.9760701754385965\n","Val loss: 0.026583842933177948, val accuracy: 0.977\n","\n","Epoch 57\n","Training loss: -5.405038356781006, training accuracy: 0.9760526315789474\n","Val loss: 0.026577053591609, val accuracy: 0.97\n","\n","Epoch 58\n","Training loss: -5.410770893096924, training accuracy: 0.975701754385965\n","Val loss: 0.0, val accuracy: 0.9776666666666667\n","Saving ...\n","\n","Epoch 59\n","Training loss: -5.399959087371826, training accuracy: 0.9776315789473684\n","Val loss: 0.0, val accuracy: 0.9803333333333333\n","Saving ...\n","\n","==================================================\n","==> Finished Training! The best accuracy is 0.9803333333333333\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IxacfaUvcy8d","executionInfo":{"status":"ok","timestamp":1638385723701,"user_tz":300,"elapsed":12789,"user":{"displayName":"林子昊","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05325542234136368744"}},"outputId":"2b6c63ee-0811-4a46-f208-e86c96365b69"},"source":["T_list = [20, 30, 40, 50, 60, 70, 80, 90, 100] # T_list = [2, 3, 4, 5, 6, 7, 8, 9, 10]  2, 3, 4, 5, 6, 7, 8, 9, 10\n","for t in T_list:\n","  print(\"Now T is\", t)\n","  model_name = \"T_\" + str(t) + \"_KDStudentNet.pth\"\n","  test_model(model_name, \"KDStudent\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Now T is 20\n","Total examples is 10000, correct examples is 9814; Test accuracy: 0.9814\n","Now T is 30\n","Total examples is 10000, correct examples is 9833; Test accuracy: 0.9833\n","Now T is 40\n","Total examples is 10000, correct examples is 9802; Test accuracy: 0.9802\n","Now T is 50\n","Total examples is 10000, correct examples is 9825; Test accuracy: 0.9825\n","Now T is 60\n","Total examples is 10000, correct examples is 9838; Test accuracy: 0.9838\n","Now T is 70\n","Total examples is 10000, correct examples is 9838; Test accuracy: 0.9838\n","Now T is 80\n","Total examples is 10000, correct examples is 9833; Test accuracy: 0.9833\n","Now T is 90\n","Total examples is 10000, correct examples is 9809; Test accuracy: 0.9809\n","Now T is 100\n","Total examples is 10000, correct examples is 9835; Test accuracy: 0.9835\n"]}]},{"cell_type":"code","metadata":{"id":"KZxwuPhOvH09"},"source":["import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":465},"id":"D-rXYjxdvLzR","executionInfo":{"status":"ok","timestamp":1638577068111,"user_tz":300,"elapsed":392,"user":{"displayName":"林子昊","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05325542234136368744"}},"outputId":"3f9dd538-d0b0-4f37-e9a5-6194c56eb3eb"},"source":["T_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1,2,3,4,5,6,7,8,9,10, 20, 30, 40,50,60,70,80,90,100]\n","test_acc = [0.9815, 0.9833, 0.9824, 0.9822, 0.9842, 0.9834, 0.9822, 0.9843, 0.9841, \n","            0.9863, 0.9847, 0.9849, 0.9821, 0.9846, 0.9847, 0.9819, 0.9837, 0.9827, 0.9831,\n","            0.9814, 0.9833, 0.9802, 0.9825, 0.9838, 0.9838, 0.9833, 0.9809, 0.9835]\n","plt.figure(figsize=(10, 7))\n","plt.xlabel(\"Temperature\", size=15)\n","plt.ylabel(\"Test Accuracy\", size=15)\n","plt.title(\"Temperature v.s. Test Accuracy\", size=15)\n","plt.grid()\n","plt.plot(test_acc)\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x504 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"MlTJHO9yRw4v"},"source":["## Randomly Omit One Digit"]},{"cell_type":"code","metadata":{"id":"yCLdZtBjR0UK"},"source":["def my_collate(batch):\n","\n","  targets_list = []\n","  count = 0\n","\n","  for item in batch:\n","    inputs, targets = item\n","    # print(targets)\n","    if targets != 3:\n","      count += 1\n","      if count == 1:\n","        inputs_tensor = inputs\n","      else:\n","        inputs_tensor = torch.cat((inputs_tensor, inputs), 0)\n","      targets_list.append(targets)\n","\n","  targets_tensor = torch.tensor(np.array(targets_list))\n","  # print(targets_tensor)\n","  return (inputs_tensor, targets_tensor)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aQQIsp97Vtbm"},"source":["student_train_loader = DataLoader(\n","    train_MNIST, \n","    batch_size=TRAIN_BATCH_SIZE,\n","    shuffle=True,\n","    num_workers=2,\n","    collate_fn = my_collate\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YFNc4Ur5V9NT","executionInfo":{"status":"ok","timestamp":1638204072498,"user_tz":300,"elapsed":734505,"user":{"displayName":"林子昊","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05325542234136368744"}},"outputId":"98233665-4dfd-44ab-bd6b-b0d5362e69ee"},"source":["T = 1\n","StudentNet = StudentSimpleNN().to(device)\n","train_model(model=StudentNet, mode=\"KDStudent\", train_loader=student_train_loader, save_name=\"KDStudent_Omit.pth\")\n","  "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Now T is 1\n","==> Start training!\n","==================================================\n","Epoch 0\n","Training loss: -0.0009932797402143478, training accuracy: 0.687636761487965\n","Val loss: 0.06948836147785187, val accuracy: 0.7123333333333334\n","Saving ...\n","\n","Epoch 1\n","Training loss: -0.0010686223395168781, training accuracy: 0.8401062832135042\n","Val loss: 0.04641358554363251, val accuracy: 0.7936666666666666\n","Saving ...\n","\n","Epoch 2\n","Training loss: -0.0012649057898670435, training accuracy: 0.9000859643638637\n","Val loss: 0.05637611076235771, val accuracy: 0.8246666666666667\n","Saving ...\n","\n","Epoch 3\n","Training loss: -0.0014485317515209317, training accuracy: 0.9261487964989059\n","Val loss: 0.06609031558036804, val accuracy: 0.8366666666666667\n","Saving ...\n","\n","Epoch 4\n","Training loss: -0.0014375329483300447, training accuracy: 0.9372069396686464\n","Val loss: 0.02287708781659603, val accuracy: 0.8453333333333334\n","Saving ...\n","\n","Epoch 5\n","Training loss: -0.0012325425632297993, training accuracy: 0.9466434823382307\n","Val loss: 0.050038695335388184, val accuracy: 0.8523333333333334\n","Saving ...\n","\n","Epoch 6\n","Training loss: -0.0014952659839764237, training accuracy: 0.9526609878086902\n","Val loss: 0.06799476593732834, val accuracy: 0.8516666666666667\n","\n","Epoch 7\n","Training loss: -0.0014276969013735652, training accuracy: 0.9569201312910285\n","Val loss: 0.035860344767570496, val accuracy: 0.848\n","\n","Epoch 8\n","Training loss: -0.0015183761715888977, training accuracy: 0.9578774617067833\n","Val loss: 0.07315977662801743, val accuracy: 0.8603333333333333\n","Saving ...\n","\n","Epoch 9\n","Training loss: -0.0015403846045956016, training accuracy: 0.9624687402313223\n","Val loss: 0.055529963225126266, val accuracy: 0.8596666666666667\n","\n","Current learning rate has decayed to 0.0095\n","Epoch 10\n","Training loss: -0.0014578314730897546, training accuracy: 0.9640121913097843\n","Val loss: 0.055862583220005035, val accuracy: 0.8626666666666667\n","Saving ...\n","\n","Epoch 11\n","Training loss: -0.0013116736663505435, training accuracy: 0.9653798061894342\n","Val loss: 0.10142936557531357, val accuracy: 0.865\n","Saving ...\n","\n","Epoch 12\n","Training loss: -0.0014712485717609525, training accuracy: 0.9664738980931541\n","Val loss: 0.11832564324140549, val accuracy: 0.8616666666666667\n","\n","Epoch 13\n","Training loss: -0.0015478366985917091, training accuracy: 0.9681541106595811\n","Val loss: 0.07205002009868622, val accuracy: 0.862\n","\n","Epoch 14\n","Training loss: -0.0015750164166092873, training accuracy: 0.9689551422319475\n","Val loss: 0.04300307855010033, val accuracy: 0.8676666666666667\n","Saving ...\n","\n","Epoch 15\n","Training loss: -0.0015664459206163883, training accuracy: 0.9701273835573617\n","Val loss: 0.05890393257141113, val accuracy: 0.87\n","Saving ...\n","\n","Epoch 16\n","Training loss: -0.001341369585134089, training accuracy: 0.9702446076899031\n","Val loss: 0.09826504439115524, val accuracy: 0.87\n","\n","Epoch 17\n","Training loss: -0.0014673711266368628, training accuracy: 0.9712800875273523\n","Val loss: 0.08188454061746597, val accuracy: 0.873\n","Saving ...\n","\n","Epoch 18\n","Training loss: -0.001542968093417585, training accuracy: 0.9721788058768365\n","Val loss: 0.08332237601280212, val accuracy: 0.8706666666666667\n","\n","Epoch 19\n","Training loss: -0.0015684542013332248, training accuracy: 0.9736245701781807\n","Val loss: 0.06823932379484177, val accuracy: 0.87\n","\n","Current learning rate has decayed to 0.009025\n","Epoch 20\n","Training loss: -0.0015125900972634554, training accuracy: 0.9739957799312285\n","Val loss: 0.020849112421274185, val accuracy: 0.8666666666666667\n","\n","Epoch 21\n","Training loss: -0.0015256489859893918, training accuracy: 0.9743279149734292\n","Val loss: 0.048306431621313095, val accuracy: 0.8696666666666667\n","\n","Epoch 22\n","Training loss: -0.0015355165814980865, training accuracy: 0.9755196936542669\n","Val loss: 0.06795590370893478, val accuracy: 0.8723333333333333\n","\n","Epoch 23\n","Training loss: -0.001451438176445663, training accuracy: 0.9751680212566427\n","Val loss: 0.07200514525175095, val accuracy: 0.8733333333333333\n","Saving ...\n","\n","Epoch 24\n","Training loss: -0.0013604596024379134, training accuracy: 0.9761839637386683\n","Val loss: 0.10721590369939804, val accuracy: 0.874\n","Saving ...\n","\n","Epoch 25\n","Training loss: -0.0015410910127684474, training accuracy: 0.9764379493591747\n","Val loss: 0.11815047264099121, val accuracy: 0.8706666666666667\n","\n","Epoch 26\n","Training loss: -0.0015632675494998693, training accuracy: 0.9760862769615505\n","Val loss: 0.09512773156166077, val accuracy: 0.877\n","Saving ...\n","\n","Epoch 27\n","Training loss: -0.001526776235550642, training accuracy: 0.9782744607689903\n","Val loss: 0.07230425626039505, val accuracy: 0.8713333333333333\n","\n","Epoch 28\n","Training loss: -0.001595749519765377, training accuracy: 0.977199906220694\n","Val loss: 0.07091076672077179, val accuracy: 0.8726666666666667\n","\n","Epoch 29\n","Training loss: -0.0015377476811408997, training accuracy: 0.9771022194435761\n","Val loss: 0.04845002293586731, val accuracy: 0.872\n","\n","Current learning rate has decayed to 0.00857375\n","Epoch 30\n","Training loss: -0.0012915859697386622, training accuracy: 0.9778251015942482\n","Val loss: 0.08151493221521378, val accuracy: 0.8743333333333333\n","\n","Epoch 31\n","Training loss: -0.0015802582493051887, training accuracy: 0.9785089090340732\n","Val loss: 0.08851992338895798, val accuracy: 0.872\n","\n","Epoch 32\n","Training loss: -0.0014132619835436344, training accuracy: 0.978606595811191\n","Val loss: 0.04056071490049362, val accuracy: 0.8753333333333333\n","\n","Epoch 33\n","Training loss: -0.0015938431024551392, training accuracy: 0.9789582682088153\n","Val loss: 0.11144456267356873, val accuracy: 0.876\n","\n","Epoch 34\n","Training loss: -0.0015314038610085845, training accuracy: 0.9788019693654267\n","Val loss: 0.07947523891925812, val accuracy: 0.874\n","\n","Epoch 35\n","Training loss: -0.0015614597359672189, training accuracy: 0.9797788371366052\n","Val loss: 0.058232635259628296, val accuracy: 0.8743333333333333\n","\n","Epoch 36\n","Training loss: -0.0015463662566617131, training accuracy: 0.9796811503594873\n","Val loss: 0.05007810890674591, val accuracy: 0.877\n","\n","Epoch 37\n","Training loss: -0.0015958216972649097, training accuracy: 0.9795834635823695\n","Val loss: 0.04475776106119156, val accuracy: 0.876\n","\n","Epoch 38\n","Training loss: -0.001544415601529181, training accuracy: 0.9802086589559237\n","Val loss: 0.0771782249212265, val accuracy: 0.8756666666666667\n","\n","Epoch 39\n","Training loss: -0.0014751043636351824, training accuracy: 0.9807752422632072\n","Val loss: 0.07036076486110687, val accuracy: 0.8746666666666667\n","\n","Current learning rate has decayed to 0.0081450625\n","Epoch 40\n","Training loss: -0.0015336067881435156, training accuracy: 0.9797983744920288\n","Val loss: 0.0871727466583252, val accuracy: 0.875\n","\n","Epoch 41\n","Training loss: -0.0015693607274442911, training accuracy: 0.9805994060643951\n","Val loss: 0.08430709689855576, val accuracy: 0.8763333333333333\n","\n","Epoch 42\n","Training loss: -0.001548060099594295, training accuracy: 0.9811855267271022\n","Val loss: 0.04636641591787338, val accuracy: 0.877\n","\n","Epoch 43\n","Training loss: -0.0016307836631312966, training accuracy: 0.9814785870584558\n","Val loss: 0.10519832372665405, val accuracy: 0.8743333333333333\n","\n","Epoch 44\n","Training loss: -0.001576955895870924, training accuracy: 0.981380900281338\n","Val loss: 0.05082984268665314, val accuracy: 0.877\n","\n","Epoch 45\n","Training loss: -0.0015263364184647799, training accuracy: 0.9814395123476086\n","Val loss: 0.09265381097793579, val accuracy: 0.876\n","\n","Epoch 46\n","Training loss: -0.0015874758828431368, training accuracy: 0.9820060956548922\n","Val loss: 0.04397105425596237, val accuracy: 0.877\n","\n","Epoch 47\n","Training loss: -0.0015584605280309916, training accuracy: 0.9820060956548922\n","Val loss: 0.08743901550769806, val accuracy: 0.8776666666666667\n","Saving ...\n","\n","Epoch 48\n","Training loss: -0.0015875180251896381, training accuracy: 0.9823577680525164\n","Val loss: 0.023007795214653015, val accuracy: 0.877\n","\n","Epoch 49\n","Training loss: -0.0015294549521058798, training accuracy: 0.9824554548296343\n","Val loss: 0.07953143119812012, val accuracy: 0.875\n","\n","Current learning rate has decayed to 0.007737809374999999\n","Epoch 50\n","Training loss: -0.0015129228122532368, training accuracy: 0.9826117536730228\n","Val loss: 0.07341310381889343, val accuracy: 0.8766666666666667\n","\n","Epoch 51\n","Training loss: -0.001491411356255412, training accuracy: 0.9826703657392936\n","Val loss: 0.05524720251560211, val accuracy: 0.8796666666666667\n","Saving ...\n","\n","Epoch 52\n","Training loss: -0.001603805460035801, training accuracy: 0.9825140668959049\n","Val loss: 0.054856136441230774, val accuracy: 0.8756666666666667\n","\n","Epoch 53\n","Training loss: -0.0015564452623948455, training accuracy: 0.9831197249140357\n","Val loss: 0.057760607451200485, val accuracy: 0.8766666666666667\n","\n","Epoch 54\n","Training loss: -0.0015744969714432955, training accuracy: 0.9827875898718349\n","Val loss: 0.05098947137594223, val accuracy: 0.878\n","\n","Epoch 55\n","Training loss: -0.0016262899152934551, training accuracy: 0.9828071272272585\n","Val loss: 0.08611636608839035, val accuracy: 0.876\n","\n","Epoch 56\n","Training loss: -0.0015463297022506595, training accuracy: 0.9839012191309784\n","Val loss: 0.03510347008705139, val accuracy: 0.8753333333333333\n","\n","Epoch 57\n","Training loss: -0.0014291234547272325, training accuracy: 0.9826312910284464\n","Val loss: 0.07698401808738708, val accuracy: 0.877\n","\n","Epoch 58\n","Training loss: -0.0014314537402242422, training accuracy: 0.9827485151609878\n","Val loss: 0.04768463969230652, val accuracy: 0.875\n","\n","Epoch 59\n","Training loss: -0.0016007949598133564, training accuracy: 0.983373710534542\n","Val loss: 0.08812671899795532, val accuracy: 0.877\n","\n","==================================================\n","==> Finished Training! The best accuracy is 0.8796666666666667\n"]}]},{"cell_type":"code","metadata":{"id":"Pu8JYLJCWCva","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638578711427,"user_tz":300,"elapsed":1590,"user":{"displayName":"林子昊","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05325542234136368744"}},"outputId":"5c5598d8-3884-480d-d43e-7bf8a44e5573"},"source":["KDStudent_Omit = StudentSimpleNN().to(device)\n","checkpoint = torch.load(\"/content/drive/MyDrive/duke/ECE 661/final project/code/checkpoints/KDStudent_Omit.pth\")\n","KDStudent_Omit.load_state_dict(checkpoint['state_dict'])\n","KDStudent_Omit.to(device)\n","KDStudent_Omit.eval()\n","\n","total_examples = 0\n","correct_examples = 0\n","wrong_target = []\n","softmax = torch.nn.Softmax(dim=1)\n","\n","with torch.no_grad():\n","  for batch_idx, (inputs, targets) in enumerate(test_loader):\n","\n","    inputs, targets = inputs.to(device), targets.to(device)\n","\n","    pred = KDStudent_Omit(inputs)\n","\n","    total_examples += inputs.shape[0]\n","\n","    out = softmax(pred)\n","    out = torch.max(out, 1)\n","\n","    # print(targets)\n","    # print(out[1])\n","    # print(targets != out[1])\n","    wrong_target += torch.masked_select(targets, targets != out[1]).cpu().data.numpy().tolist()\n","\n","    correct_examples += torch.sum(targets==out[1]).cpu().data.numpy().tolist()\n","\n","avg_acc = correct_examples / total_examples\n","print(\"Total examples is {}, correct examples is {}; Test accuracy: {}\".format(total_examples, correct_examples, avg_acc))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total examples is 10000, correct examples is 8868; Test accuracy: 0.8868\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q3W1HUVv30dN","executionInfo":{"status":"ok","timestamp":1638578766112,"user_tz":300,"elapsed":146,"user":{"displayName":"林子昊","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05325542234136368744"}},"outputId":"2ce6972d-bbb2-41cc-a8eb-6f6c0386ccde"},"source":["sum(np.array(wrong_target) == 3) / len(wrong_target)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.892226148409894"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jq0CMpYJ5wW3","executionInfo":{"status":"ok","timestamp":1638578772888,"user_tz":300,"elapsed":159,"user":{"displayName":"林子昊","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05325542234136368744"}},"outputId":"64a8b51d-538e-4037-92c7-e52f67505a90"},"source":["len(wrong_target)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1132"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"Ej1V2vIY59l7"},"source":[""],"execution_count":null,"outputs":[]}]}