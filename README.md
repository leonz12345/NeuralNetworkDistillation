# NeuralNetworkDistillation
This repo is about neural network knowledge distillation. We experimented with teacher-student framework, tested the effect of temperature on the distillation performance, reversed distillation and self distilation.
