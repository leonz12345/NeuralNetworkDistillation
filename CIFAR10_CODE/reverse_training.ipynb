{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from Models import ResNet20, ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n",
      "torch.Size([5, 10])\n"
     ]
    }
   ],
   "source": [
    "input_test = torch.randn([5,3,32,32])\n",
    "resnet20 = ResNet20()\n",
    "out = resnet20(input_test)\n",
    "print(out.size())\n",
    "\n",
    "resnet50 = ResNet50()\n",
    "out = resnet50(input_test)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def studentLoss(teacher_pred, student_pred, targets, T, alpha):\n",
    "    \"\"\"\n",
    "    Loss function for student network: Loss = alpha * (distillation loss with soft-target) + (1 - alpha) * (cross-entropy loss with true label)\n",
    "    Return: loss\n",
    "    \"\"\"\n",
    "    if alpha > 0:\n",
    "        loss = F.kl_div(F.softmax(student_pred / T, dim=1), \n",
    "                        F.softmax(teacher_pred / T, dim=1), \n",
    "                        reduction='batchmean') * (T**2) * alpha + F.cross_entropy(student_pred, targets) * (1 - alpha)\n",
    "    else:\n",
    "        loss = F.cross_entropy(student_pred, targets)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training and Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distillationTraining(model, train_loader, save_name):\n",
    "    print(\"Now T is {}\".format(T))\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    current_learning_rate = LEARNING_RATE\n",
    "    softmax = torch.nn.Softmax(dim=1)\n",
    "    print(\"==> Start training!\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for i in range(0, EPOCHS):\n",
    "        if i in DECAY_EPOCHS and i != 0:\n",
    "            current_learning_rate = current_learning_rate * DECAY\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = current_learning_rate\n",
    "            print(\"Current learning rate has decayed to {}\".format(current_learning_rate))\n",
    "        \n",
    "        model.train()\n",
    "        print(\"Epoch {}\".format(i))\n",
    "        \n",
    "        total_examples = 0\n",
    "        correct_examples = 0\n",
    "        train_loss = 0\n",
    "        \n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            pred = model(inputs)\n",
    "            if alpha > 0:\n",
    "                with torch.no_grad():\n",
    "                    teacher_pred = teacher_model(inputs)\n",
    "            else:\n",
    "                teacher_pred = 0\n",
    "            train_loss = studentLoss(teacher_pred, pred, targets, T, alpha)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_examples += inputs.shape[0]\n",
    "\n",
    "            out = softmax(pred)\n",
    "            out = torch.max(out, 1)\n",
    "\n",
    "            correct_examples += torch.sum(targets==out[1]).cpu().data.numpy().tolist()\n",
    "            \n",
    "        avg_loss = train_loss / len(train_loader)\n",
    "        avg_acc = correct_examples / total_examples\n",
    "        print(\"Training loss: {}, training accuracy: {}\".format(avg_loss, avg_acc))\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        total_examples = 0\n",
    "        correct_examples = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                pred = model(inputs)\n",
    "                val_loss = criterion(pred, targets)\n",
    "                total_examples += inputs.shape[0]\n",
    "                out = softmax(pred)\n",
    "                out = torch.max(out, 1)\n",
    "                correct_examples += torch.sum(targets==out[1]).cpu().data.numpy().tolist()\n",
    "                \n",
    "        avg_loss = val_loss / len(val_loader)\n",
    "        avg_acc = correct_examples / total_examples\n",
    "        print(\"Val loss: {}, val accuracy: {}\".format(avg_loss, avg_acc))\n",
    "\n",
    "        if avg_acc > best_val_acc:\n",
    "            best_val_acc = avg_acc\n",
    "            print(\"Saving ...\")\n",
    "            state = {'state_dict': model.state_dict(),\n",
    "                      'epoch': i,\n",
    "                      'lr': current_learning_rate}\n",
    "            \n",
    "        torch.save(state, os.path.join(CHECKPOINT_PATH, save_name))\n",
    "        print('')\n",
    "\n",
    "    print(\"=\"*50)\n",
    "    print(\"==> Finished Training! The best accuracy is {}\".format(best_val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    total_examples = 0\n",
    "    correct_examples = 0\n",
    "    softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            pred = model(inputs)\n",
    "            total_examples += inputs.shape[0]\n",
    "\n",
    "            out = softmax(pred)\n",
    "            out = torch.max(out, 1)\n",
    "\n",
    "            correct_examples += torch.sum(targets==out[1]).cpu().data.numpy().tolist()\n",
    "\n",
    "    avg_acc = correct_examples / total_examples\n",
    "    print(\"Total examples is {}, correct examples is {}; Test accuracy: {}\".format(total_examples, correct_examples, avg_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = \"./data\"\n",
    "CIFAR10_shape = (3, 32, 32)\n",
    "pad_size = 2\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "\n",
    "# Preprocessing\n",
    "transform_train = transforms.Compose([torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                      torchvision.transforms.RandomCrop((32,32), padding=4),\n",
    "                                      transforms.ToTensor(), \n",
    "                                      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "transform_val = transforms.Compose([transforms.ToTensor(), \n",
    "                                    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                    (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "transform_test = transforms.Compose([transforms.ToTensor(), \n",
    "                                    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                    (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "train_CIFAR10 = torchvision.datasets.CIFAR10(root='./', train=True, download=True, transform = transform_train)\n",
    "\n",
    "test_CIFAR10 = torchvision.datasets.CIFAR10(root='./', train=False, download=True, transform=transform_test)\n",
    "\n",
    "num_train = int(1.0 * len(train_CIFAR10) * 95 / 100)\n",
    "num_val = len(train_CIFAR10) - num_train\n",
    "train_CIFAR10, val_CIFAR10 = torch.utils.data.random_split(train_CIFAR10, [num_train, num_val])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_CIFAR10, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_CIFAR10, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_CIFAR10, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.01\n",
    "\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "EPOCHS = 150\n",
    "DECAY_EPOCHS = [75,110]\n",
    "DECAY = 0.1\n",
    "\n",
    "CHECKPOINT_PATH = \"./saved_model\"\n",
    "\n",
    "# for student model\n",
    "T = 1\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is deployed to cuda\n",
      "Total examples is 10000, correct examples is 8967; Test accuracy: 0.8967\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"The model is deployed to\", device)\n",
    "\n",
    "# Teacher Model\n",
    "teacher_model = ResNet20()\n",
    "checkpoint = torch.load(\"./saved_model/resnet20_final.pth\")\n",
    "teacher_model.load_state_dict(checkpoint['state_dict'])\n",
    "test_model(teacher_model)\n",
    "\n",
    "# Student Model\n",
    "student_model = ResNet50()\n",
    "\n",
    "teacher_model = teacher_model.to(device)\n",
    "student_model = student_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now T is 1\n",
      "==> Start training!\n",
      "==================================================\n",
      "Epoch 0\n",
      "Training loss: 0.0005555233219638467, training accuracy: 0.37509473684210526\n",
      "Val loss: 0.07840928435325623, val accuracy: 0.4956\n",
      "Saving ...\n",
      "\n",
      "Epoch 1\n",
      "Training loss: 0.0012481441954150796, training accuracy: 0.5819157894736842\n",
      "Val loss: 0.0655677393078804, val accuracy: 0.564\n",
      "Saving ...\n",
      "\n",
      "Epoch 2\n",
      "Training loss: -0.0003462386957835406, training accuracy: 0.668821052631579\n",
      "Val loss: 0.05585915967822075, val accuracy: 0.6504\n",
      "Saving ...\n",
      "\n",
      "Epoch 3\n",
      "Training loss: -0.0004385567153804004, training accuracy: 0.7205263157894737\n",
      "Val loss: 0.06990563124418259, val accuracy: 0.6536\n",
      "Saving ...\n",
      "\n",
      "Epoch 4\n",
      "Training loss: -0.0005477671511471272, training accuracy: 0.7549473684210526\n",
      "Val loss: 0.03308708965778351, val accuracy: 0.7312\n",
      "Saving ...\n",
      "\n",
      "Epoch 5\n",
      "Training loss: -2.280350418004673e-05, training accuracy: 0.7761263157894737\n",
      "Val loss: 0.04936039447784424, val accuracy: 0.7304\n",
      "\n",
      "Epoch 6\n",
      "Training loss: -0.0010279422858729959, training accuracy: 0.7948631578947368\n",
      "Val loss: 0.03275136649608612, val accuracy: 0.768\n",
      "Saving ...\n",
      "\n",
      "Epoch 7\n",
      "Training loss: -0.00010532525629969314, training accuracy: 0.8092\n",
      "Val loss: 0.02127148024737835, val accuracy: 0.7844\n",
      "Saving ...\n",
      "\n",
      "Epoch 8\n",
      "Training loss: -0.0011792340083047748, training accuracy: 0.8177263157894736\n",
      "Val loss: 0.027434920892119408, val accuracy: 0.8012\n",
      "Saving ...\n",
      "\n",
      "Epoch 9\n",
      "Training loss: -0.0010616659419611096, training accuracy: 0.8305052631578947\n",
      "Val loss: 0.05120471119880676, val accuracy: 0.7804\n",
      "\n",
      "Epoch 10\n",
      "Training loss: -0.0007123318500816822, training accuracy: 0.838378947368421\n",
      "Val loss: 0.035330548882484436, val accuracy: 0.8092\n",
      "Saving ...\n",
      "\n",
      "Epoch 11\n",
      "Training loss: -0.0005688812234438956, training accuracy: 0.8465894736842106\n",
      "Val loss: 0.034023892134428024, val accuracy: 0.8176\n",
      "Saving ...\n",
      "\n",
      "Epoch 12\n",
      "Training loss: -0.0009308136068284512, training accuracy: 0.8533263157894737\n",
      "Val loss: 0.05055243894457817, val accuracy: 0.794\n",
      "\n",
      "Epoch 13\n",
      "Training loss: -0.0008401763625442982, training accuracy: 0.8564\n",
      "Val loss: 0.03797582909464836, val accuracy: 0.8132\n",
      "\n",
      "Epoch 14\n",
      "Training loss: -0.0008793488377705216, training accuracy: 0.8648\n",
      "Val loss: 0.031060589477419853, val accuracy: 0.824\n",
      "Saving ...\n",
      "\n",
      "Epoch 15\n",
      "Training loss: -0.0006929936353117228, training accuracy: 0.8679157894736842\n",
      "Val loss: 0.026968875899910927, val accuracy: 0.8292\n",
      "Saving ...\n",
      "\n",
      "Epoch 16\n",
      "Training loss: -0.0014234300469979644, training accuracy: 0.8723578947368421\n",
      "Val loss: 0.029402369633316994, val accuracy: 0.826\n",
      "\n",
      "Epoch 17\n",
      "Training loss: -0.0009424152667634189, training accuracy: 0.8797052631578948\n",
      "Val loss: 0.023340214043855667, val accuracy: 0.8288\n",
      "\n",
      "Epoch 18\n",
      "Training loss: -0.00045302981743589044, training accuracy: 0.8836421052631579\n",
      "Val loss: 0.01875324919819832, val accuracy: 0.8328\n",
      "Saving ...\n",
      "\n",
      "Epoch 19\n",
      "Training loss: -0.0010560490190982819, training accuracy: 0.8845263157894737\n",
      "Val loss: 0.028748614713549614, val accuracy: 0.8032\n",
      "\n",
      "Epoch 20\n",
      "Training loss: -3.403969822102226e-05, training accuracy: 0.8898526315789473\n",
      "Val loss: 0.03108665905892849, val accuracy: 0.8292\n",
      "\n",
      "Epoch 21\n",
      "Training loss: -0.0004694137314800173, training accuracy: 0.8901894736842105\n",
      "Val loss: 0.03476998209953308, val accuracy: 0.8484\n",
      "Saving ...\n",
      "\n",
      "Epoch 22\n",
      "Training loss: -0.0009451885707676411, training accuracy: 0.8980842105263158\n",
      "Val loss: 0.016556916758418083, val accuracy: 0.8504\n",
      "Saving ...\n",
      "\n",
      "Epoch 23\n",
      "Training loss: -0.0009679628419689834, training accuracy: 0.9000631578947368\n",
      "Val loss: 0.03188052773475647, val accuracy: 0.828\n",
      "\n",
      "Epoch 24\n",
      "Training loss: -0.0013290508650243282, training accuracy: 0.9013263157894736\n",
      "Val loss: 0.016840562224388123, val accuracy: 0.8448\n",
      "\n",
      "Epoch 25\n",
      "Training loss: -0.0007341059972532094, training accuracy: 0.9048421052631579\n",
      "Val loss: 0.03474687412381172, val accuracy: 0.8404\n",
      "\n",
      "Epoch 26\n",
      "Training loss: -0.001555888564325869, training accuracy: 0.9082526315789474\n",
      "Val loss: 0.03288760408759117, val accuracy: 0.8332\n",
      "\n",
      "Epoch 27\n",
      "Training loss: -0.0015238915802910924, training accuracy: 0.9097263157894737\n",
      "Val loss: 0.012377416715025902, val accuracy: 0.86\n",
      "Saving ...\n",
      "\n",
      "Epoch 28\n",
      "Training loss: -0.0015790248289704323, training accuracy: 0.9102105263157895\n",
      "Val loss: 0.03005029633641243, val accuracy: 0.8584\n",
      "\n",
      "Epoch 29\n",
      "Training loss: -0.0013480880297720432, training accuracy: 0.9152210526315789\n",
      "Val loss: 0.014641279354691505, val accuracy: 0.8588\n",
      "\n",
      "Epoch 30\n",
      "Training loss: -0.0015453662490472198, training accuracy: 0.9164210526315789\n",
      "Val loss: 0.023734191432595253, val accuracy: 0.8488\n",
      "\n",
      "Epoch 31\n",
      "Training loss: -0.0012057145358994603, training accuracy: 0.9176\n",
      "Val loss: 0.02258889190852642, val accuracy: 0.856\n",
      "\n",
      "Epoch 32\n",
      "Training loss: -0.0009873744565993547, training accuracy: 0.9211789473684211\n",
      "Val loss: 0.017890123650431633, val accuracy: 0.8564\n",
      "\n",
      "Epoch 33\n",
      "Training loss: -0.0013065044768154621, training accuracy: 0.9231157894736842\n",
      "Val loss: 0.03331954404711723, val accuracy: 0.826\n",
      "\n",
      "Epoch 34\n",
      "Training loss: -0.00028966119862161577, training accuracy: 0.9262526315789473\n",
      "Val loss: 0.024446113035082817, val accuracy: 0.866\n",
      "Saving ...\n",
      "\n",
      "Epoch 35\n",
      "Training loss: -0.001128267147578299, training accuracy: 0.9228\n",
      "Val loss: 0.018676461651921272, val accuracy: 0.8444\n",
      "\n",
      "Epoch 36\n",
      "Training loss: -0.0010823115007951856, training accuracy: 0.9274736842105263\n",
      "Val loss: 0.03752657398581505, val accuracy: 0.8612\n",
      "\n",
      "Epoch 37\n",
      "Training loss: -0.0005611127708107233, training accuracy: 0.9296631578947369\n",
      "Val loss: 0.03023640811443329, val accuracy: 0.8416\n",
      "\n",
      "Epoch 38\n",
      "Training loss: -0.0009414434898644686, training accuracy: 0.930778947368421\n",
      "Val loss: 0.02028573863208294, val accuracy: 0.87\n",
      "Saving ...\n",
      "\n",
      "Epoch 39\n",
      "Training loss: -0.0015466337790712714, training accuracy: 0.9324\n",
      "Val loss: 0.021968143060803413, val accuracy: 0.864\n",
      "\n",
      "Epoch 40\n",
      "Training loss: -0.0013408279046416283, training accuracy: 0.9336210526315789\n",
      "Val loss: 0.03385046869516373, val accuracy: 0.862\n",
      "\n",
      "Epoch 41\n",
      "Training loss: -0.0016793860122561455, training accuracy: 0.9386105263157895\n",
      "Val loss: 0.024208540096879005, val accuracy: 0.8576\n",
      "\n",
      "Epoch 42\n",
      "Training loss: -0.001394245307892561, training accuracy: 0.9375157894736842\n",
      "Val loss: 0.027232998982071877, val accuracy: 0.8632\n",
      "\n",
      "Epoch 43\n",
      "Training loss: -0.0012087925570085645, training accuracy: 0.9385684210526316\n",
      "Val loss: 0.030181292444467545, val accuracy: 0.8684\n",
      "\n",
      "Epoch 44\n",
      "Training loss: -0.0011356623144820333, training accuracy: 0.9369052631578947\n",
      "Val loss: 0.028812045231461525, val accuracy: 0.852\n",
      "\n",
      "Epoch 45\n",
      "Training loss: -0.0011536491801962256, training accuracy: 0.9393894736842106\n",
      "Val loss: 0.024682248011231422, val accuracy: 0.8628\n",
      "\n",
      "Epoch 46\n",
      "Training loss: -0.0012403518194332719, training accuracy: 0.9389473684210526\n",
      "Val loss: 0.02370540425181389, val accuracy: 0.868\n",
      "\n",
      "Epoch 47\n",
      "Training loss: -0.001483384519815445, training accuracy: 0.9415157894736842\n",
      "Val loss: 0.03849231079220772, val accuracy: 0.8704\n",
      "Saving ...\n",
      "\n",
      "Epoch 48\n",
      "Training loss: -0.0016116290353238583, training accuracy: 0.9456210526315789\n",
      "Val loss: 0.0184142105281353, val accuracy: 0.876\n",
      "Saving ...\n",
      "\n",
      "Epoch 49\n",
      "Training loss: -0.0010967068374156952, training accuracy: 0.9473263157894737\n",
      "Val loss: 0.04858645796775818, val accuracy: 0.8608\n",
      "\n",
      "Epoch 50\n",
      "Training loss: -0.00118075346108526, training accuracy: 0.9459368421052632\n",
      "Val loss: 0.039036791771650314, val accuracy: 0.8684\n",
      "\n",
      "Epoch 51\n",
      "Training loss: -0.0008627565111964941, training accuracy: 0.9472\n",
      "Val loss: 0.01704554073512554, val accuracy: 0.8708\n",
      "\n",
      "Epoch 52\n",
      "Training loss: -0.0006229509599506855, training accuracy: 0.9464421052631579\n",
      "Val loss: 0.019970616325736046, val accuracy: 0.874\n",
      "\n",
      "Epoch 53\n",
      "Training loss: -0.0009468776406720281, training accuracy: 0.9486315789473684\n",
      "Val loss: 0.025266451761126518, val accuracy: 0.866\n",
      "\n",
      "Epoch 54\n",
      "Training loss: -0.0013832710683345795, training accuracy: 0.9497894736842105\n",
      "Val loss: 0.03263046219944954, val accuracy: 0.8732\n",
      "\n",
      "Epoch 55\n",
      "Training loss: -0.0012160419719293714, training accuracy: 0.9521473684210526\n",
      "Val loss: 0.0263983067125082, val accuracy: 0.8788\n",
      "Saving ...\n",
      "\n",
      "Epoch 56\n",
      "Training loss: -0.001657559652812779, training accuracy: 0.9504842105263158\n",
      "Val loss: 0.012654422782361507, val accuracy: 0.874\n",
      "\n",
      "Epoch 57\n",
      "Training loss: -0.001642304239794612, training accuracy: 0.9544842105263158\n",
      "Val loss: 0.035023096948862076, val accuracy: 0.8624\n",
      "\n",
      "Epoch 58\n",
      "Training loss: -0.0011339208576828241, training accuracy: 0.9546315789473684\n",
      "Val loss: 0.022026794031262398, val accuracy: 0.87\n",
      "\n",
      "Epoch 59\n",
      "Training loss: -0.001447416259907186, training accuracy: 0.9547789473684211\n",
      "Val loss: 0.02952095866203308, val accuracy: 0.8672\n",
      "\n",
      "Epoch 60\n",
      "Training loss: -9.283439430873841e-05, training accuracy: 0.9576\n",
      "Val loss: 0.03539026901125908, val accuracy: 0.8684\n",
      "\n",
      "Epoch 61\n",
      "Training loss: -0.0012765531428158283, training accuracy: 0.9522526315789474\n",
      "Val loss: 0.021598242223262787, val accuracy: 0.8792\n",
      "Saving ...\n",
      "\n",
      "Epoch 62\n",
      "Training loss: -0.0014892332255840302, training accuracy: 0.9586736842105263\n",
      "Val loss: 0.007303909864276648, val accuracy: 0.8752\n",
      "\n",
      "Epoch 63\n",
      "Training loss: -0.0011585316387936473, training accuracy: 0.9594105263157895\n",
      "Val loss: 0.020524457097053528, val accuracy: 0.882\n",
      "Saving ...\n",
      "\n",
      "Epoch 64\n",
      "Training loss: -0.0011107224272564054, training accuracy: 0.9560421052631579\n",
      "Val loss: 0.019624771550297737, val accuracy: 0.8728\n",
      "\n",
      "Epoch 65\n",
      "Training loss: -0.0007595248171128333, training accuracy: 0.9564421052631579\n",
      "Val loss: 0.04182727262377739, val accuracy: 0.8652\n",
      "\n",
      "Epoch 66\n",
      "Training loss: -0.0006025028415024281, training accuracy: 0.9543789473684211\n",
      "Val loss: 0.019611172378063202, val accuracy: 0.8708\n",
      "\n",
      "Epoch 67\n",
      "Training loss: -0.0011624775361269712, training accuracy: 0.9581894736842105\n",
      "Val loss: 0.03474435210227966, val accuracy: 0.88\n",
      "\n",
      "Epoch 68\n",
      "Training loss: -0.0014407327398657799, training accuracy: 0.9593684210526315\n",
      "Val loss: 0.02781626023352146, val accuracy: 0.88\n",
      "\n",
      "Epoch 69\n",
      "Training loss: -0.0004416109586600214, training accuracy: 0.9638947368421052\n",
      "Val loss: 0.03214412182569504, val accuracy: 0.8624\n",
      "\n",
      "Epoch 70\n",
      "Training loss: -0.001449785428121686, training accuracy: 0.9578947368421052\n",
      "Val loss: 0.012269251979887486, val accuracy: 0.8788\n",
      "\n",
      "Epoch 71\n",
      "Training loss: -0.0011432961327955127, training accuracy: 0.9649052631578947\n",
      "Val loss: 0.01622023805975914, val accuracy: 0.8792\n",
      "\n",
      "Epoch 72\n",
      "Training loss: -0.0014710749965161085, training accuracy: 0.964421052631579\n",
      "Val loss: 0.012642420828342438, val accuracy: 0.8736\n",
      "\n",
      "Epoch 73\n",
      "Training loss: -0.0015605823136866093, training accuracy: 0.9646947368421053\n",
      "Val loss: 0.025769010186195374, val accuracy: 0.8856\n",
      "Saving ...\n",
      "\n",
      "Epoch 74\n",
      "Training loss: -0.0005160680157132447, training accuracy: 0.965221052631579\n",
      "Val loss: 0.020546790212392807, val accuracy: 0.8828\n",
      "\n",
      "Current learning rate has decayed to 0.001\n",
      "Epoch 75\n",
      "Training loss: -0.0017631761729717255, training accuracy: 0.9790736842105263\n",
      "Val loss: 0.026653705164790154, val accuracy: 0.894\n",
      "Saving ...\n",
      "\n",
      "Epoch 76\n",
      "Training loss: -0.0008530065533705056, training accuracy: 0.9850105263157894\n",
      "Val loss: 0.019131843000650406, val accuracy: 0.9012\n",
      "Saving ...\n",
      "\n",
      "Epoch 77\n",
      "Training loss: -0.0015625564847141504, training accuracy: 0.9865473684210526\n",
      "Val loss: 0.00904364325106144, val accuracy: 0.9012\n",
      "\n",
      "Epoch 78\n",
      "Training loss: -0.000974973663687706, training accuracy: 0.9877052631578948\n",
      "Val loss: 0.02011851780116558, val accuracy: 0.8972\n",
      "\n",
      "Epoch 79\n",
      "Training loss: -0.001664140960201621, training accuracy: 0.9886105263157895\n",
      "Val loss: 0.02184179611504078, val accuracy: 0.9\n",
      "\n",
      "Epoch 80\n",
      "Training loss: -0.0010173440678045154, training accuracy: 0.9889473684210527\n",
      "Val loss: 0.009624960832297802, val accuracy: 0.8996\n",
      "\n",
      "Epoch 81\n",
      "Training loss: -0.001589100225828588, training accuracy: 0.9896421052631579\n",
      "Val loss: 0.013811632990837097, val accuracy: 0.9\n",
      "\n",
      "Epoch 82\n",
      "Training loss: -0.0016524156089872122, training accuracy: 0.9904\n",
      "Val loss: 0.022906219586730003, val accuracy: 0.8984\n",
      "\n",
      "Epoch 83\n",
      "Training loss: -0.0016160279046744108, training accuracy: 0.9905473684210526\n",
      "Val loss: 0.01184521708637476, val accuracy: 0.9052\n",
      "Saving ...\n",
      "\n",
      "Epoch 84\n",
      "Training loss: -0.00142530573066324, training accuracy: 0.9908\n",
      "Val loss: 0.02165352925658226, val accuracy: 0.9004\n",
      "\n",
      "Epoch 85\n",
      "Training loss: -0.0004989689332433045, training accuracy: 0.9905052631578948\n",
      "Val loss: 0.01801466941833496, val accuracy: 0.8976\n",
      "\n",
      "Epoch 86\n",
      "Training loss: -0.0008358056657016277, training accuracy: 0.9913684210526316\n",
      "Val loss: 0.01647830381989479, val accuracy: 0.8944\n",
      "\n",
      "Epoch 87\n",
      "Training loss: -0.0015907471533864737, training accuracy: 0.9920842105263158\n",
      "Val loss: 0.02673988603055477, val accuracy: 0.9028\n",
      "\n",
      "Epoch 88\n",
      "Training loss: -0.0016201009275391698, training accuracy: 0.9922526315789474\n",
      "Val loss: 0.03541414812207222, val accuracy: 0.9012\n",
      "\n",
      "Epoch 89\n",
      "Training loss: -0.001617766567505896, training accuracy: 0.9920842105263158\n",
      "Val loss: 0.018974507227540016, val accuracy: 0.896\n",
      "\n",
      "Epoch 90\n",
      "Training loss: -0.0016732148360460997, training accuracy: 0.9927368421052631\n",
      "Val loss: 0.02817354165017605, val accuracy: 0.902\n",
      "\n",
      "Epoch 91\n",
      "Training loss: -0.0017369602574035525, training accuracy: 0.9929263157894737\n",
      "Val loss: 0.03751985728740692, val accuracy: 0.8996\n",
      "\n",
      "Epoch 92\n",
      "Training loss: 0.0013686178717762232, training accuracy: 0.9923157894736843\n",
      "Val loss: 0.029157040640711784, val accuracy: 0.9016\n",
      "\n",
      "Epoch 93\n",
      "Training loss: -0.0014052331680431962, training accuracy: 0.9921894736842105\n",
      "Val loss: 0.01386938989162445, val accuracy: 0.9\n",
      "\n",
      "Epoch 94\n",
      "Training loss: -0.0016141543164849281, training accuracy: 0.9924631578947368\n",
      "Val loss: 0.01709904335439205, val accuracy: 0.8964\n",
      "\n",
      "Epoch 95\n",
      "Training loss: -0.0016345875337719917, training accuracy: 0.9927157894736842\n",
      "Val loss: 0.021170739084482193, val accuracy: 0.9012\n",
      "\n",
      "Epoch 96\n",
      "Training loss: -0.001073390943929553, training accuracy: 0.9928\n",
      "Val loss: 0.021119600161910057, val accuracy: 0.8968\n",
      "\n",
      "Epoch 97\n",
      "Training loss: -0.0014549648622050881, training accuracy: 0.9928\n",
      "Val loss: 0.01143910363316536, val accuracy: 0.9\n",
      "\n",
      "Epoch 98\n",
      "Training loss: -0.00030116207199171185, training accuracy: 0.9928421052631579\n",
      "Val loss: 0.003697772743180394, val accuracy: 0.8956\n",
      "\n",
      "Epoch 99\n",
      "Training loss: -0.0015977869043126702, training accuracy: 0.9931578947368421\n",
      "Val loss: 0.017722612246870995, val accuracy: 0.9032\n",
      "\n",
      "Epoch 100\n",
      "Training loss: -0.001612129737623036, training accuracy: 0.9940631578947369\n",
      "Val loss: 0.01314824540168047, val accuracy: 0.902\n",
      "\n",
      "Epoch 101\n",
      "Training loss: -0.001606841222383082, training accuracy: 0.994042105263158\n",
      "Val loss: 0.03318721428513527, val accuracy: 0.9088\n",
      "Saving ...\n",
      "\n",
      "Epoch 102\n",
      "Training loss: -0.001685260096564889, training accuracy: 0.9942526315789474\n",
      "Val loss: 0.04151966795325279, val accuracy: 0.8956\n",
      "\n",
      "Epoch 103\n",
      "Training loss: -0.0016502137295901775, training accuracy: 0.9936421052631579\n",
      "Val loss: 0.01709500327706337, val accuracy: 0.8992\n",
      "\n",
      "Epoch 104\n",
      "Training loss: -0.0016360959270969033, training accuracy: 0.9941052631578947\n",
      "Val loss: 0.03733960911631584, val accuracy: 0.904\n",
      "\n",
      "Epoch 105\n",
      "Training loss: -0.0016365409828722477, training accuracy: 0.9947368421052631\n",
      "Val loss: 0.008385262452065945, val accuracy: 0.9012\n",
      "\n",
      "Epoch 106\n",
      "Training loss: -0.0016526025719940662, training accuracy: 0.9946315789473684\n",
      "Val loss: 0.0406779907643795, val accuracy: 0.9036\n",
      "\n",
      "Epoch 107\n",
      "Training loss: -0.0016532570589333773, training accuracy: 0.9949684210526316\n",
      "Val loss: 0.02390732802450657, val accuracy: 0.8988\n",
      "\n",
      "Epoch 108\n",
      "Training loss: -0.000939304765779525, training accuracy: 0.9946105263157895\n",
      "Val loss: 0.02499478869140148, val accuracy: 0.9012\n",
      "\n",
      "Epoch 109\n",
      "Training loss: -0.0011541519779711962, training accuracy: 0.9950736842105263\n",
      "Val loss: 0.01945219747722149, val accuracy: 0.8992\n",
      "\n",
      "Current learning rate has decayed to 0.0001\n",
      "Epoch 110\n",
      "Training loss: -0.0016245506703853607, training accuracy: 0.9949684210526316\n",
      "Val loss: 0.036325130611658096, val accuracy: 0.9028\n",
      "\n",
      "Epoch 111\n",
      "Training loss: -0.001480137463659048, training accuracy: 0.9950526315789474\n",
      "Val loss: 0.014475889503955841, val accuracy: 0.9076\n",
      "\n",
      "Epoch 112\n",
      "Training loss: -0.0006855312967672944, training accuracy: 0.9953684210526316\n",
      "Val loss: 0.016575686633586884, val accuracy: 0.9032\n",
      "\n",
      "Epoch 113\n",
      "Training loss: -0.0017705814680084586, training accuracy: 0.9943578947368421\n",
      "Val loss: 0.015627766028046608, val accuracy: 0.9072\n",
      "\n",
      "Epoch 114\n",
      "Training loss: -0.0013032025890424848, training accuracy: 0.9947789473684211\n",
      "Val loss: 0.006943396758288145, val accuracy: 0.9028\n",
      "\n",
      "Epoch 115\n",
      "Training loss: -0.0012677509803324938, training accuracy: 0.9952210526315789\n",
      "Val loss: 0.02729460410773754, val accuracy: 0.8992\n",
      "\n",
      "Epoch 116\n",
      "Training loss: -0.0015707799466326833, training accuracy: 0.9951368421052632\n",
      "Val loss: 0.023230601102113724, val accuracy: 0.8992\n",
      "\n",
      "Epoch 117\n",
      "Training loss: -0.0016600567614659667, training accuracy: 0.9956\n",
      "Val loss: 0.04066154360771179, val accuracy: 0.9016\n",
      "\n",
      "Epoch 118\n",
      "Training loss: -0.0015775479841977358, training accuracy: 0.9956421052631579\n",
      "Val loss: 0.032327037304639816, val accuracy: 0.8996\n",
      "\n",
      "Epoch 119\n",
      "Training loss: -0.0016540199285373092, training accuracy: 0.9948\n",
      "Val loss: 0.029266422614455223, val accuracy: 0.8996\n",
      "\n",
      "Epoch 120\n",
      "Training loss: -0.0009855321841314435, training accuracy: 0.995178947368421\n",
      "Val loss: 0.03302454575896263, val accuracy: 0.9092\n",
      "Saving ...\n",
      "\n",
      "Epoch 121\n",
      "Training loss: -0.00165717548225075, training accuracy: 0.9954736842105263\n",
      "Val loss: 0.013995192013680935, val accuracy: 0.9052\n",
      "\n",
      "Epoch 122\n",
      "Training loss: -0.001149277202785015, training accuracy: 0.9957473684210526\n",
      "Val loss: 0.02811010181903839, val accuracy: 0.898\n",
      "\n",
      "Epoch 123\n",
      "Training loss: 0.000282678403891623, training accuracy: 0.9956421052631579\n",
      "Val loss: 0.0360465906560421, val accuracy: 0.9056\n",
      "\n",
      "Epoch 124\n",
      "Training loss: -0.0016707581235095859, training accuracy: 0.9956421052631579\n",
      "Val loss: 0.006662349682301283, val accuracy: 0.9044\n",
      "\n",
      "Epoch 125\n",
      "Training loss: -0.0015270683215931058, training accuracy: 0.9957263157894737\n",
      "Val loss: 0.01431015320122242, val accuracy: 0.906\n",
      "\n",
      "Epoch 126\n",
      "Training loss: -0.0017286534421145916, training accuracy: 0.9956421052631579\n",
      "Val loss: 0.020334741100668907, val accuracy: 0.898\n",
      "\n",
      "Epoch 127\n",
      "Training loss: -0.0017106281593441963, training accuracy: 0.9955578947368421\n",
      "Val loss: 0.03934365138411522, val accuracy: 0.8968\n",
      "\n",
      "Epoch 128\n",
      "Training loss: -0.0012454919051378965, training accuracy: 0.9954315789473684\n",
      "Val loss: 0.02464362420141697, val accuracy: 0.9052\n",
      "\n",
      "Epoch 129\n",
      "Training loss: -0.0016895029693841934, training accuracy: 0.9953684210526316\n",
      "Val loss: 0.016262996941804886, val accuracy: 0.8992\n",
      "\n",
      "Epoch 130\n",
      "Training loss: -0.0015268606366589665, training accuracy: 0.9959789473684211\n",
      "Val loss: 0.03309648483991623, val accuracy: 0.9004\n",
      "\n",
      "Epoch 131\n",
      "Training loss: -0.001300129690207541, training accuracy: 0.9957684210526315\n",
      "Val loss: 0.019816530868411064, val accuracy: 0.8996\n",
      "\n",
      "Epoch 132\n",
      "Training loss: -0.001675960491411388, training accuracy: 0.9952210526315789\n",
      "Val loss: 0.030368400737643242, val accuracy: 0.9072\n",
      "\n",
      "Epoch 133\n",
      "Training loss: -0.0016869042301550508, training accuracy: 0.995578947368421\n",
      "Val loss: 0.0263534989207983, val accuracy: 0.8996\n",
      "\n",
      "Epoch 134\n",
      "Training loss: -0.0016413743142038584, training accuracy: 0.9954526315789474\n",
      "Val loss: 0.02803671732544899, val accuracy: 0.9068\n",
      "\n",
      "Epoch 135\n",
      "Training loss: -0.0014973061624914408, training accuracy: 0.9954315789473684\n",
      "Val loss: 0.016807373613119125, val accuracy: 0.9012\n",
      "\n",
      "Epoch 136\n",
      "Training loss: -0.0016548987478017807, training accuracy: 0.9956\n",
      "Val loss: 0.026860816404223442, val accuracy: 0.9028\n",
      "\n",
      "Epoch 137\n",
      "Training loss: -0.001695175189524889, training accuracy: 0.9958736842105264\n",
      "Val loss: 0.02786758542060852, val accuracy: 0.8956\n",
      "\n",
      "Epoch 138\n",
      "Training loss: -0.0015408187173306942, training accuracy: 0.9959578947368422\n",
      "Val loss: 0.020929604768753052, val accuracy: 0.9028\n",
      "\n",
      "Epoch 139\n",
      "Training loss: -0.0015288135036826134, training accuracy: 0.9961473684210527\n",
      "Val loss: 0.007243544794619083, val accuracy: 0.8976\n",
      "\n",
      "Epoch 140\n",
      "Training loss: -0.0016143163666129112, training accuracy: 0.9959368421052631\n",
      "Val loss: 0.018219033256173134, val accuracy: 0.9004\n",
      "\n",
      "Epoch 141\n",
      "Training loss: -0.0013747934717684984, training accuracy: 0.9959368421052631\n",
      "Val loss: 0.010917647741734982, val accuracy: 0.8968\n",
      "\n",
      "Epoch 142\n",
      "Training loss: -0.0016753736417740583, training accuracy: 0.9957894736842106\n",
      "Val loss: 0.011293884366750717, val accuracy: 0.898\n",
      "\n",
      "Epoch 143\n",
      "Training loss: -0.0016365587944164872, training accuracy: 0.9956842105263158\n",
      "Val loss: 0.056379664689302444, val accuracy: 0.8992\n",
      "\n",
      "Epoch 144\n",
      "Training loss: -0.0016124602407217026, training accuracy: 0.9959368421052631\n",
      "Val loss: 0.017033720389008522, val accuracy: 0.8948\n",
      "\n",
      "Epoch 145\n",
      "Training loss: -0.0016036941669881344, training accuracy: 0.9955157894736842\n",
      "Val loss: 0.03222193568944931, val accuracy: 0.9028\n",
      "\n",
      "Epoch 146\n",
      "Training loss: -0.0015920299338176847, training accuracy: 0.9957473684210526\n",
      "Val loss: 0.010684093460440636, val accuracy: 0.9048\n",
      "\n",
      "Epoch 147\n",
      "Training loss: -0.0012478287098929286, training accuracy: 0.9952\n",
      "Val loss: 0.009792580269277096, val accuracy: 0.906\n",
      "\n",
      "Epoch 148\n",
      "Training loss: -0.0014320696936920285, training accuracy: 0.9959789473684211\n",
      "Val loss: 0.026371052488684654, val accuracy: 0.896\n",
      "\n",
      "Epoch 149\n",
      "Training loss: -0.0017494721105322242, training accuracy: 0.9957684210526315\n",
      "Val loss: 0.023274941369891167, val accuracy: 0.9004\n",
      "\n",
      "==================================================\n",
      "==> Finished Training! The best accuracy is 0.9092\n"
     ]
    }
   ],
   "source": [
    "distillationTraining(student_model, train_loader, 'reversed_distillation_resnet50.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples is 10000, correct examples is 9128; Test accuracy: 0.9128\n"
     ]
    }
   ],
   "source": [
    "reverse_distilled_model = ResNet50()\n",
    "checkpoint = torch.load(\"./saved_model/reversed_distillation_resnet50_final.pth\")\n",
    "reverse_distilled_model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "test_model(reverse_distilled_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
